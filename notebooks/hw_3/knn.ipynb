{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df183879-3cc9-4598-8111-6f9aab4c0e9a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7692a7e5bb026164c9067b95bffe9b5",
     "grade": false,
     "grade_id": "cell-8619aa6f1d11d3e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Домашнее задание №3. Вариант рекомендательной системы с knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86de5ff6-ae70-4882-8c2c-671bd4e36e1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18d7b581eb400309d98dd7948a118d2d",
     "grade": false,
     "grade_id": "cell-6520937952d69a16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyaskin_mikhail/ITMO/RecSys/RecSys/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import Union\n",
    "\n",
    "import implicit\n",
    "import rectools\n",
    "import requests\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, MeanInvUserFreq\n",
    "from rectools.dataset import Dataset\n",
    "from scipy.sparse import coo_matrix, spmatrix\n",
    "from implicit.nearest_neighbours import ItemItemRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8710b1c2-947f-4ea7-be09-2fbd1298013b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8060d70b17d75f3e5d6a280a0d259932",
     "grade": false,
     "grade_id": "cell-93a83ccdf573ad30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implicit: 0.7.2\n",
      "requests: 2.31.0\n",
      "rectools: 0.12.0\n",
      "pandas: 2.2.3\n",
      "numpy: 1.26.4\n",
      "scipy: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"implicit:\", implicit.__version__)\n",
    "print(\"requests:\", requests.__version__)\n",
    "print(\"rectools:\", rectools.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scipy:\", sp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c964a927-5d4f-431e-88a7-38ff6370796d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38070451d403c16bbdefb3e84c7814fd",
     "grade": false,
     "grade_id": "cell-b42aa4e57bf28d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476251, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  weight  watched_pct\n",
       "0   176549     9506 2021-05-11    4250         72.0\n",
       "1   699317     1659 2021-05-29    8317        100.0\n",
       "2   656683     7107 2021-05-09      10          0.0\n",
       "3   864613     7638 2021-07-05   14483        100.0\n",
       "4   964868     9506 2021-04-30    6725        100.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = (\n",
    "    pd.read_csv('/Users/kulyaskin_mikhail/ITMO/RecSys/data/data_original/interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={'total_dur': Columns.Weight,\n",
    "                     'last_watch_dt': Columns.Datetime})\n",
    ")\n",
    "users = pd.read_csv('/Users/kulyaskin_mikhail/ITMO/RecSys/data/data_original/users.csv')\n",
    "items = pd.read_csv('/Users/kulyaskin_mikhail/ITMO/RecSys/data/data_original/items.csv')\n",
    "\n",
    "print(interactions.shape)\n",
    "interactions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e79119c-f196-4899-b0b9-54e0af3af38e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82ca913cf02af8f599ef185d1c8cfac7",
     "grade": false,
     "grade_id": "cell-52b23c87b1866217",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Ситуация: \n",
    "\n",
    "Ваш коллега ушел в отпуск, оставив вам недописанную модель в `userknn.py` (код из семинара №3 будет в ячейке этого ноутбука далее)\n",
    "\n",
    "Через 3 дня ее нужно выкатить в А/B тест. Это значит, что модель должна уметь выдавать рекомендации размера `k` любым пользователям (холодным / горячим). \n",
    "\n",
    "Требуется дописать методы класса UserKnn:\n",
    "\n",
    "- метод, который выдает рекомендации холодным пользователям (сейчас модель этого не умеет)\n",
    "- в методе, который выдает рекомендации горячим пользователям, дописать код так, чтобы у всех было одинаковое кол-во рекомендаций k, а не меньше k, как сейчас.\n",
    "\n",
    "Также была договоренность, что перед выкаткой вы покажете продакт менеджеру финальные значения по оффлайн метрикам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d4c04-3785-484b-9f5b-069cb6e4636e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "149d469a22e2152cb2322351916f60ea",
     "grade": false,
     "grade_id": "cell-b654fb723ac79668",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Готовим тестовую выборку\n",
    "\n",
    "Здесь и далее жестко фиксируем тестовую выборку **ровно последние 14 дней из `interactions`**  - по результатам на ней будут выставляться баллы\n",
    "\n",
    "Сохраните тестовую выборку (тестовые interactions) в pandas DataFrame и назовите его `test`. \n",
    "\n",
    "Оставьте в нем все поля из `interactions`. Удостоверьтесь, что формат полей следующий:\n",
    "\n",
    "    Column   Dtype         \n",
    " - user_id -    int64         \n",
    " - item_id -    int64         \n",
    " - datetime -   datetime64\n",
    " - weight -      int64         \n",
    " - watched_pct - float64    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e36493a-5da4-4cd6-b8d7-cb2652d683ba",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe64c9bb32393d2030b17b8758d3e30",
     "grade": false,
     "grade_id": "cell-d6819c2c430a8e75",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "max_date = interactions['datetime'].max()\n",
    "\n",
    "train = interactions[(interactions['datetime'] <= max_date - pd.Timedelta(days=14))]\n",
    "test = interactions[(interactions['datetime'] > max_date - pd.Timedelta(days=14))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925c9d4-1678-440a-abde-5403ec7fa557",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7d660cf3c2bbd3a169c3c1e335c5e55",
     "grade": false,
     "grade_id": "cell-b375f544307c12a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Проверка:  тестовая выборка - 3 балла\n",
    "\n",
    "Внимание! Есть скрытые тесты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317056ee-8974-46ba-bbe2-d2f5a8f330e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75fd3e3424bbb99aee2223df6a57bb02",
     "grade": true,
     "grade_id": "cell-d4177ea915281721",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(test, pd.DataFrame)\n",
    "assert test.datetime.nunique() == 14\n",
    "\n",
    "expected_mean = 6887.2\n",
    "actual_mean = round(test['weight'].mean(), 1)\n",
    "assert abs(actual_mean - expected_mean) < 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d737c4-2f0c-45f0-ae0e-2ed1d37ba113",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a0dae0d42bbe8ac9079ce863868e6e9",
     "grade": false,
     "grade_id": "cell-305dab6e173e62b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Код модели\n",
    "\n",
    "Допишите методы `fit_cold_model` и  `recommend_cold`, которые делают рекомендации холодным пользователям (сейчас модель этого не умеет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aee4dce-4e2d-410b-8997-6ae2d4de1e20",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27c3c7e15dfc4211b26fbffbf86a31cc",
     "grade": false,
     "grade_id": "cell-fc1beb2c90026cfd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from rectools.models.popular import PopularModel\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "class UserKnn:\n",
    "    \"\"\"\n",
    "    A user-based KNN model wrapper around `implicit.nearest_neighbours.ItemItemRecommender`\n",
    "    \"\"\"\n",
    "\n",
    "    SIMILAR_USER_COLUMN = \"similar_user_id\"\n",
    "    SIMILARITY_COLUMN = \"similarity\"\n",
    "    IDF_COLUMN = \"idf\"\n",
    "\n",
    "    def __init__(self, model: ItemItemRecommender, N_similar_users: int):\n",
    "        self.model = model\n",
    "        self.pop = PopularModel()\n",
    "        self.N_similar_users = N_similar_users\n",
    "\n",
    "        self.users_inv_mapping = None\n",
    "        self.users_mapping = None\n",
    "        self.items_inv_mapping = None\n",
    "        self.items_mapping = None\n",
    "\n",
    "        self.watched_items_dataframe = None\n",
    "        self.item_idf = None\n",
    "        self.cold_model_fitted = False\n",
    "\n",
    "    def _set_mappings(self, interactions: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Create dictionaries to map external IDs (users, items) to internal IDs and vice versa.\n",
    "        \"\"\"\n",
    "        unique_users = interactions[Columns.User].unique()\n",
    "        self.users_inv_mapping = dict(enumerate(unique_users))\n",
    "        self.users_mapping = {v: k for k, v in self.users_inv_mapping.items()}\n",
    "\n",
    "        unique_items = interactions[Columns.Item].unique()\n",
    "        self.items_inv_mapping = dict(enumerate(unique_items))\n",
    "        self.items_mapping = {v: k for k, v in self.items_inv_mapping.items()}\n",
    "\n",
    "    def _get_user_item_matrix(self, interactions: pd.DataFrame) -> spmatrix:\n",
    "        \"\"\"\n",
    "        Construct a sparse user-item matrix in CSR format.\n",
    "        Rows represent users, and columns represent items.\n",
    "        \"\"\"\n",
    "        user_idx = interactions[Columns.User].map(self.users_mapping.get)\n",
    "        item_idx = interactions[Columns.Item].map(self.items_mapping.get)\n",
    "        data = interactions[Columns.Weight].astype(np.float32)\n",
    "\n",
    "        user_item_coo = coo_matrix((data, (user_idx, item_idx)))\n",
    "        return user_item_coo.tocsr()\n",
    "\n",
    "    def _set_interacted_items_dataframe(self, interactions: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Groups interactions by user to get item_id list for each user\n",
    "        \"\"\"\n",
    "        self.interacted_items_dataframe = (\n",
    "            interactions.groupby(Columns.User, as_index=False)\n",
    "            .agg({Columns.Item: list})\n",
    "            .rename(columns={Columns.User: self.SIMILAR_USER_COLUMN})\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def idf(n: int, x: float):\n",
    "        \"\"\"\n",
    "        Calculates IDF for one item\n",
    "        \"\"\"\n",
    "        return np.log((1 + n) / (1 + x) + 1)\n",
    "\n",
    "    def _count_item_idf(self, interactions: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Calculate IDF values for all items present in the interactions dataset\n",
    "         and store the result in self.item_idf.\n",
    "        \"\"\"\n",
    "        item_freqs = Counter(interactions[Columns.Item].values)\n",
    "        item_idf_df = (\n",
    "            pd.DataFrame\n",
    "            .from_dict(item_freqs, orient=\"index\", columns=[\"doc_freq\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "        total_interactions = len(interactions)\n",
    "        item_idf_df[self.IDF_COLUMN] = item_idf_df[\"doc_freq\"].apply(\n",
    "            lambda x: self.idf(total_interactions, x)\n",
    "        )\n",
    "        self.item_idf = item_idf_df\n",
    "\n",
    "    def _prepare_for_model(self, train_interactions: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Sets mappings, grouped interactions, calculates idf\n",
    "        \"\"\"\n",
    "        self._set_mappings(train_interactions)\n",
    "        self._set_interacted_items_dataframe(train_interactions)\n",
    "        self._count_item_idf(train_interactions)\n",
    "\n",
    "    def fit_cold_model(self, train_interactions: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Fit a model for cold recommendations.\n",
    "\n",
    "        Parameters:\n",
    "        train_interactions (pd.DataFrame): interaction data used to train the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset_cold = Dataset.construct(\n",
    "            interactions_df=train_interactions,\n",
    "            user_features_df=None,\n",
    "            item_features_df=None\n",
    "        )\n",
    "        \n",
    "        self.pop.fit(self.dataset_cold)\n",
    "\n",
    "    def recommend_cold(self, users: Union[list, np.array],\n",
    "                        k: int = 100) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return recommendations for the given cold users.\n",
    "        Can be called separately or within the class. Supports both list and numpy array as input.\n",
    "\n",
    "        Parameters:\n",
    "        users (list | np.array): List or array of users for whom recommendations will be generated.\n",
    "        k (int, optional): Number of recommendations to generate per user. Default is 100.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A dataframe containing user-item recommendations.\n",
    "        \"\"\"\n",
    "        \n",
    "        pop_recs = self.pop.recommend(\n",
    "            users,\n",
    "            dataset=self.dataset_cold,\n",
    "            k=k,\n",
    "            filter_viewed=False  # True - удаляет просмотренные айтемы из рекомендаций \n",
    "        )\n",
    "\n",
    "        return pop_recs\n",
    "\n",
    "    def fit(self, train_interactions: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model on the provided training data.\n",
    "\n",
    "        Internally:\n",
    "        1) Prepare mappings, watchlist DataFrame, and item IDF.\n",
    "        2) Create a user-item matrix and fit the underlying Implicit model.\n",
    "        \"\"\"\n",
    "        self.fit_cold_model(train_interactions)\n",
    "        self._prepare_for_model(train_interactions)\n",
    "        user_item_matrix = self._get_user_item_matrix(train_interactions)\n",
    "        user_item_matrix = user_item_matrix.astype(np.float64)\n",
    "        self.model.fit(user_item_matrix.T)\n",
    "\n",
    "    def _get_similar_users(self, external_user_id: int) -> tuple[list[int], list[float]]:\n",
    "        \"\"\"\n",
    "        Retrieve a list of similar users and corresponding similarities\n",
    "        from the underlying Implicit model.\n",
    "        \"\"\"\n",
    "        if external_user_id not in self.users_mapping:\n",
    "            # if user doesn't exist in mapping, return sentinel (-1).\n",
    "            return [-1], [-1]\n",
    "\n",
    "        internal_user_id = self.users_mapping[external_user_id]\n",
    "        user_ids, similarities = self.model.similar_items(\n",
    "            internal_user_id,\n",
    "            N=self.N_similar_users\n",
    "        )\n",
    "        # convert back to external IDs\n",
    "        external_user_ids = [self.users_inv_mapping[u_id] for u_id in user_ids]\n",
    "        return external_user_ids, similarities\n",
    "\n",
    "    @staticmethod\n",
    "    def get_rank(recs: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Sort recommendations by score in descending order,\n",
    "        assign ranks within each user group, and then truncate by top-k.\n",
    "        \"\"\"\n",
    "        recs = recs.sort_values([Columns.User, Columns.Score], ascending=False)\n",
    "        recs = recs.drop_duplicates([Columns.User, Columns.Item])\n",
    "        recs[Columns.Rank] = recs.groupby(Columns.User).cumcount() + 1\n",
    "        recs = recs[recs[Columns.Rank] <= k][\n",
    "            [Columns.User, Columns.Item, Columns.Score, Columns.Rank]\n",
    "        ]\n",
    "\n",
    "        return recs\n",
    "\n",
    "    def recommend(self, users: np.ndarray, k: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate top-k recommendations for the specified list of users.\n",
    "        \"\"\"\n",
    "        # Создаем начальный DataFrame с пользователями\n",
    "        recs = pd.DataFrame({Columns.User: users})\n",
    "        \n",
    "        # Получаем похожих пользователей и их сходство\n",
    "        recs[self.SIMILAR_USER_COLUMN], recs[self.SIMILARITY_COLUMN] = zip(\n",
    "            *recs[Columns.User].map(lambda user_id: self._get_similar_users(user_id))\n",
    "        )\n",
    "        recs = recs.set_index(Columns.User).apply(pd.Series.explode).reset_index()\n",
    "\n",
    "        # Фильтруем и обрабатываем рекомендации на основе похожих пользователей\n",
    "        knn_recs = (\n",
    "            recs[~(recs[Columns.User] == recs[self.SIMILAR_USER_COLUMN])]\n",
    "            .merge(\n",
    "                self.interacted_items_dataframe,\n",
    "                on=[self.SIMILAR_USER_COLUMN],\n",
    "                how=\"left\",\n",
    "            )\n",
    "            .explode(Columns.Item)\n",
    "            .sort_values([Columns.User, self.SIMILARITY_COLUMN], ascending=False)\n",
    "            .drop_duplicates([Columns.User, Columns.Item], keep=\"first\")\n",
    "            .merge(self.item_idf, left_on=Columns.Item, right_on=\"index\", how=\"left\")\n",
    "        )\n",
    "\n",
    "        knn_recs[Columns.Score] = knn_recs[self.SIMILARITY_COLUMN] * knn_recs[self.IDF_COLUMN]\n",
    "        knn_recs = knn_recs[[Columns.User, Columns.Item, Columns.Score]]\n",
    "        knn_recs = knn_recs.dropna()\n",
    "\n",
    "        # Сохраняем полный список пользователей для проверки в конце\n",
    "        all_users = set(users)\n",
    "        \n",
    "        # Пользователи, которые получили KNN рекомендации\n",
    "        users_with_knn_recs = set(knn_recs[Columns.User].unique())\n",
    "        \n",
    "        # Пользователи, которым не хватает KNN рекомендаций до k \n",
    "        user_rec_counts = knn_recs[Columns.User].value_counts().reset_index()\n",
    "        user_rec_counts.columns = [Columns.User, 'count']\n",
    "        users_needing_more = user_rec_counts[user_rec_counts['count'] < k][Columns.User].tolist()\n",
    "        \n",
    "        # Пользователи, у которых нет KNN рекомендаций вообще\n",
    "        users_without_knn_recs = all_users - users_with_knn_recs\n",
    "        \n",
    "        # Объединяем обе категории пользователей, которым нужны популярные рекомендации\n",
    "        users_needing_pop_recs = list(users_without_knn_recs) + users_needing_more\n",
    "        \n",
    "        if users_needing_pop_recs:\n",
    "            # Получаем популярные рекомендации для всех пользователей, которым они нужны\n",
    "            pop_recs_df = self.pop.recommend(\n",
    "                users=users_needing_pop_recs,\n",
    "                dataset=self.dataset_cold,\n",
    "                k=k,  # Запрашиваем максимальное количество\n",
    "                filter_viewed=False\n",
    "            )\n",
    "            \n",
    "            # Для пользователей без KNN рекомендаций - берем все популярные рекомендации\n",
    "            pop_only_users = pop_recs_df[pop_recs_df[Columns.User].isin(users_without_knn_recs)]\n",
    "            \n",
    "            # Для пользователей с неполными KNN рекомендациями - фильтруем по необходимости\n",
    "            if users_needing_more:\n",
    "                # Получаем уже рекомендованные элементы для каждого пользователя\n",
    "                existing_items_by_user = knn_recs.groupby(Columns.User)[Columns.Item].apply(set).to_dict()\n",
    "                \n",
    "                # Обрабатываем пользователей с неполными рекомендациями\n",
    "                additional_recs = []\n",
    "                for user_id in users_needing_more:\n",
    "                    items_needed = k - len(existing_items_by_user.get(user_id, set()))\n",
    "                    user_pop_recs = pop_recs_df[pop_recs_df[Columns.User] == user_id]\n",
    "                    user_pop_recs = user_pop_recs[~user_pop_recs[Columns.Item].isin(existing_items_by_user.get(user_id, set()))]\n",
    "                    user_pop_recs = user_pop_recs.head(items_needed)\n",
    "                    additional_recs.append(user_pop_recs)\n",
    "                \n",
    "                # Объединяем дополнительные рекомендации если они есть\n",
    "                if additional_recs:\n",
    "                    additional_recs_df = pd.concat(additional_recs, ignore_index=True)\n",
    "                    # Объединяем все рекомендации\n",
    "                    recs = pd.concat([knn_recs, pop_only_users, additional_recs_df], ignore_index=True)\n",
    "                else:\n",
    "                    recs = pd.concat([knn_recs, pop_only_users], ignore_index=True)\n",
    "            else:\n",
    "                recs = pd.concat([knn_recs, pop_only_users], ignore_index=True)\n",
    "        else:\n",
    "            recs = knn_recs\n",
    "        \n",
    "        # Получаем итоговые ранжированные рекомендации\n",
    "        recs = self.get_rank(recs, k=k)\n",
    "        \n",
    "        # Проверяем, что все пользователи получили рекомендации\n",
    "        final_users = set(recs[Columns.User].unique())\n",
    "        missing_users = all_users - final_users\n",
    "        \n",
    "        # Если остались пользователи без рекомендаций, добавляем им популярные рекомендации напрямую\n",
    "        if missing_users:\n",
    "            last_chance_recs = self.pop.recommend(\n",
    "                users=list(missing_users),\n",
    "                dataset=self.dataset_cold,\n",
    "                k=k,\n",
    "                filter_viewed=False\n",
    "            )\n",
    "            recs = pd.concat([recs, last_chance_recs], ignore_index=True)\n",
    "            recs = self.get_rank(recs, k=k)\n",
    "        \n",
    "        return recs\n",
    "    \n",
    "\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Сохраняет модель в указанную директорию.\n",
    "        \n",
    "        Parameters:\n",
    "        path (str): Путь к директории, куда будет сохранена модель\n",
    "        \"\"\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        # Сохраняем основные параметры модели\n",
    "        model_params = {\n",
    "            'N_similar_users': self.N_similar_users,\n",
    "            'users_inv_mapping': self.users_inv_mapping,\n",
    "            'users_mapping': self.users_mapping,\n",
    "            'items_inv_mapping': self.items_inv_mapping,\n",
    "            'items_mapping': self.items_mapping,\n",
    "            'cold_model_fitted': self.cold_model_fitted\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(path, 'model_params.pkl'), 'wb') as f:\n",
    "            pickle.dump(model_params, f)\n",
    "        \n",
    "        # Сохраняем датафреймы\n",
    "        if hasattr(self, 'interacted_items_dataframe') and self.interacted_items_dataframe is not None:\n",
    "            self.interacted_items_dataframe.to_pickle(os.path.join(path, 'interacted_items_df.pkl'))\n",
    "        \n",
    "        if hasattr(self, 'item_idf') and self.item_idf is not None:\n",
    "            self.item_idf.to_pickle(os.path.join(path, 'item_idf.pkl'))\n",
    "        \n",
    "        # Сохраняем матрицу схожести и другие компоненты модели ItemItemRecommender\n",
    "        if hasattr(self.model, 'similarity') and self.model.similarity is not None:\n",
    "            scipy.sparse.save_npz(os.path.join(path, 'similarity_matrix.npz'), self.model.similarity)\n",
    "        \n",
    "        # Сохраняем дополнительные параметры модели ItemItemRecommender\n",
    "        if hasattr(self.model, 'K'):\n",
    "            item_model_params = {\n",
    "                'K': self.model.K,\n",
    "                'num_threads': getattr(self.model, 'num_threads', 0),\n",
    "                'filter_users': getattr(self.model, 'filter_users', True),\n",
    "                'filter_items': getattr(self.model, 'filter_items', True),\n",
    "                'sort_items': getattr(self.model, 'sort_items', True)\n",
    "            }\n",
    "            with open(os.path.join(path, 'item_model_params.pkl'), 'wb') as f:\n",
    "                pickle.dump(item_model_params, f)\n",
    "        \n",
    "        # Сохраняем популярную модель и датасет для холодного старта\n",
    "        if hasattr(self, 'pop') and self.pop is not None:\n",
    "            joblib.dump(self.pop, os.path.join(path, 'popular_model.joblib'))\n",
    "        \n",
    "        if hasattr(self, 'dataset_cold') and self.dataset_cold is not None:\n",
    "            joblib.dump(self.dataset_cold, os.path.join(path, 'dataset_cold.joblib'))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path, implicit_model=None):\n",
    "        \"\"\"\n",
    "        Загружает модель из указанной директории.\n",
    "        \n",
    "        Parameters:\n",
    "        path (str): Путь к директории с сохраненной моделью\n",
    "        implicit_model: Экземпляр класса ItemItemRecommender (если None, будет создан новый)\n",
    "        \n",
    "        Returns:\n",
    "        UserKnn: Экземпляр загруженной модели\n",
    "        \"\"\"\n",
    "            \n",
    "        if implicit_model is None:\n",
    "            from implicit.nearest_neighbours import ItemItemRecommender\n",
    "            implicit_model = ItemItemRecommender()\n",
    "        \n",
    "        # Если implicit_model все еще None, создаем с параметрами по умолчанию\n",
    "        if implicit_model is None:\n",
    "            from implicit.nearest_neighbours import ItemItemRecommender\n",
    "            implicit_model = ItemItemRecommender()\n",
    "        \n",
    "        # Загружаем матрицу схожести, если она существует\n",
    "        if os.path.exists(os.path.join(path, 'similarity_matrix.npz')):\n",
    "            implicit_model.similarity = scipy.sparse.load_npz(os.path.join(path, 'similarity_matrix.npz'))\n",
    "        \n",
    "        # Создаем пустой экземпляр класса\n",
    "        with open(os.path.join(path, 'model_params.pkl'), 'rb') as f:\n",
    "            model_params = pickle.load(f)\n",
    "        \n",
    "        instance = cls(model=implicit_model, N_similar_users=model_params['N_similar_users'])\n",
    "        \n",
    "        # Загружаем основные параметры\n",
    "        for key, value in model_params.items():\n",
    "            if key != 'N_similar_users':  # N_similar_users уже установлен в конструкторе\n",
    "                setattr(instance, key, value)\n",
    "        \n",
    "        # Загружаем датафреймы\n",
    "        if os.path.exists(os.path.join(path, 'interacted_items_df.pkl')):\n",
    "            instance.interacted_items_dataframe = pd.read_pickle(os.path.join(path, 'interacted_items_df.pkl'))\n",
    "        \n",
    "        if os.path.exists(os.path.join(path, 'item_idf.pkl')):\n",
    "            instance.item_idf = pd.read_pickle(os.path.join(path, 'item_idf.pkl'))\n",
    "        \n",
    "        # Загружаем популярную модель и датасет для холодного старта\n",
    "        if os.path.exists(os.path.join(path, 'popular_model.joblib')):\n",
    "            instance.pop = joblib.load(os.path.join(path, 'popular_model.joblib'))\n",
    "        \n",
    "        if os.path.exists(os.path.join(path, 'dataset_cold.joblib')):\n",
    "            instance.dataset_cold = joblib.load(os.path.join(path, 'dataset_cold.joblib'))\n",
    "        \n",
    "        return instance        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d67d2-3250-4eef-82b4-0b99ab704fc2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "571d4eedb09c06b043dfd57ad1ff7679",
     "grade": false,
     "grade_id": "cell-a166ec0fd3451e8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Рекомендации для холодных пользователей\n",
    "\n",
    "Используйте метод класса UseKnn, который выдает рекомендации холодным пользователям. \n",
    "\n",
    "### Порекомендуйте k=10 уникальных айтемов для каждого холодного пользователя из тестовой выборки. Сохраните рекомендации в pandas DataFrame и назовите его `reco_cold`. \n",
    "\n",
    "Датафрейм `reco_cold` должен иметь обязательные поля `user_id`, `item_id`, `rank`. \n",
    "\n",
    "⚠️ Холодными считаем пользователей, у которых нет интеракций в train. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1173f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cold = test[~test['user_id'].isin(train['user_id'].unique())]\n",
    "model = UserKnn(model=ItemItemRecommender(), N_similar_users=30)\n",
    "model.fit_cold_model(train)\n",
    "test_cold_users = test_cold['user_id'].unique()\n",
    "reco_cold = model.recommend_cold(test_cold_users, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15ed76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505244</td>\n",
       "      <td>10440</td>\n",
       "      <td>175949.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505244</td>\n",
       "      <td>15297</td>\n",
       "      <td>168500.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>505244</td>\n",
       "      <td>13865</td>\n",
       "      <td>108966.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505244</td>\n",
       "      <td>9728</td>\n",
       "      <td>107640.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505244</td>\n",
       "      <td>4151</td>\n",
       "      <td>80649.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116895</th>\n",
       "      <td>697262</td>\n",
       "      <td>3734</td>\n",
       "      <td>64809.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116896</th>\n",
       "      <td>697262</td>\n",
       "      <td>2657</td>\n",
       "      <td>63183.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116897</th>\n",
       "      <td>697262</td>\n",
       "      <td>4880</td>\n",
       "      <td>51416.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116898</th>\n",
       "      <td>697262</td>\n",
       "      <td>142</td>\n",
       "      <td>40663.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116899</th>\n",
       "      <td>697262</td>\n",
       "      <td>6809</td>\n",
       "      <td>37847.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1116900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id     score  rank\n",
       "0         505244    10440  175949.0     1\n",
       "1         505244    15297  168500.0     2\n",
       "2         505244    13865  108966.0     3\n",
       "3         505244     9728  107640.0     4\n",
       "4         505244     4151   80649.0     5\n",
       "...          ...      ...       ...   ...\n",
       "1116895   697262     3734   64809.0     6\n",
       "1116896   697262     2657   63183.0     7\n",
       "1116897   697262     4880   51416.0     8\n",
       "1116898   697262      142   40663.0     9\n",
       "1116899   697262     6809   37847.0    10\n",
       "\n",
       "[1116900 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_cold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf2398-ca7e-4ddc-81a8-e544bb7a514a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7840aac9f44f1dffa64d84cde851e3ca",
     "grade": false,
     "grade_id": "cell-7715e1c14df33d58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Проверка рекомендаций по холодным пользователям - 4 балла\n",
    "\n",
    "Внимание! Есть скрытые тесты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea15f061-9a08-48f0-ad5d-8e05b39df162",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "628f15551565fe1047df4219760cb95d",
     "grade": true,
     "grade_id": "cell-e5bf7a9e20d1865a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка правильности формирования холодных рекомендаций - 2 балл\n",
    "\n",
    "assert isinstance(reco_cold, pd.DataFrame)\n",
    "\n",
    "expected_columns = {'user_id', 'item_id', 'rank'}\n",
    "assert expected_columns.issubset(set(reco_cold.columns))\n",
    "\n",
    "assert reco_cold.user_id.nunique() == 111690\n",
    "\n",
    "assert (reco_cold.groupby('user_id')['item_id'].nunique() == 10).all(), \\\n",
    "    \"Ошибка: у каждого user_id должно быть ровно 10 уникальных item_id\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b67784-3415-4cc8-87d4-7f8ad86abc1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0462da5fc787dd59c9be2bbcc2af5be0",
     "grade": true,
     "grade_id": "cell-4c0fc9cecc555068",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка метрик качества холодных рекомендаций на полном test - 2 балла\n",
    "assert (MAP(k=10).calc(reco_cold, test) >= 0.04 \n",
    "    and MAP(k=10).calc(reco_cold, test) < 0.98)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d41a9-c3a6-441a-ae33-50bd7e615fb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8974255dfc6b829dc5970504728ae8ab",
     "grade": false,
     "grade_id": "cell-f826c221b0cbbfac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Рекомендации для горячих пользователей\n",
    "\n",
    "Допишите метод `recommend` класса UseKnn так, чтобы он выдавал ровно k рекомендаций (сейчас он выдает некоторым пользователям меньше k, особенность implicit knn модели)\n",
    "\n",
    "### Порекомендуйте k=10 уникальных айтемов для каждого горячего пользователя из тестовой выборки. Сохраните рекомендации в pandas DataFrame и назовите его `reco_hot`\n",
    "\n",
    "датафрейм `reco_hot` ддолжен иметь обязательные поля `user_id`, `item_id`, `rank`. \n",
    "\n",
    "⚠️ горячими считаем пользователей, у которых ЕСТЬ любое количество интеракции в train. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5c1a6-f0de-4654-aa0e-6dc4ef47eb6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66c4d4f63623ffea5d821b1f6de3e7dd",
     "grade": false,
     "grade_id": "cell-9da215470ae745ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hack в помощь\n",
    "\n",
    "Дело к близится к вечеру, продакт менеджер торопит Вас.\n",
    "\n",
    "А код userknn фитится долго, потому что кто-то запихнул в него весь train с over 900 тыс пользователей. \n",
    "\n",
    "Вы решаете аккуратно уменьшить трейн\n",
    "\n",
    "- `возьмите только последние 30 дней датасета в трейн`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1f00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_date = train['datetime'].max()\n",
    "train_last_30_days = train[train['datetime'] >= (max_train_date - pd.Timedelta(days=30))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca48b63-820d-4e2e-b1f2-fd5ed3c3b7a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ead713e722204726f8b0279474a394f2",
     "grade": false,
     "grade_id": "cell-0b479a71153fc48a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Обучите модель, сделайте рекомендации `reco_hot` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6548d5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyaskin_mikhail/ITMO/RecSys/RecSys/.venv/lib/python3.12/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.006944894790649414 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 398800/398800 [01:40<00:00, 3959.64it/s]\n"
     ]
    }
   ],
   "source": [
    "model = UserKnn(model=ItemItemRecommender(), N_similar_users=30)\n",
    "model.fit(train_last_30_days)\n",
    "test_hot = test[test['user_id'].isin(train_last_30_days['user_id'].unique())]\n",
    "reco_hot = model.recommend(test_hot['user_id'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e6480-5430-4a1e-9eae-56e68cf56522",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc5bb5fd49c45a0175acb30a696d3199",
     "grade": false,
     "grade_id": "cell-8785fd65a997d897",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Проверка рекомендаций по горячим пользователям - 8 баллов\n",
    "\n",
    "Внимание! Есть скрытые тесты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31b0bf5-cf6e-4bf7-b19f-c8d3fc92f7aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79c8d1061f36fcf36fa740c49b670f88",
     "grade": true,
     "grade_id": "cell-8c1fb777f3ad7af5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверки на правильность формирования reco_hot - 3 балла за все проверки в ячейке\n",
    "\n",
    "assert isinstance(reco_hot, pd.DataFrame)\n",
    "\n",
    "expected_columns = {'user_id', 'item_id', 'rank'}\n",
    "assert expected_columns.issubset(set(reco_hot.columns))\n",
    "\n",
    "assert reco_hot.user_id.nunique() == 128070\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579efc4d-9c3e-4e6b-89c2-0301b8fcc3f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f02c295338bf5598ee49b071e7449f1e",
     "grade": true,
     "grade_id": "cell-68ad1626e291a863",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# проверки на метрики - 5 баллов за все проверки в ячейке\n",
    "\n",
    "assert (reco_hot.groupby('user_id')['item_id'].nunique() == 10).all(), \\\n",
    "    \"Ошибка: у каждого user_id должно быть ровно 10 уникальных item_id\"\n",
    "\n",
    "assert (MAP(k=10).calc(reco_hot, test) <= 0.04 \n",
    "    and MeanInvUserFreq(k=10).calc(reco_hot, test) > 7.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd9a1a-f9f8-482b-b938-134e0f7db092",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8427adf2721d692c632e0cb5e7e2a10f",
     "grade": false,
     "grade_id": "cell-0feb2f8cb349b80c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Как сдать ноутбук `knn.ipynb` на проверку\n",
    "\n",
    "⚠️ Важное замечание: чтобы ваш ноутбук смог пройти проверку, скопируйте код класса `UserKnn` из `userknn.py` в этот ноутбук. Мы не можем гарантировать, что импорты из py файла будут работать.\n",
    "\n",
    "1. Прогоните весь код ноутбука - проверьте, что нет ошибок и тесты проходят\n",
    "2. Выложите готовый ноутбук в ваш репозиторий с сервисом из домашнего задания №1 по пути `notebooks/hw_3/knn.ipynb` в ветке `hw_3`\n",
    "\n",
    "3. Проверьте, что есть доступ к вашему репозиторию для аккаунтов `https://github.com/feldlime`\n",
    "\n",
    "5. Откройте PR в main ветку и добавьте в ревьюеры **своего ментора**\n",
    "\n",
    "6. Не проводите мердж в `main` ветку, пока не увидите оценку за это ДЗ в ведомости. Файл с ноутбуком должен находиться в ветке `hw_3`\n",
    "\n",
    "Обратите внимание, что сборка ноутбуков на проверку автоматизирована. В случае неправильного пути, имени файла или ветки (а также при отсутствии доступа у `@feldlime`) ваша работа не попадёт на проверку и получит `0` баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087cd8c-893e-48e9-9941-ad7dc6d300d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "210c02b840d043fab85e47b1b42d2c8a",
     "grade": false,
     "grade_id": "cell-edd8978b30775861",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Баллы по ДЗ №3: максимум 25 баллов\n",
    "\n",
    "1. прохождение проверки кода в ноутбуке `knn.ipynb` - **15 баллов**\n",
    "2. обернуть модель UserKnn в сервис и побить безлайн `map@10 = 0.063` на лидерборде. Оценивается только лидерборд, без код ревью - **10 баллов**\n",
    "\n",
    "## Комментарии  \n",
    "\n",
    "- Вы можете переспользовать в своем сервисе код из `userknn.py`, который использован в ноутбуке `knn.ipynb`\n",
    "\n",
    "Как реализовать модель в сервисе: \n",
    "\n",
    "- онлайн вариант: обучаете модель, сохраняете обученную модель (pickle, dill), при запуске сервиса ее поднимаете и запрашиваете рекомендации \"на лету\" \n",
    "- оффлайн вариант: предварительно посчитайте рекомендации для всех пользователей, сохраните и запрашивайте их\n",
    "- в приватном тесте лидерборда есть как холодные, так и горячие пользователи"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
