{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lXUAyD4lMD79"
      },
      "outputs": [],
      "source": [
        "# DSSM is a two-tower neural network architecture for learning semantic representations\n",
        "# of users and items (or queries and documents) in a shared embedding space.\n",
        "# We will use PyTorch to build a DSSM that matches users to items.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "txFQg6ji7C21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kulyaskin_mikhail/ITMO/RecSys/RecSys/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# ----------------------\n",
        "# 2. IMPORTS AND SETUP\n",
        "# ----------------------\n",
        "import os\n",
        "import os.path\n",
        "import requests\n",
        "import zipfile\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1f6caa6903b646e9978230aab8e755ce",
            "b1cd152a8dfc4bac8b02af0109065cbd",
            "044dd95f0ac64bc58af81f99e222d166",
            "cb0860e031754e8a83fc0b56b2e31402",
            "9162e98d7091446ab6711eda100ced59",
            "8157c87a4a4e4a4f8b05aa3f2ebadf31",
            "5609cbd6c5564965bfdf64580278b887",
            "a7ce9010ffd54638b94797325827e4e0",
            "28e13beeb37845238cef064c8d7bd387",
            "9ba94d8beede438a821ccd09c36a0c21",
            "a37863cce5d74db9985fc1694df2a644"
          ]
        },
        "id": "isPdUAJtWnDo",
        "outputId": "eac2feca-7729-49d2-eda6-9d4974c7df9c"
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# 3. DOWNLOAD AND LOAD DATA\n",
        "# ----------------------\n",
        "data_path = os.environ.get(\"DATA_PATH\")\n",
        "\n",
        "if data_path is None:\n",
        "    data_path = \"/Users/kulyaskin_mikhail/ITMO/RecSys/data/data_original\"  # ваш путь к данным до папки data_original включительно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AzgB9X4OYtUm"
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# 4. DATA PREPROCESSING\n",
        "# ----------------------\n",
        "interactions_df = pd.read_csv(os.path.join(data_path, \"interactions.csv\"))\n",
        "users_df = pd.read_csv(os.path.join(data_path, \"users.csv\"))\n",
        "items_df = pd.read_csv(os.path.join(data_path, \"items.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "G8pHaDv3WqxL",
        "outputId": "4c9058d1-7ed3-4a40-d4e1-84f8a2ec7bb6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age_age_18_24</th>\n",
              "      <th>age_age_25_34</th>\n",
              "      <th>age_age_35_44</th>\n",
              "      <th>age_age_45_54</th>\n",
              "      <th>age_age_55_64</th>\n",
              "      <th>age_age_65_inf</th>\n",
              "      <th>income_income_0_20</th>\n",
              "      <th>income_income_150_inf</th>\n",
              "      <th>income_income_20_40</th>\n",
              "      <th>income_income_40_60</th>\n",
              "      <th>income_income_60_90</th>\n",
              "      <th>income_income_90_150</th>\n",
              "      <th>sex_Ж</th>\n",
              "      <th>sex_М</th>\n",
              "      <th>kids_flg_0</th>\n",
              "      <th>kids_flg_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>973171</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>962099</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1047345</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>721985</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>704055</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  age_age_18_24  age_age_25_34  age_age_35_44  age_age_45_54  \\\n",
              "0   973171          False           True          False          False   \n",
              "1   962099           True          False          False          False   \n",
              "2  1047345          False          False          False           True   \n",
              "3   721985          False          False          False           True   \n",
              "4   704055          False          False           True          False   \n",
              "\n",
              "   age_age_55_64  age_age_65_inf  income_income_0_20  income_income_150_inf  \\\n",
              "0          False           False               False                  False   \n",
              "1          False           False               False                  False   \n",
              "2          False           False               False                  False   \n",
              "3          False           False               False                  False   \n",
              "4          False           False               False                  False   \n",
              "\n",
              "   income_income_20_40  income_income_40_60  income_income_60_90  \\\n",
              "0                False                False                 True   \n",
              "1                 True                False                False   \n",
              "2                False                 True                False   \n",
              "3                 True                False                False   \n",
              "4                False                False                 True   \n",
              "\n",
              "   income_income_90_150  sex_Ж  sex_М  kids_flg_0  kids_flg_1  \n",
              "0                 False  False   True       False        True  \n",
              "1                 False  False   True        True       False  \n",
              "2                 False   True  False        True       False  \n",
              "3                 False   True  False        True       False  \n",
              "4                 False   True  False        True       False  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_cat_feats = [\"age\", \"income\", \"sex\", \"kids_flg\"]\n",
        "# из исходного датафрейма оставим только item_id - этот признак нам понадобится позже\n",
        "# для того, чтобы маппить айтемы из датафрейма с фильмами с айтемами\n",
        "# из датафрейма с взаимодействиями\n",
        "users_ohe_df = users_df.user_id\n",
        "for feat in user_cat_feats:\n",
        "    # получаем датафрейм с one-hot encoding для каждой категориальной фичи\n",
        "    ohe_feat_df = pd.get_dummies(users_df[feat], prefix=feat)\n",
        "    # конкатенируем ohe-hot датафрейм с датафреймом,\n",
        "    # который мы получили на предыдущем шаге\n",
        "    users_ohe_df = pd.concat([users_ohe_df, ohe_feat_df], axis=1)\n",
        "\n",
        "users_ohe_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "hprE3sH1WqbR",
        "outputId": "74cd20ff-96ca-410e-92f4-1b9ed98e2915"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>content_type_film</th>\n",
              "      <th>content_type_series</th>\n",
              "      <th>release_year_1897.0</th>\n",
              "      <th>release_year_1916.0</th>\n",
              "      <th>release_year_1917.0</th>\n",
              "      <th>release_year_1918.0</th>\n",
              "      <th>release_year_1920.0</th>\n",
              "      <th>release_year_1921.0</th>\n",
              "      <th>release_year_1922.0</th>\n",
              "      <th>...</th>\n",
              "      <th>directors_Яннике Систад Якобсен</th>\n",
              "      <th>directors_Янус Мец</th>\n",
              "      <th>directors_Ярив Хоровиц</th>\n",
              "      <th>directors_Ярон Зильберман</th>\n",
              "      <th>directors_Ярополк Лапшин</th>\n",
              "      <th>directors_Ярослав Лупий</th>\n",
              "      <th>directors_Ярроу Чейни, Скотт Моужер</th>\n",
              "      <th>directors_Ясина Сезар</th>\n",
              "      <th>directors_Ясуоми Умэцу</th>\n",
              "      <th>directors_сения Завьялова</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10711</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2508</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10716</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7868</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16268</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8814 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   item_id  content_type_film  content_type_series  release_year_1897.0  \\\n",
              "0    10711               True                False                False   \n",
              "1     2508               True                False                False   \n",
              "2    10716               True                False                False   \n",
              "3     7868               True                False                False   \n",
              "4    16268               True                False                False   \n",
              "\n",
              "   release_year_1916.0  release_year_1917.0  release_year_1918.0  \\\n",
              "0                False                False                False   \n",
              "1                False                False                False   \n",
              "2                False                False                False   \n",
              "3                False                False                False   \n",
              "4                False                False                False   \n",
              "\n",
              "   release_year_1920.0  release_year_1921.0  release_year_1922.0  ...  \\\n",
              "0                False                False                False  ...   \n",
              "1                False                False                False  ...   \n",
              "2                False                False                False  ...   \n",
              "3                False                False                False  ...   \n",
              "4                False                False                False  ...   \n",
              "\n",
              "   directors_Яннике Систад Якобсен  directors_Янус Мец  \\\n",
              "0                            False               False   \n",
              "1                            False               False   \n",
              "2                            False               False   \n",
              "3                            False               False   \n",
              "4                            False               False   \n",
              "\n",
              "   directors_Ярив Хоровиц  directors_Ярон Зильберман  \\\n",
              "0                   False                      False   \n",
              "1                   False                      False   \n",
              "2                   False                      False   \n",
              "3                   False                      False   \n",
              "4                   False                      False   \n",
              "\n",
              "   directors_Ярополк Лапшин  directors_Ярослав Лупий  \\\n",
              "0                     False                    False   \n",
              "1                     False                    False   \n",
              "2                     False                    False   \n",
              "3                     False                    False   \n",
              "4                     False                    False   \n",
              "\n",
              "   directors_Ярроу Чейни, Скотт Моужер  directors_Ясина Сезар  \\\n",
              "0                                False                  False   \n",
              "1                                False                  False   \n",
              "2                                False                  False   \n",
              "3                                False                  False   \n",
              "4                                False                  False   \n",
              "\n",
              "   directors_Ясуоми Умэцу  directors_сения Завьялова  \n",
              "0                   False                      False  \n",
              "1                   False                      False  \n",
              "2                   False                      False  \n",
              "3                   False                      False  \n",
              "4                   False                      False  \n",
              "\n",
              "[5 rows x 8814 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_cat_feats = ['content_type', 'release_year',\n",
        "                  'for_kids', 'age_rating',\n",
        "                  'studios', 'countries', 'directors']\n",
        "\n",
        "items_ohe_df = items_df.item_id\n",
        "\n",
        "for feat in item_cat_feats:\n",
        "    ohe_feat_df = pd.get_dummies(items_df[feat], prefix=feat)\n",
        "    items_ohe_df = pd.concat([items_ohe_df, ohe_feat_df], axis=1)\n",
        "\n",
        "items_ohe_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oNLfVeMW1T5",
        "outputId": "43111d7f-adc7-45f5-e43e-f6dd8f2f94f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N users before: 962179\n",
            "N items before: 15706\n",
            "\n",
            "N users after: 79515\n",
            "N items after: 6901\n"
          ]
        }
      ],
      "source": [
        "print(f\"N users before: {interactions_df.user_id.nunique()}\")\n",
        "print(f\"N items before: {interactions_df.item_id.nunique()}\\n\")\n",
        "\n",
        "# отфильтруем все события взаимодействий, в которых пользователь посмотрел\n",
        "# фильм менее чем на 10 процентов\n",
        "interactions_df = interactions_df[interactions_df.watched_pct > 10]\n",
        "\n",
        "# соберем всех пользователей, которые посмотрели\n",
        "# больше 10 фильмов (можете выбрать другой порог)\n",
        "valid_users = []\n",
        "\n",
        "c = Counter(interactions_df.user_id)\n",
        "for user_id, entries in c.most_common():\n",
        "    if entries > 10:\n",
        "        valid_users.append(user_id)\n",
        "\n",
        "# и соберем все фильмы, которые посмотрели больше 10 пользователей\n",
        "valid_items = []\n",
        "\n",
        "c = Counter(interactions_df.item_id)\n",
        "for item_id, entries in c.most_common():\n",
        "    if entries > 10:\n",
        "        valid_items.append(item_id)\n",
        "\n",
        "# отбросим непопулярные фильмы и неактивных юзеров\n",
        "interactions_df = interactions_df[interactions_df.user_id.isin(valid_users)]\n",
        "interactions_df = interactions_df[interactions_df.item_id.isin(valid_items)]\n",
        "\n",
        "print(f\"N users after: {interactions_df.user_id.nunique()}\")\n",
        "print(f\"N items after: {interactions_df.item_id.nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCIle0WUW1LW",
        "outputId": "a6c68931-04a4-4caf-c5b5-fec4741ead2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65974\n",
            "6901\n"
          ]
        }
      ],
      "source": [
        "common_users = set(interactions_df.user_id.unique()).intersection(set(users_ohe_df.user_id.unique()))\n",
        "common_items = set(interactions_df.item_id.unique()).intersection(set(items_ohe_df.item_id.unique()))\n",
        "\n",
        "print(len(common_users))\n",
        "print(len(common_items))\n",
        "\n",
        "interactions_df = interactions_df[interactions_df.item_id.isin(common_items)]\n",
        "interactions_df = interactions_df[interactions_df.user_id.isin(common_users)]\n",
        "\n",
        "items_ohe_df = items_ohe_df[items_ohe_df.item_id.isin(common_items)]\n",
        "users_ohe_df = users_ohe_df[users_ohe_df.user_id.isin(common_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65974\n",
            "6897\n"
          ]
        }
      ],
      "source": [
        "common_users = set(interactions_df.user_id.unique()).intersection(set(users_ohe_df.user_id.unique()))\n",
        "common_items = set(interactions_df.item_id.unique()).intersection(set(items_ohe_df.item_id.unique()))\n",
        "\n",
        "print(len(common_users))\n",
        "print(len(common_items))\n",
        "\n",
        "interactions_df = interactions_df[interactions_df.item_id.isin(common_items)]\n",
        "interactions_df = interactions_df[interactions_df.user_id.isin(common_users)]\n",
        "\n",
        "items_ohe_df = items_ohe_df[items_ohe_df.item_id.isin(common_items)]\n",
        "users_ohe_df = users_ohe_df[users_ohe_df.user_id.isin(common_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "WYzEnGc0W_Po",
        "outputId": "67499b7a-dd53-4343-f50c-b3546add5b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>last_watch_dt</th>\n",
              "      <th>total_dur</th>\n",
              "      <th>watched_pct</th>\n",
              "      <th>uid</th>\n",
              "      <th>iid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176549</td>\n",
              "      <td>9506</td>\n",
              "      <td>2021-05-11</td>\n",
              "      <td>4250</td>\n",
              "      <td>72.0</td>\n",
              "      <td>10616</td>\n",
              "      <td>3944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>699317</td>\n",
              "      <td>1659</td>\n",
              "      <td>2021-05-29</td>\n",
              "      <td>8317</td>\n",
              "      <td>100.0</td>\n",
              "      <td>42131</td>\n",
              "      <td>675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1016458</td>\n",
              "      <td>354</td>\n",
              "      <td>2021-08-14</td>\n",
              "      <td>1672</td>\n",
              "      <td>25.0</td>\n",
              "      <td>61024</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>884009</td>\n",
              "      <td>693</td>\n",
              "      <td>2021-08-04</td>\n",
              "      <td>703</td>\n",
              "      <td>14.0</td>\n",
              "      <td>53150</td>\n",
              "      <td>279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5324</td>\n",
              "      <td>8437</td>\n",
              "      <td>2021-04-18</td>\n",
              "      <td>6598</td>\n",
              "      <td>92.0</td>\n",
              "      <td>310</td>\n",
              "      <td>3485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id  item_id last_watch_dt  total_dur  watched_pct    uid   iid\n",
              "0    176549     9506    2021-05-11       4250         72.0  10616  3944\n",
              "1    699317     1659    2021-05-29       8317        100.0  42131   675\n",
              "6   1016458      354    2021-08-14       1672         25.0  61024   139\n",
              "7    884009      693    2021-08-04        703         14.0  53150   279\n",
              "14     5324     8437    2021-04-18       6598         92.0    310  3485"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions_df[\"uid\"] = interactions_df[\"user_id\"].astype(\"category\")\n",
        "interactions_df[\"uid\"] = interactions_df[\"uid\"].cat.codes\n",
        "\n",
        "interactions_df[\"iid\"] = interactions_df[\"item_id\"].astype(\"category\")\n",
        "interactions_df[\"iid\"] = interactions_df[\"iid\"].cat.codes\n",
        "\n",
        "print(sorted(interactions_df.iid.unique())[:5])\n",
        "print(sorted(interactions_df.uid.unique())[:5])\n",
        "interactions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kJDeuDDpW_Il"
      },
      "outputs": [],
      "source": [
        "interactions_vec = np.zeros((interactions_df.uid.nunique(),\n",
        "                             interactions_df.iid.nunique()))\n",
        "\n",
        "for user_id, item_id in zip(interactions_df.uid, interactions_df.iid):\n",
        "    interactions_vec[user_id, item_id] += 1\n",
        "\n",
        "\n",
        "res = interactions_vec.sum(axis=1)\n",
        "for i in range(len(interactions_vec)):\n",
        "    interactions_vec[i] /= res[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJfwwkAtXL5S",
        "outputId": "624fdfc2-ba9d-42c1-8d0a-f9d40cfb3e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6897\n",
            "6897\n",
            "65974\n",
            "65974\n",
            "set()\n"
          ]
        }
      ],
      "source": [
        "print(interactions_df.item_id.nunique())\n",
        "print(items_ohe_df.item_id.nunique())\n",
        "print(interactions_df.user_id.nunique())\n",
        "print(users_ohe_df.user_id.nunique())\n",
        "\n",
        "print(set(items_ohe_df.item_id.unique()) - set(interactions_df.item_id.unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iQQYK7_XXL0E"
      },
      "outputs": [],
      "source": [
        "iid_to_item_id = interactions_df[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"iid\").to_dict()[\"item_id\"]\n",
        "item_id_to_iid = interactions_df[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"item_id\").to_dict()[\"iid\"]\n",
        "\n",
        "uid_to_user_id = interactions_df[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"uid\").to_dict()[\"user_id\"]\n",
        "user_id_to_uid = interactions_df[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"user_id\").to_dict()[\"uid\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cCtzTnnjXU2v"
      },
      "outputs": [],
      "source": [
        "items_ohe_df[\"iid\"] = items_ohe_df[\"item_id\"].apply(lambda x: item_id_to_iid[x])\n",
        "items_ohe_df = items_ohe_df.set_index(\"iid\")\n",
        "\n",
        "users_ohe_df[\"uid\"] = users_ohe_df[\"user_id\"].apply(lambda x: user_id_to_uid[x])\n",
        "users_ohe_df = users_ohe_df.set_index(\"uid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pmyydKsXUvf",
        "outputId": "8ab36bf9-3a81-4d96-c9a1-2332da0f1ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N_FACTORS: 32\n",
            "ITEM_MODEL_SHAPE: (8813,)\n",
            "USER_META_MODEL_SHAPE: (16,)\n",
            "USER_INTERACTION_MODEL_SHAPE: (6897,)\n"
          ]
        }
      ],
      "source": [
        "N_FACTORS = 32\n",
        "\n",
        "# в датасетах есть столбец user_id/item_id, помним, что он не является фичей для обучения!\n",
        "ITEM_MODEL_SHAPE = (items_ohe_df.drop([\"item_id\"], axis=1).shape[1], )\n",
        "USER_META_MODEL_SHAPE = (users_ohe_df.drop([\"user_id\"], axis=1).shape[1], )\n",
        "\n",
        "USER_INTERACTION_MODEL_SHAPE = (interactions_vec.shape[1], )\n",
        "\n",
        "print(f\"N_FACTORS: {N_FACTORS}\")\n",
        "print(f\"ITEM_MODEL_SHAPE: {ITEM_MODEL_SHAPE}\")\n",
        "print(f\"USER_META_MODEL_SHAPE: {USER_META_MODEL_SHAPE}\")\n",
        "print(f\"USER_INTERACTION_MODEL_SHAPE: {USER_INTERACTION_MODEL_SHAPE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3MbRSkAaX9a2"
      },
      "outputs": [],
      "source": [
        "class ItemModel(nn.Module):\n",
        "    def __init__(self, n_factors=N_FACTORS, nhead=8, num_layers=2, dropout=0.2):\n",
        "        super(ItemModel, self).__init__()\n",
        "        self.input_proj = nn.Linear(ITEM_MODEL_SHAPE[0], n_factors)\n",
        "        self.input_norm = nn.LayerNorm(n_factors)\n",
        "        self.input_dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=n_factors, nhead=nhead, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        self.output_norm = nn.LayerNorm(n_factors)\n",
        "        self.output_dropout = nn.Dropout(dropout)\n",
        "        self.output_proj = nn.Linear(n_factors, n_factors)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Проекция входных признаков до размера n_factors\n",
        "        x = self.input_proj(x)\n",
        "        x = self.input_norm(x)\n",
        "        x = self.input_dropout(x)\n",
        "        \n",
        "        # Добавляем фиктивную размерность последовательности (sequence length = 1)\n",
        "        x = x.unsqueeze(1)\n",
        "        # Трансформер ожидает формат [seq_len, batch_size, n_factors]\n",
        "        x = x.transpose(0, 1)\n",
        "        # Применяем Transformer Encoder\n",
        "        x = self.transformer_encoder(x)\n",
        "        # Возвращаем в формат [batch_size, n_factors]\n",
        "        x = x.transpose(0, 1).squeeze(1)\n",
        "        \n",
        "        x = self.output_norm(x)\n",
        "        x = self.output_dropout(x)\n",
        "        # Финальная проекция\n",
        "        x = self.output_proj(x)\n",
        "        return x\n",
        "\n",
        "# Define the user model\n",
        "class UserModel(nn.Module):\n",
        "    def __init__(self, n_factors=N_FACTORS, nhead=8, num_layers=2, dropout=0.2):\n",
        "        super(UserModel, self).__init__()\n",
        "        # Проекция метаданных пользователя\n",
        "        self.meta_proj = nn.Linear(USER_META_MODEL_SHAPE[0], n_factors)\n",
        "        self.meta_norm = nn.LayerNorm(n_factors)\n",
        "        self.meta_dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # Проекция взаимодействий пользователя\n",
        "        self.interaction_proj = nn.Linear(USER_INTERACTION_MODEL_SHAPE[0], n_factors)\n",
        "        self.interaction_norm = nn.LayerNorm(n_factors)\n",
        "        self.interaction_dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # Трансформеры для метаданных и взаимодействий\n",
        "        encoder_layer_meta = nn.TransformerEncoderLayer(d_model=n_factors, nhead=nhead, dropout=dropout)\n",
        "        self.transformer_encoder_meta = nn.TransformerEncoder(encoder_layer_meta, num_layers=num_layers)\n",
        "        \n",
        "        encoder_layer_inter = nn.TransformerEncoderLayer(d_model=n_factors, nhead=nhead, dropout=dropout)\n",
        "        self.transformer_encoder_inter = nn.TransformerEncoder(encoder_layer_inter, num_layers=num_layers)\n",
        "        \n",
        "        # Нормализация и Dropout для выходных представлений\n",
        "        self.meta_out_norm = nn.LayerNorm(n_factors)\n",
        "        self.inter_out_norm = nn.LayerNorm(n_factors)\n",
        "        \n",
        "        # Финальная проекция объединенных представлений\n",
        "        self.final_dropout = nn.Dropout(dropout)\n",
        "        self.output_proj = nn.Linear(n_factors * 2, n_factors)\n",
        "        \n",
        "    def forward(self, meta, interaction):\n",
        "        # Проекция метаданных\n",
        "        meta = self.meta_proj(meta)\n",
        "        meta = self.meta_norm(meta)\n",
        "        meta = self.meta_dropout(meta)\n",
        "        \n",
        "        # Добавляем фиктивную размерность последовательности\n",
        "        meta = meta.unsqueeze(1)\n",
        "        # Трансформер ожидает формат [seq_len, batch_size, n_factors]\n",
        "        meta = meta.transpose(0, 1)\n",
        "        # Применяем Transformer Encoder\n",
        "        meta = self.transformer_encoder_meta(meta)\n",
        "        # Возвращаем в формат [batch_size, n_factors]\n",
        "        meta = meta.transpose(0, 1).squeeze(1)\n",
        "        meta = self.meta_out_norm(meta)\n",
        "        \n",
        "        # Аналогично для взаимодействий\n",
        "        interaction = self.interaction_proj(interaction)\n",
        "        interaction = self.interaction_norm(interaction)\n",
        "        interaction = self.interaction_dropout(interaction)\n",
        "        \n",
        "        interaction = interaction.unsqueeze(1)\n",
        "        interaction = interaction.transpose(0, 1)\n",
        "        interaction = self.transformer_encoder_inter(interaction)\n",
        "        interaction = interaction.transpose(0, 1).squeeze(1)\n",
        "        interaction = self.inter_out_norm(interaction)\n",
        "        \n",
        "        # Объединяем представления и применяем финальную проекцию\n",
        "        x = torch.cat([meta, interaction], dim=1)\n",
        "        x = self.final_dropout(x)\n",
        "        x = self.output_proj(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# изменяем loss на triplet loss с расчетом косинусной близости\n",
        "triplet_loss = nn.TripletMarginWithDistanceLoss(\n",
        "    distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y),\n",
        "    margin=0.4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VVB9nqElYDlz"
      },
      "outputs": [],
      "source": [
        "# Define the dataset\n",
        "class RecSysDataset(Dataset):\n",
        "    def __init__(self, items, users, interactions):\n",
        "        self.items = items\n",
        "        self.users = users\n",
        "        self.interactions = interactions\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.interactions.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        uid = idx\n",
        "        pos_i = np.random.choice(range(self.interactions.shape[1]), p=self.interactions[uid])\n",
        "        neg_i = np.random.choice(range(self.interactions.shape[1]))\n",
        "        uid_meta = self.users.iloc[uid].values\n",
        "        uid_interaction = self.interactions[uid]\n",
        "        pos = self.items.iloc[pos_i].values\n",
        "        neg = self.items.iloc[neg_i].values\n",
        "        return torch.tensor(uid_meta, dtype=torch.float32), torch.tensor(uid_interaction, dtype=torch.float32), torch.tensor(pos, dtype=torch.float32), torch.tensor(neg, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Rk0-FV0YMGMr"
      },
      "outputs": [],
      "source": [
        "# Initialize the models, optimizer, and dataset\n",
        "i2v = ItemModel()\n",
        "u2v = UserModel()\n",
        "optimizer = optim.Adam(list(i2v.parameters()) + list(u2v.parameters()), lr=0.001)\n",
        "dataset = RecSysDataset(items=items_ohe_df.drop([\"item_id\"], axis=1), users=users_ohe_df.drop([\"user_id\"], axis=1), interactions=interactions_vec)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "U_B6mNCsY1KJ"
      },
      "outputs": [],
      "source": [
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMd-V8HpMGJC",
        "outputId": "9af2c2a4-6d2c-4af7-f811-1482fc2bfb5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch Loss: 0.4215570390224457\n",
            "Epoch 1, Batch Loss: 0.3735736608505249\n",
            "Epoch 1, Batch Loss: 0.3773857355117798\n",
            "Epoch 1, Batch Loss: 0.38890400528907776\n",
            "Epoch 1, Batch Loss: 0.36707454919815063\n",
            "Epoch 1, Batch Loss: 0.43003368377685547\n",
            "Epoch 1, Batch Loss: 0.39561575651168823\n",
            "Epoch 1, Batch Loss: 0.44626086950302124\n",
            "Epoch 1, Batch Loss: 0.39964061975479126\n",
            "Epoch 1, Batch Loss: 0.38553956151008606\n",
            "Epoch 1, Batch Loss: 0.4067000448703766\n",
            "Epoch 1, Batch Loss: 0.40201669931411743\n",
            "Epoch 1, Batch Loss: 0.3312397599220276\n",
            "Epoch 1, Batch Loss: 0.3503345847129822\n",
            "Epoch 1, Batch Loss: 0.33818185329437256\n",
            "Epoch 1, Batch Loss: 0.3728874921798706\n",
            "Epoch 1, Batch Loss: 0.36076509952545166\n",
            "Epoch 1, Batch Loss: 0.29485899209976196\n",
            "Epoch 1, Batch Loss: 0.28871339559555054\n",
            "Epoch 1, Batch Loss: 0.3253413438796997\n",
            "Epoch 1, Batch Loss: 0.3198901116847992\n",
            "Epoch 1, Batch Loss: 0.33764833211898804\n",
            "Epoch 1, Batch Loss: 0.3641596734523773\n",
            "Epoch 1, Batch Loss: 0.253708153963089\n",
            "Epoch 1, Batch Loss: 0.40646713972091675\n",
            "Epoch 1, Batch Loss: 0.29971829056739807\n",
            "Epoch 1, Batch Loss: 0.29847466945648193\n",
            "Epoch 1, Batch Loss: 0.3691886067390442\n",
            "Epoch 1, Batch Loss: 0.3819887638092041\n",
            "Epoch 1, Batch Loss: 0.3179275393486023\n",
            "Epoch 1, Batch Loss: 0.33322399854660034\n",
            "Epoch 1, Batch Loss: 0.2657250761985779\n",
            "Epoch 1, Batch Loss: 0.3423157334327698\n",
            "Epoch 1, Batch Loss: 0.30363768339157104\n",
            "Epoch 1, Batch Loss: 0.2630588412284851\n",
            "Epoch 1, Batch Loss: 0.30090808868408203\n",
            "Epoch 1, Batch Loss: 0.27997031807899475\n",
            "Epoch 1, Batch Loss: 0.3071511685848236\n",
            "Epoch 1, Batch Loss: 0.32072675228118896\n",
            "Epoch 1, Batch Loss: 0.3226814568042755\n",
            "Epoch 1, Batch Loss: 0.30457741022109985\n",
            "Epoch 1, Batch Loss: 0.2692536413669586\n",
            "Epoch 1, Batch Loss: 0.3434167504310608\n",
            "Epoch 1, Batch Loss: 0.29134297370910645\n",
            "Epoch 1, Batch Loss: 0.30589038133621216\n",
            "Epoch 1, Batch Loss: 0.2680237889289856\n",
            "Epoch 1, Batch Loss: 0.25412893295288086\n",
            "Epoch 1, Batch Loss: 0.3312194049358368\n",
            "Epoch 1, Batch Loss: 0.20941823720932007\n",
            "Epoch 1, Batch Loss: 0.26263701915740967\n",
            "Epoch 1, Batch Loss: 0.2895192503929138\n",
            "Epoch 1, Batch Loss: 0.26341575384140015\n",
            "Epoch 1, Batch Loss: 0.28887179493904114\n",
            "Epoch 1, Batch Loss: 0.3421286940574646\n",
            "Epoch 1, Batch Loss: 0.29418644309043884\n",
            "Epoch 1, Batch Loss: 0.25562599301338196\n",
            "Epoch 1, Batch Loss: 0.23395591974258423\n",
            "Epoch 1, Batch Loss: 0.2845391035079956\n",
            "Epoch 1, Batch Loss: 0.27680328488349915\n",
            "Epoch 1, Batch Loss: 0.2534862756729126\n",
            "Epoch 1, Batch Loss: 0.22636909782886505\n",
            "Epoch 1, Batch Loss: 0.27427351474761963\n",
            "Epoch 1, Batch Loss: 0.28799960017204285\n",
            "Epoch 1, Batch Loss: 0.33949214220046997\n",
            "Epoch 1, Batch Loss: 0.3284447193145752\n",
            "Epoch 1, Batch Loss: 0.29827380180358887\n",
            "Epoch 1, Batch Loss: 0.27899789810180664\n",
            "Epoch 1, Batch Loss: 0.32523298263549805\n",
            "Epoch 1, Batch Loss: 0.24388864636421204\n",
            "Epoch 1, Batch Loss: 0.2830984592437744\n",
            "Epoch 1, Batch Loss: 0.2233373075723648\n",
            "Epoch 1, Batch Loss: 0.2745654284954071\n",
            "Epoch 1, Batch Loss: 0.2646656930446625\n",
            "Epoch 1, Batch Loss: 0.24773718416690826\n",
            "Epoch 1, Batch Loss: 0.19863685965538025\n",
            "Epoch 1, Batch Loss: 0.31033679842948914\n",
            "Epoch 1, Batch Loss: 0.2811436057090759\n",
            "Epoch 1, Batch Loss: 0.31597790122032166\n",
            "Epoch 1, Batch Loss: 0.3477960228919983\n",
            "Epoch 1, Batch Loss: 0.22938722372055054\n",
            "Epoch 1, Batch Loss: 0.2231288105249405\n",
            "Epoch 1, Batch Loss: 0.2814863324165344\n",
            "Epoch 1, Batch Loss: 0.3167053461074829\n",
            "Epoch 1, Batch Loss: 0.22771061956882477\n",
            "Epoch 1, Batch Loss: 0.2521210014820099\n",
            "Epoch 1, Batch Loss: 0.2660544514656067\n",
            "Epoch 1, Batch Loss: 0.24075248837471008\n",
            "Epoch 1, Batch Loss: 0.2424149513244629\n",
            "Epoch 1, Batch Loss: 0.25542986392974854\n",
            "Epoch 1, Batch Loss: 0.21777474880218506\n",
            "Epoch 1, Batch Loss: 0.25405019521713257\n",
            "Epoch 1, Batch Loss: 0.17815127968788147\n",
            "Epoch 1, Batch Loss: 0.2662183344364166\n",
            "Epoch 1, Batch Loss: 0.20086917281150818\n",
            "Epoch 1, Batch Loss: 0.21440333127975464\n",
            "Epoch 1, Batch Loss: 0.18615871667861938\n",
            "Epoch 1, Batch Loss: 0.1996147632598877\n",
            "Epoch 1, Batch Loss: 0.2209574580192566\n",
            "Epoch 1, Batch Loss: 0.22632020711898804\n",
            "Epoch 1, Batch Loss: 0.2488941252231598\n",
            "Epoch 1, Batch Loss: 0.20202429592609406\n",
            "Epoch 1, Batch Loss: 0.2838829755783081\n",
            "Epoch 1, Batch Loss: 0.2026365101337433\n",
            "Epoch 1, Batch Loss: 0.2715550363063812\n",
            "Epoch 1, Batch Loss: 0.2125289887189865\n",
            "Epoch 1, Batch Loss: 0.1653827577829361\n",
            "Epoch 1, Batch Loss: 0.26734310388565063\n",
            "Epoch 1, Batch Loss: 0.16542644798755646\n",
            "Epoch 1, Batch Loss: 0.2529389560222626\n",
            "Epoch 1, Batch Loss: 0.30197274684906006\n",
            "Epoch 1, Batch Loss: 0.18650291860103607\n",
            "Epoch 1, Batch Loss: 0.22534304857254028\n",
            "Epoch 1, Batch Loss: 0.21403731405735016\n",
            "Epoch 1, Batch Loss: 0.2859075367450714\n",
            "Epoch 1, Batch Loss: 0.2776637673377991\n",
            "Epoch 1, Batch Loss: 0.23867832124233246\n",
            "Epoch 1, Batch Loss: 0.21987149119377136\n",
            "Epoch 1, Batch Loss: 0.2390446960926056\n",
            "Epoch 1, Batch Loss: 0.24888469278812408\n",
            "Epoch 1, Batch Loss: 0.2246941775083542\n",
            "Epoch 1, Batch Loss: 0.21628481149673462\n",
            "Epoch 1, Batch Loss: 0.17740163207054138\n",
            "Epoch 1, Batch Loss: 0.22396592795848846\n",
            "Epoch 1, Batch Loss: 0.22646157443523407\n",
            "Epoch 1, Batch Loss: 0.2533735930919647\n",
            "Epoch 1, Batch Loss: 0.19452820718288422\n",
            "Epoch 1, Batch Loss: 0.22828271985054016\n",
            "Epoch 1, Batch Loss: 0.22032727301120758\n",
            "Epoch 1, Batch Loss: 0.2696046531200409\n",
            "Epoch 1, Batch Loss: 0.18711113929748535\n",
            "Epoch 1, Batch Loss: 0.22566065192222595\n",
            "Epoch 1, Batch Loss: 0.253291517496109\n",
            "Epoch 1, Batch Loss: 0.20514079928398132\n",
            "Epoch 1, Batch Loss: 0.23616331815719604\n",
            "Epoch 1, Batch Loss: 0.1824386715888977\n",
            "Epoch 1, Batch Loss: 0.1771162897348404\n",
            "Epoch 1, Batch Loss: 0.16509909927845\n",
            "Epoch 1, Batch Loss: 0.25112366676330566\n",
            "Epoch 1, Batch Loss: 0.2865417003631592\n",
            "Epoch 1, Batch Loss: 0.16718848049640656\n",
            "Epoch 1, Batch Loss: 0.19511765241622925\n",
            "Epoch 1, Batch Loss: 0.22492557764053345\n",
            "Epoch 1, Batch Loss: 0.21397115290164948\n",
            "Epoch 1, Batch Loss: 0.2223832905292511\n",
            "Epoch 1, Batch Loss: 0.1532420665025711\n",
            "Epoch 1, Batch Loss: 0.17643651366233826\n",
            "Epoch 1, Batch Loss: 0.21269428730010986\n",
            "Epoch 1, Batch Loss: 0.23823942244052887\n",
            "Epoch 1, Batch Loss: 0.18666672706604004\n",
            "Epoch 1, Batch Loss: 0.2013513296842575\n",
            "Epoch 1, Batch Loss: 0.2720796465873718\n",
            "Epoch 1, Batch Loss: 0.20287688076496124\n",
            "Epoch 1, Batch Loss: 0.14953236281871796\n",
            "Epoch 1, Batch Loss: 0.1804821789264679\n",
            "Epoch 1, Batch Loss: 0.20258638262748718\n",
            "Epoch 1, Batch Loss: 0.22999118268489838\n",
            "Epoch 1, Batch Loss: 0.16366180777549744\n",
            "Epoch 1, Batch Loss: 0.20182311534881592\n",
            "Epoch 1, Batch Loss: 0.19753900170326233\n",
            "Epoch 1, Batch Loss: 0.15665438771247864\n",
            "Epoch 1, Batch Loss: 0.1909257173538208\n",
            "Epoch 1, Batch Loss: 0.2677004337310791\n",
            "Epoch 1, Batch Loss: 0.19538132846355438\n",
            "Epoch 1, Batch Loss: 0.2035946547985077\n",
            "Epoch 1, Batch Loss: 0.19248245656490326\n",
            "Epoch 1, Batch Loss: 0.1818770468235016\n",
            "Epoch 1, Batch Loss: 0.22993017733097076\n",
            "Epoch 1, Batch Loss: 0.24103474617004395\n",
            "Epoch 1, Batch Loss: 0.2200293093919754\n",
            "Epoch 1, Batch Loss: 0.2621610164642334\n",
            "Epoch 1, Batch Loss: 0.2759024500846863\n",
            "Epoch 1, Batch Loss: 0.13693776726722717\n",
            "Epoch 1, Batch Loss: 0.21062207221984863\n",
            "Epoch 1, Batch Loss: 0.19615402817726135\n",
            "Epoch 1, Batch Loss: 0.1777603030204773\n",
            "Epoch 1, Batch Loss: 0.2264036238193512\n",
            "Epoch 1, Batch Loss: 0.1702478528022766\n",
            "Epoch 1, Batch Loss: 0.1988048553466797\n",
            "Epoch 1, Batch Loss: 0.19171349704265594\n",
            "Epoch 1, Batch Loss: 0.19522863626480103\n",
            "Epoch 1, Batch Loss: 0.1773403435945511\n",
            "Epoch 1, Batch Loss: 0.18798300623893738\n",
            "Epoch 1, Batch Loss: 0.19567391276359558\n",
            "Epoch 1, Batch Loss: 0.21899203956127167\n",
            "Epoch 1, Batch Loss: 0.1495920866727829\n",
            "Epoch 1, Batch Loss: 0.21278738975524902\n",
            "Epoch 1, Batch Loss: 0.15662971138954163\n",
            "Epoch 1, Batch Loss: 0.22899651527404785\n",
            "Epoch 1, Batch Loss: 0.2428957223892212\n",
            "Epoch 1, Batch Loss: 0.2311498075723648\n",
            "Epoch 1, Batch Loss: 0.21560655534267426\n",
            "Epoch 1, Batch Loss: 0.22716517746448517\n",
            "Epoch 1, Batch Loss: 0.2618599236011505\n",
            "Epoch 1, Batch Loss: 0.1781172901391983\n",
            "Epoch 1, Batch Loss: 0.2162744253873825\n",
            "Epoch 1, Batch Loss: 0.1857202649116516\n",
            "Epoch 1, Batch Loss: 0.2787441909313202\n",
            "Epoch 1, Batch Loss: 0.18036986887454987\n",
            "Epoch 1, Batch Loss: 0.14495663344860077\n",
            "Epoch 1, Batch Loss: 0.16712740063667297\n",
            "Epoch 1, Batch Loss: 0.2251185178756714\n",
            "Epoch 1, Batch Loss: 0.2049831748008728\n",
            "Epoch 1, Batch Loss: 0.1582210510969162\n",
            "Epoch 1, Batch Loss: 0.1850433200597763\n",
            "Epoch 1, Batch Loss: 0.28580978512763977\n",
            "Epoch 1, Batch Loss: 0.25606128573417664\n",
            "Epoch 1, Batch Loss: 0.1507967710494995\n",
            "Epoch 1, Batch Loss: 0.16491849720478058\n",
            "Epoch 1, Batch Loss: 0.2815202474594116\n",
            "Epoch 1, Batch Loss: 0.19331535696983337\n",
            "Epoch 1, Batch Loss: 0.24668221175670624\n",
            "Epoch 1, Batch Loss: 0.19540315866470337\n",
            "Epoch 1, Batch Loss: 0.17946220934391022\n",
            "Epoch 1, Batch Loss: 0.27655160427093506\n",
            "Epoch 1, Batch Loss: 0.20556947588920593\n",
            "Epoch 1, Batch Loss: 0.20645545423030853\n",
            "Epoch 1, Batch Loss: 0.12042847275733948\n",
            "Epoch 1, Batch Loss: 0.13168232142925262\n",
            "Epoch 1, Batch Loss: 0.20604854822158813\n",
            "Epoch 1, Batch Loss: 0.23201656341552734\n",
            "Epoch 1, Batch Loss: 0.20641884207725525\n",
            "Epoch 1, Batch Loss: 0.2310677170753479\n",
            "Epoch 1, Batch Loss: 0.19569022953510284\n",
            "Epoch 1, Batch Loss: 0.23568445444107056\n",
            "Epoch 1, Batch Loss: 0.17765283584594727\n",
            "Epoch 1, Batch Loss: 0.2008591890335083\n",
            "Epoch 1, Batch Loss: 0.14394822716712952\n",
            "Epoch 1, Batch Loss: 0.19400155544281006\n",
            "Epoch 1, Batch Loss: 0.17802715301513672\n",
            "Epoch 1, Batch Loss: 0.220512256026268\n",
            "Epoch 1, Batch Loss: 0.18854157626628876\n",
            "Epoch 1, Batch Loss: 0.16021421551704407\n",
            "Epoch 1, Batch Loss: 0.1931111067533493\n",
            "Epoch 1, Batch Loss: 0.17313078045845032\n",
            "Epoch 1, Batch Loss: 0.19470930099487305\n",
            "Epoch 1, Batch Loss: 0.26684653759002686\n",
            "Epoch 1, Batch Loss: 0.18146148324012756\n",
            "Epoch 1, Batch Loss: 0.24063929915428162\n",
            "Epoch 1, Batch Loss: 0.19928815960884094\n",
            "Epoch 1, Batch Loss: 0.20743969082832336\n",
            "Epoch 1, Batch Loss: 0.2004190981388092\n",
            "Epoch 1, Batch Loss: 0.21982356905937195\n",
            "Epoch 1, Batch Loss: 0.19717156887054443\n",
            "Epoch 1, Batch Loss: 0.2333332896232605\n",
            "Epoch 1, Batch Loss: 0.18830916285514832\n",
            "Epoch 1, Batch Loss: 0.14898213744163513\n",
            "Epoch 1, Batch Loss: 0.1553756445646286\n",
            "Epoch 1, Batch Loss: 0.174751415848732\n",
            "Epoch 1, Batch Loss: 0.19933173060417175\n",
            "Epoch 1, Batch Loss: 0.24201393127441406\n",
            "Epoch 1, Batch Loss: 0.2304607331752777\n",
            "Epoch 1, Batch Loss: 0.2306961715221405\n",
            "Epoch 1, Batch Loss: 0.20636098086833954\n",
            "Epoch 1, Batch Loss: 0.17675650119781494\n",
            "Epoch 1, Batch Loss: 0.21494247019290924\n",
            "Epoch 1, Batch Loss: 0.1863788664340973\n",
            "Epoch 1, Batch Loss: 0.14264032244682312\n",
            "Epoch 1, Batch Loss: 0.13872787356376648\n",
            "Epoch 1, Batch Loss: 0.19794227182865143\n",
            "Epoch 1, Batch Loss: 0.21687740087509155\n",
            "Epoch 1, Batch Loss: 0.2023274004459381\n",
            "Epoch 1, Batch Loss: 0.1852342188358307\n",
            "Epoch 1, Batch Loss: 0.20151418447494507\n",
            "Epoch 1, Batch Loss: 0.21522167325019836\n",
            "Epoch 1, Batch Loss: 0.22799277305603027\n",
            "Epoch 1, Batch Loss: 0.17026686668395996\n",
            "Epoch 1, Batch Loss: 0.187593013048172\n",
            "Epoch 1, Batch Loss: 0.2137787640094757\n",
            "Epoch 1, Batch Loss: 0.19759544730186462\n",
            "Epoch 1, Batch Loss: 0.144847571849823\n",
            "Epoch 1, Batch Loss: 0.15299206972122192\n",
            "Epoch 1, Batch Loss: 0.22114324569702148\n",
            "Epoch 1, Batch Loss: 0.15444937348365784\n",
            "Epoch 1, Batch Loss: 0.18484808504581451\n",
            "Epoch 1, Batch Loss: 0.21973270177841187\n",
            "Epoch 1, Batch Loss: 0.22924602031707764\n",
            "Epoch 1, Batch Loss: 0.18025246262550354\n",
            "Epoch 1, Batch Loss: 0.2618792951107025\n",
            "Epoch 1, Batch Loss: 0.17773360013961792\n",
            "Epoch 1, Batch Loss: 0.21435891091823578\n",
            "Epoch 1, Batch Loss: 0.19096070528030396\n",
            "Epoch 1, Batch Loss: 0.20213599503040314\n",
            "Epoch 1, Batch Loss: 0.16877752542495728\n",
            "Epoch 1, Batch Loss: 0.23319588601589203\n",
            "Epoch 1, Batch Loss: 0.16274654865264893\n",
            "Epoch 1, Batch Loss: 0.18488247692584991\n",
            "Epoch 1, Batch Loss: 0.15249048173427582\n",
            "Epoch 1, Batch Loss: 0.17483267188072205\n",
            "Epoch 1, Batch Loss: 0.25033169984817505\n",
            "Epoch 1, Batch Loss: 0.1712653785943985\n",
            "Epoch 1, Batch Loss: 0.1862134337425232\n",
            "Epoch 1, Batch Loss: 0.23104459047317505\n",
            "Epoch 1, Batch Loss: 0.13365493714809418\n",
            "Epoch 1, Batch Loss: 0.18050050735473633\n",
            "Epoch 1, Batch Loss: 0.14597252011299133\n",
            "Epoch 1, Batch Loss: 0.16023463010787964\n",
            "Epoch 1, Batch Loss: 0.21959564089775085\n",
            "Epoch 1, Batch Loss: 0.17642003297805786\n",
            "Epoch 1, Batch Loss: 0.1755441278219223\n",
            "Epoch 1, Batch Loss: 0.23674292862415314\n",
            "Epoch 1, Batch Loss: 0.19755002856254578\n",
            "Epoch 1, Batch Loss: 0.130782350897789\n",
            "Epoch 1, Batch Loss: 0.2914353609085083\n",
            "Epoch 1, Batch Loss: 0.24342843890190125\n",
            "Epoch 1, Batch Loss: 0.19775374233722687\n",
            "Epoch 1, Batch Loss: 0.1741698980331421\n",
            "Epoch 1, Batch Loss: 0.17141234874725342\n",
            "Epoch 1, Batch Loss: 0.21566128730773926\n",
            "Epoch 1, Batch Loss: 0.17744025588035583\n",
            "Epoch 1, Batch Loss: 0.1722533106803894\n",
            "Epoch 1, Batch Loss: 0.207881897687912\n",
            "Epoch 1, Batch Loss: 0.18877847492694855\n",
            "Epoch 1, Batch Loss: 0.20309938490390778\n",
            "Epoch 1, Batch Loss: 0.186630517244339\n",
            "Epoch 1, Batch Loss: 0.22156332433223724\n",
            "Epoch 1, Batch Loss: 0.2650632858276367\n",
            "Epoch 1, Batch Loss: 0.1644904613494873\n",
            "Epoch 1, Batch Loss: 0.18260431289672852\n",
            "Epoch 1, Batch Loss: 0.1398799568414688\n",
            "Epoch 1, Batch Loss: 0.1770702600479126\n",
            "Epoch 1, Batch Loss: 0.18642018735408783\n",
            "Epoch 1, Batch Loss: 0.1831543743610382\n",
            "Epoch 1, Batch Loss: 0.1943351924419403\n",
            "Epoch 1, Batch Loss: 0.18097220361232758\n",
            "Epoch 1, Batch Loss: 0.17280542850494385\n",
            "Epoch 1, Batch Loss: 0.1399829387664795\n",
            "Epoch 1, Batch Loss: 0.16890503466129303\n",
            "Epoch 1, Batch Loss: 0.21766948699951172\n",
            "Epoch 1, Batch Loss: 0.1355353146791458\n",
            "Epoch 1, Batch Loss: 0.21553367376327515\n",
            "Epoch 1, Batch Loss: 0.1953865885734558\n",
            "Epoch 1, Batch Loss: 0.21719242632389069\n",
            "Epoch 1, Batch Loss: 0.1904725730419159\n",
            "Epoch 1, Batch Loss: 0.20344886183738708\n",
            "Epoch 1, Batch Loss: 0.17187516391277313\n",
            "Epoch 1, Batch Loss: 0.18689918518066406\n",
            "Epoch 1, Batch Loss: 0.20817351341247559\n",
            "Epoch 1, Batch Loss: 0.26952090859413147\n",
            "Epoch 1, Batch Loss: 0.20252367854118347\n",
            "Epoch 1, Batch Loss: 0.2202669382095337\n",
            "Epoch 1, Batch Loss: 0.21174979209899902\n",
            "Epoch 1, Batch Loss: 0.18742947280406952\n",
            "Epoch 1, Batch Loss: 0.16749566793441772\n",
            "Epoch 1, Batch Loss: 0.2032727599143982\n",
            "Epoch 1, Batch Loss: 0.13911107182502747\n",
            "Epoch 1, Batch Loss: 0.20598700642585754\n",
            "Epoch 1, Batch Loss: 0.14220717549324036\n",
            "Epoch 1, Batch Loss: 0.22002461552619934\n",
            "Epoch 1, Batch Loss: 0.2094930112361908\n",
            "Epoch 1, Batch Loss: 0.14126062393188477\n",
            "Epoch 1, Batch Loss: 0.2020767331123352\n",
            "Epoch 1, Batch Loss: 0.22750622034072876\n",
            "Epoch 1, Batch Loss: 0.16122910380363464\n",
            "Epoch 1, Batch Loss: 0.15264597535133362\n",
            "Epoch 1, Batch Loss: 0.22971178591251373\n",
            "Epoch 1, Batch Loss: 0.1769092082977295\n",
            "Epoch 1, Batch Loss: 0.17263981699943542\n",
            "Epoch 1, Batch Loss: 0.18525481224060059\n",
            "Epoch 1, Batch Loss: 0.23456217348575592\n",
            "Epoch 1, Batch Loss: 0.15597577393054962\n",
            "Epoch 1, Batch Loss: 0.12882442772388458\n",
            "Epoch 1, Batch Loss: 0.21223124861717224\n",
            "Epoch 1, Batch Loss: 0.22588440775871277\n",
            "Epoch 1, Batch Loss: 0.2281801700592041\n",
            "Epoch 1, Batch Loss: 0.19120147824287415\n",
            "Epoch 1, Batch Loss: 0.2088741958141327\n",
            "Epoch 1, Batch Loss: 0.20348407328128815\n",
            "Epoch 1, Batch Loss: 0.20920933783054352\n",
            "Epoch 1, Batch Loss: 0.19395369291305542\n",
            "Epoch 1, Batch Loss: 0.17568077147006989\n",
            "Epoch 1, Batch Loss: 0.21780264377593994\n",
            "Epoch 1, Batch Loss: 0.2020057737827301\n",
            "Epoch 1, Batch Loss: 0.16944263875484467\n",
            "Epoch 1, Batch Loss: 0.1725742071866989\n",
            "Epoch 1, Batch Loss: 0.2144145518541336\n",
            "Epoch 1, Batch Loss: 0.21645453572273254\n",
            "Epoch 1, Batch Loss: 0.20007944107055664\n",
            "Epoch 1, Batch Loss: 0.19565890729427338\n",
            "Epoch 1, Batch Loss: 0.1350749284029007\n",
            "Epoch 1, Batch Loss: 0.15005740523338318\n",
            "Epoch 1, Batch Loss: 0.21843260526657104\n",
            "Epoch 1, Batch Loss: 0.18330059945583344\n",
            "Epoch 1, Batch Loss: 0.1801573634147644\n",
            "Epoch 1, Batch Loss: 0.1746576428413391\n",
            "Epoch 1, Batch Loss: 0.2360946238040924\n",
            "Epoch 1, Batch Loss: 0.2066451609134674\n",
            "Epoch 1, Batch Loss: 0.15290303528308868\n",
            "Epoch 1, Batch Loss: 0.16155001521110535\n",
            "Epoch 1, Batch Loss: 0.1327134072780609\n",
            "Epoch 1, Batch Loss: 0.16382376849651337\n",
            "Epoch 1, Batch Loss: 0.12258688360452652\n",
            "Epoch 1, Batch Loss: 0.17989161610603333\n",
            "Epoch 1, Batch Loss: 0.16973437368869781\n",
            "Epoch 1, Batch Loss: 0.2512577772140503\n",
            "Epoch 1, Batch Loss: 0.15553632378578186\n",
            "Epoch 1, Batch Loss: 0.1712600737810135\n",
            "Epoch 1, Batch Loss: 0.1988285481929779\n",
            "Epoch 1, Batch Loss: 0.19457650184631348\n",
            "Epoch 1, Batch Loss: 0.25033026933670044\n",
            "Epoch 1, Batch Loss: 0.21400447189807892\n",
            "Epoch 1, Batch Loss: 0.1736239790916443\n",
            "Epoch 1, Batch Loss: 0.17112167179584503\n",
            "Epoch 1, Batch Loss: 0.1942254602909088\n",
            "Epoch 1, Batch Loss: 0.22902308404445648\n",
            "Epoch 1, Batch Loss: 0.16280265152454376\n",
            "Epoch 1, Batch Loss: 0.23950377106666565\n",
            "Epoch 1, Batch Loss: 0.21836420893669128\n",
            "Epoch 1, Batch Loss: 0.15517893433570862\n",
            "Epoch 1, Batch Loss: 0.19920998811721802\n",
            "Epoch 1, Batch Loss: 0.19035214185714722\n",
            "Epoch 1, Batch Loss: 0.2205362617969513\n",
            "Epoch 1, Batch Loss: 0.16364125907421112\n",
            "Epoch 1, Batch Loss: 0.15588097274303436\n",
            "Epoch 1, Batch Loss: 0.1913469135761261\n",
            "Epoch 1, Batch Loss: 0.2290186583995819\n",
            "Epoch 1, Batch Loss: 0.17631743848323822\n",
            "Epoch 1, Batch Loss: 0.1915513277053833\n",
            "Epoch 1, Batch Loss: 0.13030339777469635\n",
            "Epoch 1, Batch Loss: 0.17284099757671356\n",
            "Epoch 1, Batch Loss: 0.1386643499135971\n",
            "Epoch 1, Batch Loss: 0.22536085546016693\n",
            "Epoch 1, Batch Loss: 0.22494617104530334\n",
            "Epoch 1, Batch Loss: 0.1730033904314041\n",
            "Epoch 1, Batch Loss: 0.11012674868106842\n",
            "Epoch 1, Batch Loss: 0.19871380925178528\n",
            "Epoch 1, Batch Loss: 0.2580452859401703\n",
            "Epoch 1, Batch Loss: 0.17396438121795654\n",
            "Epoch 1, Batch Loss: 0.23456759750843048\n",
            "Epoch 1, Batch Loss: 0.12156850099563599\n",
            "Epoch 1, Batch Loss: 0.2658863067626953\n",
            "Epoch 1, Batch Loss: 0.14019636809825897\n",
            "Epoch 1, Batch Loss: 0.1595311164855957\n",
            "Epoch 1, Batch Loss: 0.19093598425388336\n",
            "Epoch 1, Batch Loss: 0.20024919509887695\n",
            "Epoch 1, Batch Loss: 0.12561863660812378\n",
            "Epoch 1, Batch Loss: 0.18018393218517303\n",
            "Epoch 1, Batch Loss: 0.1359969973564148\n",
            "Epoch 1, Batch Loss: 0.19964633882045746\n",
            "Epoch 1, Batch Loss: 0.20601427555084229\n",
            "Epoch 1, Batch Loss: 0.11490118503570557\n",
            "Epoch 1, Batch Loss: 0.14298900961875916\n",
            "Epoch 1, Batch Loss: 0.16953153908252716\n",
            "Epoch 1, Batch Loss: 0.18507786095142365\n",
            "Epoch 1, Batch Loss: 0.20777510106563568\n",
            "Epoch 1, Batch Loss: 0.11263818293809891\n",
            "Epoch 1, Batch Loss: 0.11212185025215149\n",
            "Epoch 1, Batch Loss: 0.1841794103384018\n",
            "Epoch 1, Batch Loss: 0.1673588752746582\n",
            "Epoch 1, Batch Loss: 0.2046426236629486\n",
            "Epoch 1, Batch Loss: 0.17481666803359985\n",
            "Epoch 1, Batch Loss: 0.22805845737457275\n",
            "Epoch 1, Batch Loss: 0.19540336728096008\n",
            "Epoch 1, Batch Loss: 0.12953726947307587\n",
            "Epoch 1, Batch Loss: 0.1532568335533142\n",
            "Epoch 1, Batch Loss: 0.16166158020496368\n",
            "Epoch 1, Batch Loss: 0.17389607429504395\n",
            "Epoch 1, Batch Loss: 0.17702122032642365\n",
            "Epoch 1, Batch Loss: 0.1649891883134842\n",
            "Epoch 1, Batch Loss: 0.14997629821300507\n",
            "Epoch 1, Batch Loss: 0.12755054235458374\n",
            "Epoch 1, Batch Loss: 0.18049532175064087\n",
            "Epoch 1, Batch Loss: 0.1885143518447876\n",
            "Epoch 1, Batch Loss: 0.21241441369056702\n",
            "Epoch 1, Batch Loss: 0.15163569152355194\n",
            "Epoch 1, Batch Loss: 0.1750820428133011\n",
            "Epoch 1, Batch Loss: 0.17727768421173096\n",
            "Epoch 1, Batch Loss: 0.16013963520526886\n",
            "Epoch 1, Batch Loss: 0.16172640025615692\n",
            "Epoch 1, Batch Loss: 0.20016944408416748\n",
            "Epoch 1, Batch Loss: 0.22948220372200012\n",
            "Epoch 1, Batch Loss: 0.24667803943157196\n",
            "Epoch 1, Batch Loss: 0.16614246368408203\n",
            "Epoch 1, Batch Loss: 0.1684047132730484\n",
            "Epoch 1, Batch Loss: 0.18424968421459198\n",
            "Epoch 1, Batch Loss: 0.10834178328514099\n",
            "Epoch 1, Batch Loss: 0.16533847153186798\n",
            "Epoch 1, Batch Loss: 0.188277006149292\n",
            "Epoch 1, Batch Loss: 0.16142702102661133\n",
            "Epoch 1, Batch Loss: 0.18836179375648499\n",
            "Epoch 1, Batch Loss: 0.16610857844352722\n",
            "Epoch 1, Batch Loss: 0.17199188470840454\n",
            "Epoch 1, Batch Loss: 0.1458628922700882\n",
            "Epoch 1, Batch Loss: 0.2340947836637497\n",
            "Epoch 1, Batch Loss: 0.13150718808174133\n",
            "Epoch 1, Batch Loss: 0.1908397078514099\n",
            "Epoch 1, Batch Loss: 0.206851989030838\n",
            "Epoch 1, Batch Loss: 0.1400911659002304\n",
            "Epoch 1, Batch Loss: 0.2761632204055786\n",
            "Epoch 1, Batch Loss: 0.19986093044281006\n",
            "Epoch 1, Batch Loss: 0.19056689739227295\n",
            "Epoch 1, Batch Loss: 0.1568620502948761\n",
            "Epoch 1, Batch Loss: 0.1439470648765564\n",
            "Epoch 1, Batch Loss: 0.20302578806877136\n",
            "Epoch 1, Batch Loss: 0.14966857433319092\n",
            "Epoch 1, Batch Loss: 0.2213287353515625\n",
            "Epoch 1, Batch Loss: 0.22010432183742523\n",
            "Epoch 1, Batch Loss: 0.13676020503044128\n",
            "Epoch 1, Batch Loss: 0.11139117181301117\n",
            "Epoch 1, Batch Loss: 0.1731511503458023\n",
            "Epoch 1, Batch Loss: 0.1325766146183014\n",
            "Epoch 1, Batch Loss: 0.22459502518177032\n",
            "Epoch 1, Batch Loss: 0.20891737937927246\n",
            "Epoch 1, Batch Loss: 0.11691609025001526\n",
            "Epoch 1, Batch Loss: 0.14650824666023254\n",
            "Epoch 1, Batch Loss: 0.15162251889705658\n",
            "Epoch 1, Batch Loss: 0.13411641120910645\n",
            "Epoch 1, Batch Loss: 0.1384577751159668\n",
            "Epoch 1, Batch Loss: 0.16221432387828827\n",
            "Epoch 1, Batch Loss: 0.17343172430992126\n",
            "Epoch 1, Batch Loss: 0.1357967108488083\n",
            "Epoch 1, Batch Loss: 0.133338063955307\n",
            "Epoch 1, Batch Loss: 0.162679523229599\n",
            "Epoch 1, Batch Loss: 0.24070753157138824\n",
            "Epoch 1, Batch Loss: 0.148108571767807\n",
            "Epoch 1, Batch Loss: 0.2351970374584198\n",
            "Epoch 1, Batch Loss: 0.17290140688419342\n",
            "Epoch 1, Batch Loss: 0.26481136679649353\n",
            "Epoch 1, Batch Loss: 0.13931256532669067\n",
            "Epoch 1, Batch Loss: 0.19999176263809204\n",
            "Epoch 1, Batch Loss: 0.22441737353801727\n",
            "Epoch 1, Batch Loss: 0.12533321976661682\n",
            "Epoch 1, Batch Loss: 0.2614285945892334\n",
            "Epoch 1, Batch Loss: 0.1842729151248932\n",
            "Epoch 1, Batch Loss: 0.24263271689414978\n",
            "Epoch 1, Batch Loss: 0.15102700889110565\n",
            "Epoch 1, Batch Loss: 0.18217170238494873\n",
            "Epoch 1, Batch Loss: 0.20238393545150757\n",
            "Epoch 1, Batch Loss: 0.16739806532859802\n",
            "Epoch 1, Batch Loss: 0.17122581601142883\n",
            "Epoch 1, Batch Loss: 0.18990746140480042\n",
            "Epoch 1, Batch Loss: 0.17434701323509216\n",
            "Epoch 1, Batch Loss: 0.11390630900859833\n",
            "Epoch 1, Batch Loss: 0.16148893535137177\n",
            "Epoch 1, Batch Loss: 0.17073118686676025\n",
            "Epoch 1, Batch Loss: 0.23721905052661896\n",
            "Epoch 1, Batch Loss: 0.12493579089641571\n",
            "Epoch 1, Batch Loss: 0.049994662404060364\n",
            "Epoch 1, Batch Loss: 0.20393823087215424\n",
            "Epoch 1, Batch Loss: 0.19791848957538605\n",
            "Epoch 1, Batch Loss: 0.218421071767807\n",
            "Epoch 1, Batch Loss: 0.14146974682807922\n",
            "Epoch 1, Batch Loss: 0.13384318351745605\n",
            "Epoch 1, Batch Loss: 0.12515954673290253\n",
            "Epoch 1, Batch Loss: 0.19458015263080597\n",
            "Epoch 1, Batch Loss: 0.18553394079208374\n",
            "Epoch 1, Batch Loss: 0.15912528336048126\n",
            "Epoch 1, Batch Loss: 0.1514180302619934\n",
            "Epoch 1, Batch Loss: 0.1887144297361374\n",
            "Epoch 1, Batch Loss: 0.1432303935289383\n",
            "Epoch 1, Batch Loss: 0.19899101555347443\n",
            "Epoch 1, Batch Loss: 0.21789678931236267\n",
            "Epoch 1, Batch Loss: 0.21567867696285248\n",
            "Epoch 1, Batch Loss: 0.14352717995643616\n",
            "Epoch 1, Batch Loss: 0.1921178549528122\n",
            "Epoch 1, Batch Loss: 0.22416897118091583\n",
            "Epoch 1, Batch Loss: 0.2084338366985321\n",
            "Epoch 1, Batch Loss: 0.15647798776626587\n",
            "Epoch 1, Batch Loss: 0.18273240327835083\n",
            "Epoch 1, Batch Loss: 0.241424560546875\n",
            "Epoch 1, Batch Loss: 0.18664631247520447\n",
            "Epoch 1, Batch Loss: 0.19875457882881165\n",
            "Epoch 1, Batch Loss: 0.14040863513946533\n",
            "Epoch 1, Batch Loss: 0.1808004081249237\n",
            "Epoch 1, Batch Loss: 0.15972039103507996\n",
            "Epoch 1, Batch Loss: 0.14965589344501495\n",
            "Epoch 1, Batch Loss: 0.13146740198135376\n",
            "Epoch 1, Batch Loss: 0.13856688141822815\n",
            "Epoch 1, Batch Loss: 0.09995805472135544\n",
            "Epoch 1, Batch Loss: 0.20241586863994598\n",
            "Epoch 1, Batch Loss: 0.19315476715564728\n",
            "Epoch 1, Batch Loss: 0.17139455676078796\n",
            "Epoch 1, Batch Loss: 0.18299296498298645\n",
            "Epoch 1, Batch Loss: 0.19279401004314423\n",
            "Epoch 1, Batch Loss: 0.1871611773967743\n",
            "Epoch 1, Batch Loss: 0.18313227593898773\n",
            "Epoch 1, Batch Loss: 0.25929224491119385\n",
            "Epoch 1, Batch Loss: 0.15382499992847443\n",
            "Epoch 1, Batch Loss: 0.21594202518463135\n",
            "Epoch 1, Batch Loss: 0.04773163050413132\n",
            "Epoch 1, Batch Loss: 0.09310347586870193\n",
            "Epoch 1, Batch Loss: 0.16410976648330688\n",
            "Epoch 1, Batch Loss: 0.17730176448822021\n",
            "Epoch 1, Batch Loss: 0.23436081409454346\n",
            "Epoch 1, Batch Loss: 0.19513165950775146\n",
            "Epoch 1, Batch Loss: 0.20930685102939606\n",
            "Epoch 1, Batch Loss: 0.14698369801044464\n",
            "Epoch 1, Batch Loss: 0.15992364287376404\n",
            "Epoch 1, Batch Loss: 0.20332637429237366\n",
            "Epoch 1, Batch Loss: 0.21081893146038055\n",
            "Epoch 1, Batch Loss: 0.16432568430900574\n",
            "Epoch 1, Batch Loss: 0.18879318237304688\n",
            "Epoch 1, Batch Loss: 0.17593970894813538\n",
            "Epoch 1, Batch Loss: 0.14213696122169495\n",
            "Epoch 1, Batch Loss: 0.17147196829319\n",
            "Epoch 1, Batch Loss: 0.1607767641544342\n",
            "Epoch 1, Batch Loss: 0.12416099011898041\n",
            "Epoch 1, Batch Loss: 0.19110321998596191\n",
            "Epoch 1, Batch Loss: 0.18026188015937805\n",
            "Epoch 1, Batch Loss: 0.1299215853214264\n",
            "Epoch 1, Batch Loss: 0.14214539527893066\n",
            "Epoch 1, Batch Loss: 0.1608167439699173\n",
            "Epoch 1, Batch Loss: 0.19943785667419434\n",
            "Epoch 1, Batch Loss: 0.24271920323371887\n",
            "Epoch 1, Batch Loss: 0.21510347723960876\n",
            "Epoch 1, Batch Loss: 0.14013344049453735\n",
            "Epoch 1, Batch Loss: 0.15686506032943726\n",
            "Epoch 1, Batch Loss: 0.18364863097667694\n",
            "Epoch 1, Batch Loss: 0.10714089125394821\n",
            "Epoch 1, Batch Loss: 0.1604524552822113\n",
            "Epoch 1, Batch Loss: 0.1563951075077057\n",
            "Epoch 1, Batch Loss: 0.1663183867931366\n",
            "Epoch 1, Batch Loss: 0.17719154059886932\n",
            "Epoch 1, Batch Loss: 0.16522644460201263\n",
            "Epoch 1, Batch Loss: 0.16221387684345245\n",
            "Epoch 1, Batch Loss: 0.13114267587661743\n",
            "Epoch 1, Batch Loss: 0.17510993778705597\n",
            "Epoch 1, Batch Loss: 0.19191506505012512\n",
            "Epoch 1, Batch Loss: 0.13792511820793152\n",
            "Epoch 1, Batch Loss: 0.2007523775100708\n",
            "Epoch 1, Batch Loss: 0.140180304646492\n",
            "Epoch 1, Batch Loss: 0.19138303399085999\n",
            "Epoch 1, Batch Loss: 0.21188344061374664\n",
            "Epoch 1, Batch Loss: 0.16858415305614471\n",
            "Epoch 1, Batch Loss: 0.14490413665771484\n",
            "Epoch 1, Batch Loss: 0.19175615906715393\n",
            "Epoch 1, Batch Loss: 0.12467060983181\n",
            "Epoch 1, Batch Loss: 0.10666317492723465\n",
            "Epoch 1, Batch Loss: 0.1427937150001526\n",
            "Epoch 1, Batch Loss: 0.17032140493392944\n",
            "Epoch 1, Batch Loss: 0.11689800024032593\n",
            "Epoch 1, Batch Loss: 0.2290331870317459\n",
            "Epoch 1, Batch Loss: 0.24117441475391388\n",
            "Epoch 1, Batch Loss: 0.15196876227855682\n",
            "Epoch 1, Batch Loss: 0.2007146030664444\n",
            "Epoch 1, Batch Loss: 0.1292625367641449\n",
            "Epoch 1, Batch Loss: 0.15873345732688904\n",
            "Epoch 1, Batch Loss: 0.1383298933506012\n",
            "Epoch 1, Batch Loss: 0.11539633572101593\n",
            "Epoch 1, Batch Loss: 0.11781901121139526\n",
            "Epoch 1, Batch Loss: 0.1905866265296936\n",
            "Epoch 1, Batch Loss: 0.17784476280212402\n",
            "Epoch 1, Batch Loss: 0.18510006368160248\n",
            "Epoch 1, Batch Loss: 0.19233107566833496\n",
            "Epoch 1, Batch Loss: 0.24732235074043274\n",
            "Epoch 1, Batch Loss: 0.19390258193016052\n",
            "Epoch 1, Batch Loss: 0.15040110051631927\n",
            "Epoch 1, Batch Loss: 0.17122863233089447\n",
            "Epoch 1, Batch Loss: 0.1895386427640915\n",
            "Epoch 1, Batch Loss: 0.19877073168754578\n",
            "Epoch 1, Batch Loss: 0.15950199961662292\n",
            "Epoch 1, Batch Loss: 0.1785511076450348\n",
            "Epoch 1, Batch Loss: 0.18981324136257172\n",
            "Epoch 1, Batch Loss: 0.15059822797775269\n",
            "Epoch 1, Batch Loss: 0.14384044706821442\n",
            "Epoch 1, Batch Loss: 0.1185506284236908\n",
            "Epoch 1, Batch Loss: 0.21928256750106812\n",
            "Epoch 1, Batch Loss: 0.18420976400375366\n",
            "Epoch 1, Batch Loss: 0.2390275001525879\n",
            "Epoch 1, Batch Loss: 0.18539798259735107\n",
            "Epoch 1, Batch Loss: 0.1660623550415039\n",
            "Epoch 1, Batch Loss: 0.2053157091140747\n",
            "Epoch 1, Batch Loss: 0.15456728637218475\n",
            "Epoch 1, Batch Loss: 0.14585071802139282\n",
            "Epoch 1, Batch Loss: 0.18151380121707916\n",
            "Epoch 1, Batch Loss: 0.14439842104911804\n",
            "Epoch 1, Batch Loss: 0.13833698630332947\n",
            "Epoch 1, Batch Loss: 0.1726309061050415\n",
            "Epoch 1, Batch Loss: 0.10372523963451385\n",
            "Epoch 1, Batch Loss: 0.14134535193443298\n",
            "Epoch 1, Batch Loss: 0.154237300157547\n",
            "Epoch 1, Batch Loss: 0.11197298020124435\n",
            "Epoch 1, Batch Loss: 0.14872997999191284\n",
            "Epoch 1, Batch Loss: 0.1784096509218216\n",
            "Epoch 1, Batch Loss: 0.13847479224205017\n",
            "Epoch 1, Batch Loss: 0.14530973136425018\n",
            "Epoch 1, Batch Loss: 0.1382688730955124\n",
            "Epoch 1, Batch Loss: 0.19789525866508484\n",
            "Epoch 1, Batch Loss: 0.16173836588859558\n",
            "Epoch 1, Batch Loss: 0.12289488315582275\n",
            "Epoch 1, Batch Loss: 0.17994511127471924\n",
            "Epoch 1, Batch Loss: 0.1709466278553009\n",
            "Epoch 1, Batch Loss: 0.23878173530101776\n",
            "Epoch 1, Batch Loss: 0.1032421737909317\n",
            "Epoch 1, Batch Loss: 0.2066306322813034\n",
            "Epoch 1, Batch Loss: 0.13634809851646423\n",
            "Epoch 1, Batch Loss: 0.18178342282772064\n",
            "Epoch 1, Batch Loss: 0.15545210242271423\n",
            "Epoch 1, Batch Loss: 0.20185431838035583\n",
            "Epoch 1, Batch Loss: 0.19082549214363098\n",
            "Epoch 1, Batch Loss: 0.20796778798103333\n",
            "Epoch 1, Batch Loss: 0.25209367275238037\n",
            "Epoch 1, Batch Loss: 0.1439010500907898\n",
            "Epoch 1, Batch Loss: 0.14618991315364838\n",
            "Epoch 1, Batch Loss: 0.13013310730457306\n",
            "Epoch 1, Batch Loss: 0.09446457028388977\n",
            "Epoch 1, Batch Loss: 0.12864409387111664\n",
            "Epoch 1, Batch Loss: 0.15183354914188385\n",
            "Epoch 1, Batch Loss: 0.15861299633979797\n",
            "Epoch 1, Batch Loss: 0.14989139139652252\n",
            "Epoch 1, Batch Loss: 0.15431129932403564\n",
            "Epoch 1, Batch Loss: 0.13298624753952026\n",
            "Epoch 1, Batch Loss: 0.17068889737129211\n",
            "Epoch 1, Batch Loss: 0.0545930415391922\n",
            "Epoch 1, Batch Loss: 0.14863751828670502\n",
            "Epoch 1, Batch Loss: 0.1416683793067932\n",
            "Epoch 1, Batch Loss: 0.2144259512424469\n",
            "Epoch 1, Batch Loss: 0.1430450975894928\n",
            "Epoch 1, Batch Loss: 0.14968279004096985\n",
            "Epoch 1, Batch Loss: 0.15528005361557007\n",
            "Epoch 1, Batch Loss: 0.17271855473518372\n",
            "Epoch 1, Batch Loss: 0.19244788587093353\n",
            "Epoch 1, Batch Loss: 0.19815558195114136\n",
            "Epoch 1, Batch Loss: 0.17560678720474243\n",
            "Epoch 1, Batch Loss: 0.13654698431491852\n",
            "Epoch 1, Batch Loss: 0.17455145716667175\n",
            "Epoch 1, Batch Loss: 0.22567257285118103\n",
            "Epoch 1, Batch Loss: 0.1250162571668625\n",
            "Epoch 1, Batch Loss: 0.19880619645118713\n",
            "Epoch 1, Batch Loss: 0.16894380748271942\n",
            "Epoch 1, Batch Loss: 0.15885084867477417\n",
            "Epoch 1, Batch Loss: 0.1609565168619156\n",
            "Epoch 1, Batch Loss: 0.15751579403877258\n",
            "Epoch 1, Batch Loss: 0.2010074108839035\n",
            "Epoch 1, Batch Loss: 0.2225092351436615\n",
            "Epoch 1, Batch Loss: 0.10339909046888351\n",
            "Epoch 1, Batch Loss: 0.15881289541721344\n",
            "Epoch 1, Batch Loss: 0.17919600009918213\n",
            "Epoch 1, Batch Loss: 0.24457931518554688\n",
            "Epoch 1, Batch Loss: 0.17875458300113678\n",
            "Epoch 1, Batch Loss: 0.16004711389541626\n",
            "Epoch 1, Batch Loss: 0.1249922439455986\n",
            "Epoch 1, Batch Loss: 0.17214316129684448\n",
            "Epoch 1, Batch Loss: 0.19042325019836426\n",
            "Epoch 1, Batch Loss: 0.21784541010856628\n",
            "Epoch 1, Batch Loss: 0.138339564204216\n",
            "Epoch 1, Batch Loss: 0.14743393659591675\n",
            "Epoch 1, Batch Loss: 0.19577307999134064\n",
            "Epoch 1, Batch Loss: 0.15682198107242584\n",
            "Epoch 1, Batch Loss: 0.13864271342754364\n",
            "Epoch 1, Batch Loss: 0.1529669165611267\n",
            "Epoch 1, Batch Loss: 0.14281855523586273\n",
            "Epoch 1, Batch Loss: 0.19311973452568054\n",
            "Epoch 1, Batch Loss: 0.1554919183254242\n",
            "Epoch 1, Batch Loss: 0.1313045769929886\n",
            "Epoch 1, Batch Loss: 0.22378991544246674\n",
            "Epoch 1, Batch Loss: 0.2396026849746704\n",
            "Epoch 1, Batch Loss: 0.11047088354825974\n",
            "Epoch 1, Batch Loss: 0.21196117997169495\n",
            "Epoch 1, Batch Loss: 0.11216790974140167\n",
            "Epoch 1, Batch Loss: 0.14933468401432037\n",
            "Epoch 1, Batch Loss: 0.17033877968788147\n",
            "Epoch 1, Batch Loss: 0.18198904395103455\n",
            "Epoch 1, Batch Loss: 0.10229207575321198\n",
            "Epoch 1, Batch Loss: 0.22158965468406677\n",
            "Epoch 1, Batch Loss: 0.22771324217319489\n",
            "Epoch 1, Batch Loss: 0.15759354829788208\n",
            "Epoch 1, Batch Loss: 0.1273026168346405\n",
            "Epoch 1, Batch Loss: 0.1695123314857483\n",
            "Epoch 1, Batch Loss: 0.11707311868667603\n",
            "Epoch 1, Batch Loss: 0.18044587969779968\n",
            "Epoch 1, Batch Loss: 0.13680261373519897\n",
            "Epoch 1, Batch Loss: 0.1946260929107666\n",
            "Epoch 1, Batch Loss: 0.14516261219978333\n",
            "Epoch 1, Batch Loss: 0.1545865833759308\n",
            "Epoch 1, Batch Loss: 0.11300381273031235\n",
            "Epoch 1, Batch Loss: 0.13458168506622314\n",
            "Epoch 1, Batch Loss: 0.16185083985328674\n",
            "Epoch 1, Batch Loss: 0.12587308883666992\n",
            "Epoch 1, Batch Loss: 0.15924759209156036\n",
            "Epoch 1, Batch Loss: 0.16223596036434174\n",
            "Epoch 1, Batch Loss: 0.22654789686203003\n",
            "Epoch 1, Batch Loss: 0.20625539124011993\n",
            "Epoch 1, Batch Loss: 0.20716387033462524\n",
            "Epoch 1, Batch Loss: 0.20054736733436584\n",
            "Epoch 1, Batch Loss: 0.12859240174293518\n",
            "Epoch 1, Batch Loss: 0.1922398954629898\n",
            "Epoch 1, Batch Loss: 0.19162213802337646\n",
            "Epoch 1, Batch Loss: 0.21308106184005737\n",
            "Epoch 1, Batch Loss: 0.11736815422773361\n",
            "Epoch 1, Batch Loss: 0.1513352245092392\n",
            "Epoch 1, Batch Loss: 0.16122102737426758\n",
            "Epoch 1, Batch Loss: 0.14906515181064606\n",
            "Epoch 1, Batch Loss: 0.1598820835351944\n",
            "Epoch 1, Batch Loss: 0.13549740612506866\n",
            "Epoch 1, Batch Loss: 0.06386259198188782\n",
            "Epoch 1, Batch Loss: 0.15338283777236938\n",
            "Epoch 1, Batch Loss: 0.1788325309753418\n",
            "Epoch 1, Batch Loss: 0.16348779201507568\n",
            "Epoch 1, Batch Loss: 0.1399010419845581\n",
            "Epoch 1, Batch Loss: 0.23719914257526398\n",
            "Epoch 1, Batch Loss: 0.2082473486661911\n",
            "Epoch 1, Batch Loss: 0.16251060366630554\n",
            "Epoch 1, Batch Loss: 0.12705060839653015\n",
            "Epoch 1, Batch Loss: 0.15922804176807404\n",
            "Epoch 1, Batch Loss: 0.16533300280570984\n",
            "Epoch 1, Batch Loss: 0.15157632529735565\n",
            "Epoch 1, Batch Loss: 0.2193058431148529\n",
            "Epoch 1, Batch Loss: 0.14390909671783447\n",
            "Epoch 1, Batch Loss: 0.18607278168201447\n",
            "Epoch 1, Batch Loss: 0.1451023370027542\n",
            "Epoch 1, Batch Loss: 0.14189653098583221\n",
            "Epoch 1, Batch Loss: 0.17571201920509338\n",
            "Epoch 1, Batch Loss: 0.09325672686100006\n",
            "Epoch 1, Batch Loss: 0.2359142303466797\n",
            "Epoch 1, Batch Loss: 0.14045435190200806\n",
            "Epoch 1, Batch Loss: 0.06968529522418976\n",
            "Epoch 1, Batch Loss: 0.24917635321617126\n",
            "Epoch 1, Batch Loss: 0.19287748634815216\n",
            "Epoch 1, Batch Loss: 0.1344602108001709\n",
            "Epoch 1, Batch Loss: 0.13592395186424255\n",
            "Epoch 1, Batch Loss: 0.13432040810585022\n",
            "Epoch 1, Batch Loss: 0.2317819893360138\n",
            "Epoch 1, Batch Loss: 0.22953608632087708\n",
            "Epoch 1, Batch Loss: 0.11678606271743774\n",
            "Epoch 1, Batch Loss: 0.16542848944664001\n",
            "Epoch 1, Batch Loss: 0.2127317488193512\n",
            "Epoch 1, Batch Loss: 0.16691815853118896\n",
            "Epoch 1, Batch Loss: 0.1513771414756775\n",
            "Epoch 1, Batch Loss: 0.1992618292570114\n",
            "Epoch 1, Batch Loss: 0.19241061806678772\n",
            "Epoch 1, Batch Loss: 0.1454726755619049\n",
            "Epoch 1, Batch Loss: 0.17964790761470795\n",
            "Epoch 1, Batch Loss: 0.20528286695480347\n",
            "Epoch 1, Batch Loss: 0.17494793236255646\n",
            "Epoch 1, Batch Loss: 0.16098779439926147\n",
            "Epoch 1, Batch Loss: 0.1466919481754303\n",
            "Epoch 1, Batch Loss: 0.1600250005722046\n",
            "Epoch 1, Batch Loss: 0.1543959379196167\n",
            "Epoch 1, Batch Loss: 0.2332901805639267\n",
            "Epoch 1, Batch Loss: 0.13757361471652985\n",
            "Epoch 1, Batch Loss: 0.18604472279548645\n",
            "Epoch 1, Batch Loss: 0.152155801653862\n",
            "Epoch 1, Batch Loss: 0.11071062088012695\n",
            "Epoch 1, Batch Loss: 0.16230398416519165\n",
            "Epoch 1, Batch Loss: 0.14398890733718872\n",
            "Epoch 1, Batch Loss: 0.21969565749168396\n",
            "Epoch 1, Batch Loss: 0.15493164956569672\n",
            "Epoch 1, Batch Loss: 0.17356011271476746\n",
            "Epoch 1, Batch Loss: 0.17620135843753815\n",
            "Epoch 1, Batch Loss: 0.2365047186613083\n",
            "Epoch 1, Batch Loss: 0.17529568076133728\n",
            "Epoch 1, Batch Loss: 0.17085503041744232\n",
            "Epoch 1, Batch Loss: 0.1793433129787445\n",
            "Epoch 1, Batch Loss: 0.17775698006153107\n",
            "Epoch 1, Batch Loss: 0.16488952934741974\n",
            "Epoch 1, Batch Loss: 0.10664594918489456\n",
            "Epoch 1, Batch Loss: 0.18123389780521393\n",
            "Epoch 1, Batch Loss: 0.14524568617343903\n",
            "Epoch 1, Batch Loss: 0.1798236072063446\n",
            "Epoch 1, Batch Loss: 0.1703622043132782\n",
            "Epoch 1, Batch Loss: 0.1275087296962738\n",
            "Epoch 1, Batch Loss: 0.2002831995487213\n",
            "Epoch 1, Batch Loss: 0.13943316042423248\n",
            "Epoch 1, Batch Loss: 0.17261651158332825\n",
            "Epoch 1, Batch Loss: 0.198897585272789\n",
            "Epoch 1, Batch Loss: 0.16094207763671875\n",
            "Epoch 1, Batch Loss: 0.11069747805595398\n",
            "Epoch 1, Batch Loss: 0.1440972238779068\n",
            "Epoch 1, Batch Loss: 0.17156368494033813\n",
            "Epoch 1, Batch Loss: 0.21373721957206726\n",
            "Epoch 1, Batch Loss: 0.2045060098171234\n",
            "Epoch 1, Batch Loss: 0.17411300539970398\n",
            "Epoch 1, Batch Loss: 0.22007952630519867\n",
            "Epoch 1, Batch Loss: 0.19795747101306915\n",
            "Epoch 1, Batch Loss: 0.19799070060253143\n",
            "Epoch 1, Batch Loss: 0.1914585530757904\n",
            "Epoch 1, Batch Loss: 0.16905802488327026\n",
            "Epoch 1, Batch Loss: 0.11408668011426926\n",
            "Epoch 1, Batch Loss: 0.12270589917898178\n",
            "Epoch 1, Batch Loss: 0.0901460200548172\n",
            "Epoch 1, Batch Loss: 0.17442694306373596\n",
            "Epoch 1, Batch Loss: 0.18207570910453796\n",
            "Epoch 1, Batch Loss: 0.15932869911193848\n",
            "Epoch 1, Batch Loss: 0.11629864573478699\n",
            "Epoch 1, Batch Loss: 0.19820724427700043\n",
            "Epoch 1, Batch Loss: 0.12558656930923462\n",
            "Epoch 1, Batch Loss: 0.1246550977230072\n",
            "Epoch 1, Batch Loss: 0.1073368489742279\n",
            "Epoch 1, Batch Loss: 0.15823540091514587\n",
            "Epoch 1, Batch Loss: 0.17232631146907806\n",
            "Epoch 1, Batch Loss: 0.17753300070762634\n",
            "Epoch 1, Batch Loss: 0.13938751816749573\n",
            "Epoch 1, Batch Loss: 0.13207435607910156\n",
            "Epoch 1, Batch Loss: 0.18734851479530334\n",
            "Epoch 1, Batch Loss: 0.16068390011787415\n",
            "Epoch 1, Batch Loss: 0.16729360818862915\n",
            "Epoch 1, Batch Loss: 0.16254471242427826\n",
            "Epoch 1, Batch Loss: 0.1794128715991974\n",
            "Epoch 1, Batch Loss: 0.15911434590816498\n",
            "Epoch 1, Batch Loss: 0.15791279077529907\n",
            "Epoch 1, Batch Loss: 0.15678195655345917\n",
            "Epoch 1, Batch Loss: 0.12852972745895386\n",
            "Epoch 1, Batch Loss: 0.16424833238124847\n",
            "Epoch 1, Batch Loss: 0.19334492087364197\n",
            "Epoch 1, Batch Loss: 0.09592648595571518\n",
            "Epoch 1, Batch Loss: 0.1818508505821228\n",
            "Epoch 1, Batch Loss: 0.13770204782485962\n",
            "Epoch 1, Batch Loss: 0.16225256025791168\n",
            "Epoch 1, Batch Loss: 0.14485257863998413\n",
            "Epoch 1, Batch Loss: 0.14722919464111328\n",
            "Epoch 1, Batch Loss: 0.23601731657981873\n",
            "Epoch 1, Batch Loss: 0.19916421175003052\n",
            "Epoch 1, Batch Loss: 0.11181244254112244\n",
            "Epoch 1, Batch Loss: 0.1459304839372635\n",
            "Epoch 1, Batch Loss: 0.14898212254047394\n",
            "Epoch 1, Batch Loss: 0.09722451865673065\n",
            "Epoch 1, Batch Loss: 0.1556210219860077\n",
            "Epoch 1, Batch Loss: 0.11470085382461548\n",
            "Epoch 1, Batch Loss: 0.1414114087820053\n",
            "Epoch 1, Batch Loss: 0.135476216673851\n",
            "Epoch 1, Batch Loss: 0.16383683681488037\n",
            "Epoch 1, Batch Loss: 0.13494303822517395\n",
            "Epoch 1, Batch Loss: 0.2221071720123291\n",
            "Epoch 1, Batch Loss: 0.1750582754611969\n",
            "Epoch 1, Batch Loss: 0.17893162369728088\n",
            "Epoch 1, Batch Loss: 0.15953142940998077\n",
            "Epoch 1, Batch Loss: 0.1256258189678192\n",
            "Epoch 1, Batch Loss: 0.1448102742433548\n",
            "Epoch 1, Batch Loss: 0.1104746162891388\n",
            "Epoch 1, Batch Loss: 0.19077256321907043\n",
            "Epoch 1, Batch Loss: 0.13907912373542786\n",
            "Epoch 1, Batch Loss: 0.17689085006713867\n",
            "Epoch 1, Batch Loss: 0.12411098927259445\n",
            "Epoch 1, Batch Loss: 0.1781415492296219\n",
            "Epoch 1, Batch Loss: 0.1935129165649414\n",
            "Epoch 1, Batch Loss: 0.22363236546516418\n",
            "Epoch 1, Batch Loss: 0.16224727034568787\n",
            "Epoch 1, Batch Loss: 0.15466226637363434\n",
            "Epoch 1, Batch Loss: 0.1571146547794342\n",
            "Epoch 1, Batch Loss: 0.16516119241714478\n",
            "Epoch 1, Batch Loss: 0.18674714863300323\n",
            "Epoch 1, Batch Loss: 0.1325860619544983\n",
            "Epoch 1, Batch Loss: 0.15589942038059235\n",
            "Epoch 1, Batch Loss: 0.18434473872184753\n",
            "Epoch 1, Batch Loss: 0.14970514178276062\n",
            "Epoch 1, Batch Loss: 0.1049981340765953\n",
            "Epoch 1, Batch Loss: 0.17973288893699646\n",
            "Epoch 1, Batch Loss: 0.10949457436800003\n",
            "Epoch 1, Batch Loss: 0.17457078397274017\n",
            "Epoch 1, Batch Loss: 0.15668417513370514\n",
            "Epoch 1, Batch Loss: 0.1793493777513504\n",
            "Epoch 1, Batch Loss: 0.17718100547790527\n",
            "Epoch 1, Batch Loss: 0.18963953852653503\n",
            "Epoch 1, Batch Loss: 0.08019547909498215\n",
            "Epoch 1, Batch Loss: 0.14766958355903625\n",
            "Epoch 1, Batch Loss: 0.11855348944664001\n",
            "Epoch 1, Batch Loss: 0.1675083041191101\n",
            "Epoch 1, Batch Loss: 0.21471785008907318\n",
            "Epoch 1, Batch Loss: 0.17775732278823853\n",
            "Epoch 1, Batch Loss: 0.15901337563991547\n",
            "Epoch 1, Batch Loss: 0.15009786188602448\n",
            "Epoch 1, Batch Loss: 0.13762342929840088\n",
            "Epoch 1, Batch Loss: 0.15939396619796753\n",
            "Epoch 1, Batch Loss: 0.19023440778255463\n",
            "Epoch 1, Batch Loss: 0.1254289150238037\n",
            "Epoch 1, Batch Loss: 0.2059740424156189\n",
            "Epoch 1, Batch Loss: 0.11679396033287048\n",
            "Epoch 1, Batch Loss: 0.15870657563209534\n",
            "Epoch 1, Batch Loss: 0.20168855786323547\n",
            "Epoch 1, Batch Loss: 0.1704617440700531\n",
            "Epoch 1, Batch Loss: 0.13257116079330444\n",
            "Epoch 1, Batch Loss: 0.17200151085853577\n",
            "Epoch 1, Batch Loss: 0.1387915313243866\n",
            "Epoch 1, Batch Loss: 0.16370448470115662\n",
            "Epoch 1, Batch Loss: 0.13655981421470642\n",
            "Epoch 1, Batch Loss: 0.13020989298820496\n",
            "Epoch 1, Batch Loss: 0.1430296152830124\n",
            "Epoch 1, Batch Loss: 0.16722384095191956\n",
            "Epoch 1, Batch Loss: 0.1686868667602539\n",
            "Epoch 1, Batch Loss: 0.21046921610832214\n",
            "Epoch 1, Batch Loss: 0.12248650193214417\n",
            "Epoch 1, Batch Loss: 0.21074768900871277\n",
            "Epoch 1, Batch Loss: 0.18855580687522888\n",
            "Epoch 1, Batch Loss: 0.15599480271339417\n",
            "Epoch 1, Batch Loss: 0.1565837562084198\n",
            "Epoch 1, Batch Loss: 0.15022581815719604\n",
            "Epoch 1, Batch Loss: 0.21648871898651123\n",
            "Epoch 1, Batch Loss: 0.21341711282730103\n",
            "Epoch 1, Batch Loss: 0.13192647695541382\n",
            "Epoch 1, Batch Loss: 0.1423385888338089\n",
            "Epoch 1, Batch Loss: 0.13160330057144165\n",
            "Epoch 1, Batch Loss: 0.129102423787117\n",
            "Epoch 1, Batch Loss: 0.15503700077533722\n",
            "Epoch 1, Batch Loss: 0.13123883306980133\n",
            "Epoch 1, Batch Loss: 0.19740627706050873\n",
            "Epoch 1, Batch Loss: 0.1375814974308014\n",
            "Epoch 1, Batch Loss: 0.20023809373378754\n",
            "Epoch 1, Batch Loss: 0.2318732738494873\n",
            "Epoch 1, Batch Loss: 0.1802229881286621\n",
            "Epoch 1, Batch Loss: 0.15934893488883972\n",
            "Epoch 1, Batch Loss: 0.18708756566047668\n",
            "Epoch 1, Batch Loss: 0.1844097226858139\n",
            "Epoch 1, Batch Loss: 0.15534710884094238\n",
            "Epoch 1, Batch Loss: 0.1847132444381714\n",
            "Epoch 1, Batch Loss: 0.15178023278713226\n",
            "Epoch 1, Batch Loss: 0.13609977066516876\n",
            "Epoch 1, Batch Loss: 0.14610633254051208\n",
            "Epoch 1, Batch Loss: 0.15443196892738342\n",
            "Epoch 1, Batch Loss: 0.15914645791053772\n",
            "Epoch 1, Batch Loss: 0.20410937070846558\n",
            "Epoch 1, Batch Loss: 0.12739117443561554\n",
            "Epoch 1, Batch Loss: 0.112410768866539\n",
            "Epoch 1, Batch Loss: 0.20256754755973816\n",
            "Epoch 1, Batch Loss: 0.14410017430782318\n",
            "Epoch 1, Batch Loss: 0.1402454972267151\n",
            "Epoch 1, Batch Loss: 0.14129534363746643\n",
            "Epoch 1, Batch Loss: 0.154100239276886\n",
            "Epoch 1, Batch Loss: 0.12095431238412857\n",
            "Epoch 1, Batch Loss: 0.16088910400867462\n",
            "Epoch 1, Batch Loss: 0.1306697130203247\n",
            "Epoch 1, Batch Loss: 0.11942082643508911\n",
            "Epoch 1, Batch Loss: 0.10656116902828217\n",
            "Epoch 1, Batch Loss: 0.18602001667022705\n",
            "Epoch 1, Batch Loss: 0.11823426932096481\n",
            "Epoch 1, Batch Loss: 0.1536760777235031\n",
            "Epoch 1, Batch Loss: 0.18472138047218323\n",
            "Epoch 1, Batch Loss: 0.15100398659706116\n",
            "Epoch 1, Batch Loss: 0.15481889247894287\n",
            "Epoch 1, Batch Loss: 0.15152625739574432\n",
            "Epoch 1, Batch Loss: 0.15710511803627014\n",
            "Epoch 1, Batch Loss: 0.1307314932346344\n",
            "Epoch 1, Batch Loss: 0.17741461098194122\n",
            "Epoch 1, Batch Loss: 0.17071813344955444\n",
            "Epoch 1, Batch Loss: 0.06721742451190948\n",
            "Epoch 1, Batch Loss: 0.20706796646118164\n",
            "Epoch 1, Batch Loss: 0.13497507572174072\n",
            "Epoch 1, Batch Loss: 0.12284258753061295\n",
            "Epoch 1, Batch Loss: 0.13603229820728302\n",
            "Epoch 1, Batch Loss: 0.15446752309799194\n",
            "Epoch 1, Batch Loss: 0.1554478108882904\n",
            "Epoch 1, Batch Loss: 0.1505155712366104\n",
            "Epoch 1, Epoch Loss: 0.1505155712366104\n",
            "Epoch 2, Batch Loss: 0.16179490089416504\n",
            "Epoch 2, Batch Loss: 0.247666597366333\n",
            "Epoch 2, Batch Loss: 0.1604081243276596\n",
            "Epoch 2, Batch Loss: 0.14705465734004974\n",
            "Epoch 2, Batch Loss: 0.23599225282669067\n",
            "Epoch 2, Batch Loss: 0.16706474125385284\n",
            "Epoch 2, Batch Loss: 0.1935325264930725\n",
            "Epoch 2, Batch Loss: 0.10408446937799454\n",
            "Epoch 2, Batch Loss: 0.16271540522575378\n",
            "Epoch 2, Batch Loss: 0.16854408383369446\n",
            "Epoch 2, Batch Loss: 0.17004075646400452\n",
            "Epoch 2, Batch Loss: 0.19145476818084717\n",
            "Epoch 2, Batch Loss: 0.1760820597410202\n",
            "Epoch 2, Batch Loss: 0.2196251004934311\n",
            "Epoch 2, Batch Loss: 0.2024441808462143\n",
            "Epoch 2, Batch Loss: 0.1436980664730072\n",
            "Epoch 2, Batch Loss: 0.22788208723068237\n",
            "Epoch 2, Batch Loss: 0.19292175769805908\n",
            "Epoch 2, Batch Loss: 0.17501255869865417\n",
            "Epoch 2, Batch Loss: 0.10316362231969833\n",
            "Epoch 2, Batch Loss: 0.16753631830215454\n",
            "Epoch 2, Batch Loss: 0.15982463955879211\n",
            "Epoch 2, Batch Loss: 0.18880869448184967\n",
            "Epoch 2, Batch Loss: 0.15382981300354004\n",
            "Epoch 2, Batch Loss: 0.24732369184494019\n",
            "Epoch 2, Batch Loss: 0.12402571737766266\n",
            "Epoch 2, Batch Loss: 0.14539673924446106\n",
            "Epoch 2, Batch Loss: 0.1412622332572937\n",
            "Epoch 2, Batch Loss: 0.17251896858215332\n",
            "Epoch 2, Batch Loss: 0.23693272471427917\n",
            "Epoch 2, Batch Loss: 0.19653066992759705\n",
            "Epoch 2, Batch Loss: 0.15279409289360046\n",
            "Epoch 2, Batch Loss: 0.15392929315567017\n",
            "Epoch 2, Batch Loss: 0.0876844972372055\n",
            "Epoch 2, Batch Loss: 0.17333143949508667\n",
            "Epoch 2, Batch Loss: 0.21164754033088684\n",
            "Epoch 2, Batch Loss: 0.1396016776561737\n",
            "Epoch 2, Batch Loss: 0.14542384445667267\n",
            "Epoch 2, Batch Loss: 0.19314903020858765\n",
            "Epoch 2, Batch Loss: 0.23578092455863953\n",
            "Epoch 2, Batch Loss: 0.1557898223400116\n",
            "Epoch 2, Batch Loss: 0.21635186672210693\n",
            "Epoch 2, Batch Loss: 0.17287179827690125\n",
            "Epoch 2, Batch Loss: 0.1877402365207672\n",
            "Epoch 2, Batch Loss: 0.1408005654811859\n",
            "Epoch 2, Batch Loss: 0.18692119419574738\n",
            "Epoch 2, Batch Loss: 0.14525793492794037\n",
            "Epoch 2, Batch Loss: 0.20350658893585205\n",
            "Epoch 2, Batch Loss: 0.18029099702835083\n",
            "Epoch 2, Batch Loss: 0.16610029339790344\n",
            "Epoch 2, Batch Loss: 0.2199787199497223\n",
            "Epoch 2, Batch Loss: 0.18396572768688202\n",
            "Epoch 2, Batch Loss: 0.1717010736465454\n",
            "Epoch 2, Batch Loss: 0.21275606751441956\n",
            "Epoch 2, Batch Loss: 0.12542805075645447\n",
            "Epoch 2, Batch Loss: 0.15359847247600555\n",
            "Epoch 2, Batch Loss: 0.1364092230796814\n",
            "Epoch 2, Batch Loss: 0.1177513599395752\n",
            "Epoch 2, Batch Loss: 0.13361868262290955\n",
            "Epoch 2, Batch Loss: 0.16940996050834656\n",
            "Epoch 2, Batch Loss: 0.1702893078327179\n",
            "Epoch 2, Batch Loss: 0.14632350206375122\n",
            "Epoch 2, Batch Loss: 0.1671256721019745\n",
            "Epoch 2, Batch Loss: 0.17915746569633484\n",
            "Epoch 2, Batch Loss: 0.17485755681991577\n",
            "Epoch 2, Batch Loss: 0.17200802266597748\n",
            "Epoch 2, Batch Loss: 0.1581883579492569\n",
            "Epoch 2, Batch Loss: 0.1728765070438385\n",
            "Epoch 2, Batch Loss: 0.15761636197566986\n",
            "Epoch 2, Batch Loss: 0.20312365889549255\n",
            "Epoch 2, Batch Loss: 0.2559840679168701\n",
            "Epoch 2, Batch Loss: 0.14654386043548584\n",
            "Epoch 2, Batch Loss: 0.146202951669693\n",
            "Epoch 2, Batch Loss: 0.177861750125885\n",
            "Epoch 2, Batch Loss: 0.1864396631717682\n",
            "Epoch 2, Batch Loss: 0.11421966552734375\n",
            "Epoch 2, Batch Loss: 0.15854956209659576\n",
            "Epoch 2, Batch Loss: 0.14888203144073486\n",
            "Epoch 2, Batch Loss: 0.16903069615364075\n",
            "Epoch 2, Batch Loss: 0.17474240064620972\n",
            "Epoch 2, Batch Loss: 0.17434336245059967\n",
            "Epoch 2, Batch Loss: 0.12722310423851013\n",
            "Epoch 2, Batch Loss: 0.12211013585329056\n",
            "Epoch 2, Batch Loss: 0.14173051714897156\n",
            "Epoch 2, Batch Loss: 0.1627574861049652\n",
            "Epoch 2, Batch Loss: 0.17894265055656433\n",
            "Epoch 2, Batch Loss: 0.17186349630355835\n",
            "Epoch 2, Batch Loss: 0.1449485719203949\n",
            "Epoch 2, Batch Loss: 0.1620585173368454\n",
            "Epoch 2, Batch Loss: 0.1617405116558075\n",
            "Epoch 2, Batch Loss: 0.11261604726314545\n",
            "Epoch 2, Batch Loss: 0.11847636103630066\n",
            "Epoch 2, Batch Loss: 0.24369759857654572\n",
            "Epoch 2, Batch Loss: 0.1613839864730835\n",
            "Epoch 2, Batch Loss: 0.15556171536445618\n",
            "Epoch 2, Batch Loss: 0.1587221920490265\n",
            "Epoch 2, Batch Loss: 0.0864342749118805\n",
            "Epoch 2, Batch Loss: 0.14154928922653198\n",
            "Epoch 2, Batch Loss: 0.09934528917074203\n",
            "Epoch 2, Batch Loss: 0.11660165339708328\n",
            "Epoch 2, Batch Loss: 0.14308741688728333\n",
            "Epoch 2, Batch Loss: 0.20719456672668457\n",
            "Epoch 2, Batch Loss: 0.0986611470580101\n",
            "Epoch 2, Batch Loss: 0.1776202917098999\n",
            "Epoch 2, Batch Loss: 0.18931040167808533\n",
            "Epoch 2, Batch Loss: 0.17810508608818054\n",
            "Epoch 2, Batch Loss: 0.11089316010475159\n",
            "Epoch 2, Batch Loss: 0.13740336894989014\n",
            "Epoch 2, Batch Loss: 0.1394428312778473\n",
            "Epoch 2, Batch Loss: 0.11650725454092026\n",
            "Epoch 2, Batch Loss: 0.22654953598976135\n",
            "Epoch 2, Batch Loss: 0.12056239694356918\n",
            "Epoch 2, Batch Loss: 0.12114514410495758\n",
            "Epoch 2, Batch Loss: 0.18100763857364655\n",
            "Epoch 2, Batch Loss: 0.11691391468048096\n",
            "Epoch 2, Batch Loss: 0.20066717267036438\n",
            "Epoch 2, Batch Loss: 0.1513923704624176\n",
            "Epoch 2, Batch Loss: 0.13438962399959564\n",
            "Epoch 2, Batch Loss: 0.11034809798002243\n",
            "Epoch 2, Batch Loss: 0.16852229833602905\n",
            "Epoch 2, Batch Loss: 0.13254627585411072\n",
            "Epoch 2, Batch Loss: 0.15108095109462738\n",
            "Epoch 2, Batch Loss: 0.1344217211008072\n",
            "Epoch 2, Batch Loss: 0.215439110994339\n",
            "Epoch 2, Batch Loss: 0.21366342902183533\n",
            "Epoch 2, Batch Loss: 0.19634339213371277\n",
            "Epoch 2, Batch Loss: 0.10696204751729965\n",
            "Epoch 2, Batch Loss: 0.13481824100017548\n",
            "Epoch 2, Batch Loss: 0.12373005598783493\n",
            "Epoch 2, Batch Loss: 0.12833574414253235\n",
            "Epoch 2, Batch Loss: 0.11230691522359848\n",
            "Epoch 2, Batch Loss: 0.15610863268375397\n",
            "Epoch 2, Batch Loss: 0.17687220871448517\n",
            "Epoch 2, Batch Loss: 0.15382911264896393\n",
            "Epoch 2, Batch Loss: 0.1827327311038971\n",
            "Epoch 2, Batch Loss: 0.15050959587097168\n",
            "Epoch 2, Batch Loss: 0.11359991878271103\n",
            "Epoch 2, Batch Loss: 0.19155140221118927\n",
            "Epoch 2, Batch Loss: 0.14346322417259216\n",
            "Epoch 2, Batch Loss: 0.1445002406835556\n",
            "Epoch 2, Batch Loss: 0.18286186456680298\n",
            "Epoch 2, Batch Loss: 0.16694557666778564\n",
            "Epoch 2, Batch Loss: 0.18051880598068237\n",
            "Epoch 2, Batch Loss: 0.18742704391479492\n",
            "Epoch 2, Batch Loss: 0.16928444802761078\n",
            "Epoch 2, Batch Loss: 0.17610865831375122\n",
            "Epoch 2, Batch Loss: 0.14940211176872253\n",
            "Epoch 2, Batch Loss: 0.15629886090755463\n",
            "Epoch 2, Batch Loss: 0.12849107384681702\n",
            "Epoch 2, Batch Loss: 0.24206551909446716\n",
            "Epoch 2, Batch Loss: 0.10459616780281067\n",
            "Epoch 2, Batch Loss: 0.1277480125427246\n",
            "Epoch 2, Batch Loss: 0.2282736599445343\n",
            "Epoch 2, Batch Loss: 0.1915408968925476\n",
            "Epoch 2, Batch Loss: 0.1691940277814865\n",
            "Epoch 2, Batch Loss: 0.17370358109474182\n",
            "Epoch 2, Batch Loss: 0.14825917780399323\n",
            "Epoch 2, Batch Loss: 0.16724388301372528\n",
            "Epoch 2, Batch Loss: 0.14964723587036133\n",
            "Epoch 2, Batch Loss: 0.13500717282295227\n",
            "Epoch 2, Batch Loss: 0.23498179018497467\n",
            "Epoch 2, Batch Loss: 0.15012511610984802\n",
            "Epoch 2, Batch Loss: 0.21322140097618103\n",
            "Epoch 2, Batch Loss: 0.10887660831212997\n",
            "Epoch 2, Batch Loss: 0.14560773968696594\n",
            "Epoch 2, Batch Loss: 0.1822398453950882\n",
            "Epoch 2, Batch Loss: 0.10572880506515503\n",
            "Epoch 2, Batch Loss: 0.11673980951309204\n",
            "Epoch 2, Batch Loss: 0.14978575706481934\n",
            "Epoch 2, Batch Loss: 0.1585233211517334\n",
            "Epoch 2, Batch Loss: 0.16091737151145935\n",
            "Epoch 2, Batch Loss: 0.16345420479774475\n",
            "Epoch 2, Batch Loss: 0.17245635390281677\n",
            "Epoch 2, Batch Loss: 0.15348009765148163\n",
            "Epoch 2, Batch Loss: 0.18710193037986755\n",
            "Epoch 2, Batch Loss: 0.13963991403579712\n",
            "Epoch 2, Batch Loss: 0.17183458805084229\n",
            "Epoch 2, Batch Loss: 0.08605608344078064\n",
            "Epoch 2, Batch Loss: 0.09792649000883102\n",
            "Epoch 2, Batch Loss: 0.2141132950782776\n",
            "Epoch 2, Batch Loss: 0.17223599553108215\n",
            "Epoch 2, Batch Loss: 0.1490345299243927\n",
            "Epoch 2, Batch Loss: 0.15492871403694153\n",
            "Epoch 2, Batch Loss: 0.18971458077430725\n",
            "Epoch 2, Batch Loss: 0.14550697803497314\n",
            "Epoch 2, Batch Loss: 0.16803571581840515\n",
            "Epoch 2, Batch Loss: 0.15861240029335022\n",
            "Epoch 2, Batch Loss: 0.24281682074069977\n",
            "Epoch 2, Batch Loss: 0.15708811581134796\n",
            "Epoch 2, Batch Loss: 0.1924380660057068\n",
            "Epoch 2, Batch Loss: 0.13764135539531708\n",
            "Epoch 2, Batch Loss: 0.15827390551567078\n",
            "Epoch 2, Batch Loss: 0.14759570360183716\n",
            "Epoch 2, Batch Loss: 0.15522000193595886\n",
            "Epoch 2, Batch Loss: 0.11344418674707413\n",
            "Epoch 2, Batch Loss: 0.16517573595046997\n",
            "Epoch 2, Batch Loss: 0.17083260416984558\n",
            "Epoch 2, Batch Loss: 0.18527482450008392\n",
            "Epoch 2, Batch Loss: 0.19834215939044952\n",
            "Epoch 2, Batch Loss: 0.14553065598011017\n",
            "Epoch 2, Batch Loss: 0.22379742562770844\n",
            "Epoch 2, Batch Loss: 0.14843431115150452\n",
            "Epoch 2, Batch Loss: 0.09261465072631836\n",
            "Epoch 2, Batch Loss: 0.139711394906044\n",
            "Epoch 2, Batch Loss: 0.15042123198509216\n",
            "Epoch 2, Batch Loss: 0.1070246696472168\n",
            "Epoch 2, Batch Loss: 0.09132488816976547\n",
            "Epoch 2, Batch Loss: 0.1230422705411911\n",
            "Epoch 2, Batch Loss: 0.178490549325943\n",
            "Epoch 2, Batch Loss: 0.13318674266338348\n",
            "Epoch 2, Batch Loss: 0.21413102746009827\n",
            "Epoch 2, Batch Loss: 0.11380995064973831\n",
            "Epoch 2, Batch Loss: 0.14619719982147217\n",
            "Epoch 2, Batch Loss: 0.13432760536670685\n",
            "Epoch 2, Batch Loss: 0.20296013355255127\n",
            "Epoch 2, Batch Loss: 0.1547226458787918\n",
            "Epoch 2, Batch Loss: 0.1913776993751526\n",
            "Epoch 2, Batch Loss: 0.19029387831687927\n",
            "Epoch 2, Batch Loss: 0.15118637681007385\n",
            "Epoch 2, Batch Loss: 0.13722670078277588\n",
            "Epoch 2, Batch Loss: 0.1245778501033783\n",
            "Epoch 2, Batch Loss: 0.09088388830423355\n",
            "Epoch 2, Batch Loss: 0.10738223046064377\n",
            "Epoch 2, Batch Loss: 0.2751655876636505\n",
            "Epoch 2, Batch Loss: 0.10657759010791779\n",
            "Epoch 2, Batch Loss: 0.15280508995056152\n",
            "Epoch 2, Batch Loss: 0.1788509488105774\n",
            "Epoch 2, Batch Loss: 0.13154280185699463\n",
            "Epoch 2, Batch Loss: 0.1313987821340561\n",
            "Epoch 2, Batch Loss: 0.1811702847480774\n",
            "Epoch 2, Batch Loss: 0.09597180783748627\n",
            "Epoch 2, Batch Loss: 0.21711090207099915\n",
            "Epoch 2, Batch Loss: 0.1314147561788559\n",
            "Epoch 2, Batch Loss: 0.09396253526210785\n",
            "Epoch 2, Batch Loss: 0.16026601195335388\n",
            "Epoch 2, Batch Loss: 0.15699312090873718\n",
            "Epoch 2, Batch Loss: 0.18952228128910065\n",
            "Epoch 2, Batch Loss: 0.14215633273124695\n",
            "Epoch 2, Batch Loss: 0.19435769319534302\n",
            "Epoch 2, Batch Loss: 0.11881321668624878\n",
            "Epoch 2, Batch Loss: 0.0768650472164154\n",
            "Epoch 2, Batch Loss: 0.17740045487880707\n",
            "Epoch 2, Batch Loss: 0.17956936359405518\n",
            "Epoch 2, Batch Loss: 0.15756399929523468\n",
            "Epoch 2, Batch Loss: 0.11523272097110748\n",
            "Epoch 2, Batch Loss: 0.13837094604969025\n",
            "Epoch 2, Batch Loss: 0.1569059193134308\n",
            "Epoch 2, Batch Loss: 0.10397151112556458\n",
            "Epoch 2, Batch Loss: 0.1481514722108841\n",
            "Epoch 2, Batch Loss: 0.22285541892051697\n",
            "Epoch 2, Batch Loss: 0.19357511401176453\n",
            "Epoch 2, Batch Loss: 0.16319885849952698\n",
            "Epoch 2, Batch Loss: 0.1699538677930832\n",
            "Epoch 2, Batch Loss: 0.15880835056304932\n",
            "Epoch 2, Batch Loss: 0.12559807300567627\n",
            "Epoch 2, Batch Loss: 0.2036675214767456\n",
            "Epoch 2, Batch Loss: 0.1567780077457428\n",
            "Epoch 2, Batch Loss: 0.13542619347572327\n",
            "Epoch 2, Batch Loss: 0.18520475924015045\n",
            "Epoch 2, Batch Loss: 0.19082358479499817\n",
            "Epoch 2, Batch Loss: 0.1509585678577423\n",
            "Epoch 2, Batch Loss: 0.1546478569507599\n",
            "Epoch 2, Batch Loss: 0.16212740540504456\n",
            "Epoch 2, Batch Loss: 0.13899512588977814\n",
            "Epoch 2, Batch Loss: 0.13017043471336365\n",
            "Epoch 2, Batch Loss: 0.20987501740455627\n",
            "Epoch 2, Batch Loss: 0.11627782136201859\n",
            "Epoch 2, Batch Loss: 0.12718425691127777\n",
            "Epoch 2, Batch Loss: 0.1513364464044571\n",
            "Epoch 2, Batch Loss: 0.16352786123752594\n",
            "Epoch 2, Batch Loss: 0.16837748885154724\n",
            "Epoch 2, Batch Loss: 0.139135479927063\n",
            "Epoch 2, Batch Loss: 0.1906101405620575\n",
            "Epoch 2, Batch Loss: 0.17756816744804382\n",
            "Epoch 2, Batch Loss: 0.12310691922903061\n",
            "Epoch 2, Batch Loss: 0.1543900966644287\n",
            "Epoch 2, Batch Loss: 0.12157590687274933\n",
            "Epoch 2, Batch Loss: 0.19524332880973816\n",
            "Epoch 2, Batch Loss: 0.11462447047233582\n",
            "Epoch 2, Batch Loss: 0.1561695635318756\n",
            "Epoch 2, Batch Loss: 0.1480763852596283\n",
            "Epoch 2, Batch Loss: 0.14546111226081848\n",
            "Epoch 2, Batch Loss: 0.12761832773685455\n",
            "Epoch 2, Batch Loss: 0.16369082033634186\n",
            "Epoch 2, Batch Loss: 0.12308454513549805\n",
            "Epoch 2, Batch Loss: 0.15274129807949066\n",
            "Epoch 2, Batch Loss: 0.21332606673240662\n",
            "Epoch 2, Batch Loss: 0.16434040665626526\n",
            "Epoch 2, Batch Loss: 0.1884995400905609\n",
            "Epoch 2, Batch Loss: 0.17557592689990997\n",
            "Epoch 2, Batch Loss: 0.18214885890483856\n",
            "Epoch 2, Batch Loss: 0.1735251545906067\n",
            "Epoch 2, Batch Loss: 0.12454883754253387\n",
            "Epoch 2, Batch Loss: 0.18322503566741943\n",
            "Epoch 2, Batch Loss: 0.0972847044467926\n",
            "Epoch 2, Batch Loss: 0.11749684810638428\n",
            "Epoch 2, Batch Loss: 0.14595302939414978\n",
            "Epoch 2, Batch Loss: 0.1495434045791626\n",
            "Epoch 2, Batch Loss: 0.1512496918439865\n",
            "Epoch 2, Batch Loss: 0.18676543235778809\n",
            "Epoch 2, Batch Loss: 0.1629570722579956\n",
            "Epoch 2, Batch Loss: 0.21369974315166473\n",
            "Epoch 2, Batch Loss: 0.1720844954252243\n",
            "Epoch 2, Batch Loss: 0.15929260849952698\n",
            "Epoch 2, Batch Loss: 0.1780719757080078\n",
            "Epoch 2, Batch Loss: 0.1572359800338745\n",
            "Epoch 2, Batch Loss: 0.14314979314804077\n",
            "Epoch 2, Batch Loss: 0.16503019630908966\n",
            "Epoch 2, Batch Loss: 0.22043001651763916\n",
            "Epoch 2, Batch Loss: 0.11148664355278015\n",
            "Epoch 2, Batch Loss: 0.10607679933309555\n",
            "Epoch 2, Batch Loss: 0.11181826144456863\n",
            "Epoch 2, Batch Loss: 0.12708495557308197\n",
            "Epoch 2, Batch Loss: 0.2059641182422638\n",
            "Epoch 2, Batch Loss: 0.19238561391830444\n",
            "Epoch 2, Batch Loss: 0.1210358515381813\n",
            "Epoch 2, Batch Loss: 0.14027667045593262\n",
            "Epoch 2, Batch Loss: 0.13296900689601898\n",
            "Epoch 2, Batch Loss: 0.21560779213905334\n",
            "Epoch 2, Batch Loss: 0.1785767823457718\n",
            "Epoch 2, Batch Loss: 0.1571655422449112\n",
            "Epoch 2, Batch Loss: 0.2497328221797943\n",
            "Epoch 2, Batch Loss: 0.18377074599266052\n",
            "Epoch 2, Batch Loss: 0.19671565294265747\n",
            "Epoch 2, Batch Loss: 0.22541025280952454\n",
            "Epoch 2, Batch Loss: 0.1275578737258911\n",
            "Epoch 2, Batch Loss: 0.20592105388641357\n",
            "Epoch 2, Batch Loss: 0.1225941851735115\n",
            "Epoch 2, Batch Loss: 0.15242472290992737\n",
            "Epoch 2, Batch Loss: 0.12715879082679749\n",
            "Epoch 2, Batch Loss: 0.14560210704803467\n",
            "Epoch 2, Batch Loss: 0.17132213711738586\n",
            "Epoch 2, Batch Loss: 0.13894009590148926\n",
            "Epoch 2, Batch Loss: 0.12588228285312653\n",
            "Epoch 2, Batch Loss: 0.17343366146087646\n",
            "Epoch 2, Batch Loss: 0.1381460726261139\n",
            "Epoch 2, Batch Loss: 0.1664542853832245\n",
            "Epoch 2, Batch Loss: 0.12291274219751358\n",
            "Epoch 2, Batch Loss: 0.14910730719566345\n",
            "Epoch 2, Batch Loss: 0.23704831302165985\n",
            "Epoch 2, Batch Loss: 0.11517892777919769\n",
            "Epoch 2, Batch Loss: 0.12450239062309265\n",
            "Epoch 2, Batch Loss: 0.17581215500831604\n",
            "Epoch 2, Batch Loss: 0.1677396595478058\n",
            "Epoch 2, Batch Loss: 0.1411263346672058\n",
            "Epoch 2, Batch Loss: 0.15197066962718964\n",
            "Epoch 2, Batch Loss: 0.18896843492984772\n",
            "Epoch 2, Batch Loss: 0.1067342609167099\n",
            "Epoch 2, Batch Loss: 0.21136599779129028\n",
            "Epoch 2, Batch Loss: 0.12992791831493378\n",
            "Epoch 2, Batch Loss: 0.13994356989860535\n",
            "Epoch 2, Batch Loss: 0.15532521903514862\n",
            "Epoch 2, Batch Loss: 0.16995954513549805\n",
            "Epoch 2, Batch Loss: 0.2007041573524475\n",
            "Epoch 2, Batch Loss: 0.14022032916545868\n",
            "Epoch 2, Batch Loss: 0.12176238745450974\n",
            "Epoch 2, Batch Loss: 0.16465722024440765\n",
            "Epoch 2, Batch Loss: 0.11824551224708557\n",
            "Epoch 2, Batch Loss: 0.17016372084617615\n",
            "Epoch 2, Batch Loss: 0.15408602356910706\n",
            "Epoch 2, Batch Loss: 0.15299378335475922\n",
            "Epoch 2, Batch Loss: 0.18528781831264496\n",
            "Epoch 2, Batch Loss: 0.1018586978316307\n",
            "Epoch 2, Batch Loss: 0.1429407149553299\n",
            "Epoch 2, Batch Loss: 0.08685454726219177\n",
            "Epoch 2, Batch Loss: 0.12777777016162872\n",
            "Epoch 2, Batch Loss: 0.2339928299188614\n",
            "Epoch 2, Batch Loss: 0.22123153507709503\n",
            "Epoch 2, Batch Loss: 0.14322656393051147\n",
            "Epoch 2, Batch Loss: 0.15365339815616608\n",
            "Epoch 2, Batch Loss: 0.17082151770591736\n",
            "Epoch 2, Batch Loss: 0.14667370915412903\n",
            "Epoch 2, Batch Loss: 0.1960531622171402\n",
            "Epoch 2, Batch Loss: 0.11026207357645035\n",
            "Epoch 2, Batch Loss: 0.18556754291057587\n",
            "Epoch 2, Batch Loss: 0.15030136704444885\n",
            "Epoch 2, Batch Loss: 0.15504388511180878\n",
            "Epoch 2, Batch Loss: 0.15421992540359497\n",
            "Epoch 2, Batch Loss: 0.09983686357736588\n",
            "Epoch 2, Batch Loss: 0.12973156571388245\n",
            "Epoch 2, Batch Loss: 0.20350323617458344\n",
            "Epoch 2, Batch Loss: 0.15390385687351227\n",
            "Epoch 2, Batch Loss: 0.21517664194107056\n",
            "Epoch 2, Batch Loss: 0.182514488697052\n",
            "Epoch 2, Batch Loss: 0.1456543505191803\n",
            "Epoch 2, Batch Loss: 0.19071508944034576\n",
            "Epoch 2, Batch Loss: 0.12817725539207458\n",
            "Epoch 2, Batch Loss: 0.18478067219257355\n",
            "Epoch 2, Batch Loss: 0.1455853283405304\n",
            "Epoch 2, Batch Loss: 0.15085312724113464\n",
            "Epoch 2, Batch Loss: 0.19168372452259064\n",
            "Epoch 2, Batch Loss: 0.11769824475049973\n",
            "Epoch 2, Batch Loss: 0.17102672159671783\n",
            "Epoch 2, Batch Loss: 0.12885811924934387\n",
            "Epoch 2, Batch Loss: 0.13578945398330688\n",
            "Epoch 2, Batch Loss: 0.2063232809305191\n",
            "Epoch 2, Batch Loss: 0.12132620066404343\n",
            "Epoch 2, Batch Loss: 0.178582563996315\n",
            "Epoch 2, Batch Loss: 0.10404682159423828\n",
            "Epoch 2, Batch Loss: 0.15915361046791077\n",
            "Epoch 2, Batch Loss: 0.1011124774813652\n",
            "Epoch 2, Batch Loss: 0.130510613322258\n",
            "Epoch 2, Batch Loss: 0.14437606930732727\n",
            "Epoch 2, Batch Loss: 0.1355687826871872\n",
            "Epoch 2, Batch Loss: 0.15760089457035065\n",
            "Epoch 2, Batch Loss: 0.18486812710762024\n",
            "Epoch 2, Batch Loss: 0.12175363302230835\n",
            "Epoch 2, Batch Loss: 0.1512412428855896\n",
            "Epoch 2, Batch Loss: 0.15338517725467682\n",
            "Epoch 2, Batch Loss: 0.17855000495910645\n",
            "Epoch 2, Batch Loss: 0.15456512570381165\n",
            "Epoch 2, Batch Loss: 0.17634645104408264\n",
            "Epoch 2, Batch Loss: 0.0970660075545311\n",
            "Epoch 2, Batch Loss: 0.19975215196609497\n",
            "Epoch 2, Batch Loss: 0.12042662501335144\n",
            "Epoch 2, Batch Loss: 0.1310713291168213\n",
            "Epoch 2, Batch Loss: 0.18168474733829498\n",
            "Epoch 2, Batch Loss: 0.21323277056217194\n",
            "Epoch 2, Batch Loss: 0.1410980373620987\n",
            "Epoch 2, Batch Loss: 0.0929538756608963\n",
            "Epoch 2, Batch Loss: 0.13607704639434814\n",
            "Epoch 2, Batch Loss: 0.1059749573469162\n",
            "Epoch 2, Batch Loss: 0.13240869343280792\n",
            "Epoch 2, Batch Loss: 0.15248119831085205\n",
            "Epoch 2, Batch Loss: 0.16003090143203735\n",
            "Epoch 2, Batch Loss: 0.21029454469680786\n",
            "Epoch 2, Batch Loss: 0.1306302398443222\n",
            "Epoch 2, Batch Loss: 0.16593411564826965\n",
            "Epoch 2, Batch Loss: 0.10471803694963455\n",
            "Epoch 2, Batch Loss: 0.12623198330402374\n",
            "Epoch 2, Batch Loss: 0.1367270052433014\n",
            "Epoch 2, Batch Loss: 0.121314138174057\n",
            "Epoch 2, Batch Loss: 0.2320653796195984\n",
            "Epoch 2, Batch Loss: 0.1078893393278122\n",
            "Epoch 2, Batch Loss: 0.18582212924957275\n",
            "Epoch 2, Batch Loss: 0.1499331295490265\n",
            "Epoch 2, Batch Loss: 0.16601529717445374\n",
            "Epoch 2, Batch Loss: 0.11953267455101013\n",
            "Epoch 2, Batch Loss: 0.1777448207139969\n",
            "Epoch 2, Batch Loss: 0.16420243680477142\n",
            "Epoch 2, Batch Loss: 0.13263703882694244\n",
            "Epoch 2, Batch Loss: 0.12457551807165146\n",
            "Epoch 2, Batch Loss: 0.17795604467391968\n",
            "Epoch 2, Batch Loss: 0.170722097158432\n",
            "Epoch 2, Batch Loss: 0.13802136480808258\n",
            "Epoch 2, Batch Loss: 0.19191041588783264\n",
            "Epoch 2, Batch Loss: 0.17034831643104553\n",
            "Epoch 2, Batch Loss: 0.21292127668857574\n",
            "Epoch 2, Batch Loss: 0.11950911581516266\n",
            "Epoch 2, Batch Loss: 0.12132548540830612\n",
            "Epoch 2, Batch Loss: 0.08700677752494812\n",
            "Epoch 2, Batch Loss: 0.14420431852340698\n",
            "Epoch 2, Batch Loss: 0.15296310186386108\n",
            "Epoch 2, Batch Loss: 0.13623768091201782\n",
            "Epoch 2, Batch Loss: 0.10901141166687012\n",
            "Epoch 2, Batch Loss: 0.17707151174545288\n",
            "Epoch 2, Batch Loss: 0.16889558732509613\n",
            "Epoch 2, Batch Loss: 0.08301927149295807\n",
            "Epoch 2, Batch Loss: 0.10025452822446823\n",
            "Epoch 2, Batch Loss: 0.16481558978557587\n",
            "Epoch 2, Batch Loss: 0.19280099868774414\n",
            "Epoch 2, Batch Loss: 0.1194908618927002\n",
            "Epoch 2, Batch Loss: 0.16533493995666504\n",
            "Epoch 2, Batch Loss: 0.1490214765071869\n",
            "Epoch 2, Batch Loss: 0.08320125937461853\n",
            "Epoch 2, Batch Loss: 0.1926763951778412\n",
            "Epoch 2, Batch Loss: 0.148251473903656\n",
            "Epoch 2, Batch Loss: 0.15883606672286987\n",
            "Epoch 2, Batch Loss: 0.12751054763793945\n",
            "Epoch 2, Batch Loss: 0.0879211574792862\n",
            "Epoch 2, Batch Loss: 0.15559664368629456\n",
            "Epoch 2, Batch Loss: 0.12780366837978363\n",
            "Epoch 2, Batch Loss: 0.20667105913162231\n",
            "Epoch 2, Batch Loss: 0.18713028728961945\n",
            "Epoch 2, Batch Loss: 0.13604949414730072\n",
            "Epoch 2, Batch Loss: 0.1983867883682251\n",
            "Epoch 2, Batch Loss: 0.15772633254528046\n",
            "Epoch 2, Batch Loss: 0.17854323983192444\n",
            "Epoch 2, Batch Loss: 0.15116670727729797\n",
            "Epoch 2, Batch Loss: 0.18690012395381927\n",
            "Epoch 2, Batch Loss: 0.10952166467905045\n",
            "Epoch 2, Batch Loss: 0.1845705807209015\n",
            "Epoch 2, Batch Loss: 0.19767947494983673\n",
            "Epoch 2, Batch Loss: 0.11903861165046692\n",
            "Epoch 2, Batch Loss: 0.1792220175266266\n",
            "Epoch 2, Batch Loss: 0.11003006994724274\n",
            "Epoch 2, Batch Loss: 0.15869438648223877\n",
            "Epoch 2, Batch Loss: 0.12689730525016785\n",
            "Epoch 2, Batch Loss: 0.17431588470935822\n",
            "Epoch 2, Batch Loss: 0.18833960592746735\n",
            "Epoch 2, Batch Loss: 0.15444375574588776\n",
            "Epoch 2, Batch Loss: 0.14568163454532623\n",
            "Epoch 2, Batch Loss: 0.2116149365901947\n",
            "Epoch 2, Batch Loss: 0.1622922569513321\n",
            "Epoch 2, Batch Loss: 0.10868114233016968\n",
            "Epoch 2, Batch Loss: 0.14167693257331848\n",
            "Epoch 2, Batch Loss: 0.14511778950691223\n",
            "Epoch 2, Batch Loss: 0.19050809741020203\n",
            "Epoch 2, Batch Loss: 0.15354090929031372\n",
            "Epoch 2, Batch Loss: 0.12935709953308105\n",
            "Epoch 2, Batch Loss: 0.21061566472053528\n",
            "Epoch 2, Batch Loss: 0.15575167536735535\n",
            "Epoch 2, Batch Loss: 0.14677926898002625\n",
            "Epoch 2, Batch Loss: 0.12874151766300201\n",
            "Epoch 2, Batch Loss: 0.1496489942073822\n",
            "Epoch 2, Batch Loss: 0.13421577215194702\n",
            "Epoch 2, Batch Loss: 0.18866531550884247\n",
            "Epoch 2, Batch Loss: 0.16598482429981232\n",
            "Epoch 2, Batch Loss: 0.19264015555381775\n",
            "Epoch 2, Batch Loss: 0.18408429622650146\n",
            "Epoch 2, Batch Loss: 0.16160309314727783\n",
            "Epoch 2, Batch Loss: 0.12877961993217468\n",
            "Epoch 2, Batch Loss: 0.1523674577474594\n",
            "Epoch 2, Batch Loss: 0.1390758752822876\n",
            "Epoch 2, Batch Loss: 0.09406702220439911\n",
            "Epoch 2, Batch Loss: 0.10146215558052063\n",
            "Epoch 2, Batch Loss: 0.15102523565292358\n",
            "Epoch 2, Batch Loss: 0.12854620814323425\n",
            "Epoch 2, Batch Loss: 0.15206566452980042\n",
            "Epoch 2, Batch Loss: 0.14065268635749817\n",
            "Epoch 2, Batch Loss: 0.1822909116744995\n",
            "Epoch 2, Batch Loss: 0.19290171563625336\n",
            "Epoch 2, Batch Loss: 0.16408130526542664\n",
            "Epoch 2, Batch Loss: 0.12607598304748535\n",
            "Epoch 2, Batch Loss: 0.14655701816082\n",
            "Epoch 2, Batch Loss: 0.1668071746826172\n",
            "Epoch 2, Batch Loss: 0.1423107087612152\n",
            "Epoch 2, Batch Loss: 0.17595459520816803\n",
            "Epoch 2, Batch Loss: 0.10785339772701263\n",
            "Epoch 2, Batch Loss: 0.14228197932243347\n",
            "Epoch 2, Batch Loss: 0.13903936743736267\n",
            "Epoch 2, Batch Loss: 0.12067709863185883\n",
            "Epoch 2, Batch Loss: 0.16128090023994446\n",
            "Epoch 2, Batch Loss: 0.16128025949001312\n",
            "Epoch 2, Batch Loss: 0.1598476767539978\n",
            "Epoch 2, Batch Loss: 0.1103295236825943\n",
            "Epoch 2, Batch Loss: 0.10686028003692627\n",
            "Epoch 2, Batch Loss: 0.20448769629001617\n",
            "Epoch 2, Batch Loss: 0.17947843670845032\n",
            "Epoch 2, Batch Loss: 0.17176365852355957\n",
            "Epoch 2, Batch Loss: 0.12043783813714981\n",
            "Epoch 2, Batch Loss: 0.1966782808303833\n",
            "Epoch 2, Batch Loss: 0.13182026147842407\n",
            "Epoch 2, Batch Loss: 0.10795102268457413\n",
            "Epoch 2, Batch Loss: 0.07840708643198013\n",
            "Epoch 2, Batch Loss: 0.15146538615226746\n",
            "Epoch 2, Batch Loss: 0.18326438963413239\n",
            "Epoch 2, Batch Loss: 0.09890593588352203\n",
            "Epoch 2, Batch Loss: 0.13337190449237823\n",
            "Epoch 2, Batch Loss: 0.15270736813545227\n",
            "Epoch 2, Batch Loss: 0.05469745397567749\n",
            "Epoch 2, Batch Loss: 0.13306769728660583\n",
            "Epoch 2, Batch Loss: 0.14266495406627655\n",
            "Epoch 2, Batch Loss: 0.14761285483837128\n",
            "Epoch 2, Batch Loss: 0.13488426804542542\n",
            "Epoch 2, Batch Loss: 0.14178241789340973\n",
            "Epoch 2, Batch Loss: 0.13990457355976105\n",
            "Epoch 2, Batch Loss: 0.1061212569475174\n",
            "Epoch 2, Batch Loss: 0.1337035447359085\n",
            "Epoch 2, Batch Loss: 0.10581212490797043\n",
            "Epoch 2, Batch Loss: 0.1521526277065277\n",
            "Epoch 2, Batch Loss: 0.11550897359848022\n",
            "Epoch 2, Batch Loss: 0.20190975069999695\n",
            "Epoch 2, Batch Loss: 0.15876564383506775\n",
            "Epoch 2, Batch Loss: 0.13195382058620453\n",
            "Epoch 2, Batch Loss: 0.12806130945682526\n",
            "Epoch 2, Batch Loss: 0.15379416942596436\n",
            "Epoch 2, Batch Loss: 0.1253071427345276\n",
            "Epoch 2, Batch Loss: 0.14152061939239502\n",
            "Epoch 2, Batch Loss: 0.11667022854089737\n",
            "Epoch 2, Batch Loss: 0.10474522411823273\n",
            "Epoch 2, Batch Loss: 0.17692434787750244\n",
            "Epoch 2, Batch Loss: 0.10849106311798096\n",
            "Epoch 2, Batch Loss: 0.13846883177757263\n",
            "Epoch 2, Batch Loss: 0.14190182089805603\n",
            "Epoch 2, Batch Loss: 0.13897252082824707\n",
            "Epoch 2, Batch Loss: 0.244608074426651\n",
            "Epoch 2, Batch Loss: 0.17729641497135162\n",
            "Epoch 2, Batch Loss: 0.13566064834594727\n",
            "Epoch 2, Batch Loss: 0.12399398535490036\n",
            "Epoch 2, Batch Loss: 0.1911170929670334\n",
            "Epoch 2, Batch Loss: 0.20706701278686523\n",
            "Epoch 2, Batch Loss: 0.15204277634620667\n",
            "Epoch 2, Batch Loss: 0.11639857292175293\n",
            "Epoch 2, Batch Loss: 0.18312636017799377\n",
            "Epoch 2, Batch Loss: 0.1981492042541504\n",
            "Epoch 2, Batch Loss: 0.1076539009809494\n",
            "Epoch 2, Batch Loss: 0.18948538601398468\n",
            "Epoch 2, Batch Loss: 0.1717231571674347\n",
            "Epoch 2, Batch Loss: 0.14143620431423187\n",
            "Epoch 2, Batch Loss: 0.1790010631084442\n",
            "Epoch 2, Batch Loss: 0.13614726066589355\n",
            "Epoch 2, Batch Loss: 0.16828510165214539\n",
            "Epoch 2, Batch Loss: 0.1596878468990326\n",
            "Epoch 2, Batch Loss: 0.13742613792419434\n",
            "Epoch 2, Batch Loss: 0.17627006769180298\n",
            "Epoch 2, Batch Loss: 0.21186672151088715\n",
            "Epoch 2, Batch Loss: 0.1108756959438324\n",
            "Epoch 2, Batch Loss: 0.09280318021774292\n",
            "Epoch 2, Batch Loss: 0.13742397725582123\n",
            "Epoch 2, Batch Loss: 0.1735997200012207\n",
            "Epoch 2, Batch Loss: 0.14481940865516663\n",
            "Epoch 2, Batch Loss: 0.07985129952430725\n",
            "Epoch 2, Batch Loss: 0.1496366709470749\n",
            "Epoch 2, Batch Loss: 0.10508772730827332\n",
            "Epoch 2, Batch Loss: 0.21559195220470428\n",
            "Epoch 2, Batch Loss: 0.1301238238811493\n",
            "Epoch 2, Batch Loss: 0.14407747983932495\n",
            "Epoch 2, Batch Loss: 0.14940422773361206\n",
            "Epoch 2, Batch Loss: 0.1493760198354721\n",
            "Epoch 2, Batch Loss: 0.14417868852615356\n",
            "Epoch 2, Batch Loss: 0.13524378836154938\n",
            "Epoch 2, Batch Loss: 0.15334121882915497\n",
            "Epoch 2, Batch Loss: 0.1093878298997879\n",
            "Epoch 2, Batch Loss: 0.1685326099395752\n",
            "Epoch 2, Batch Loss: 0.12187197059392929\n",
            "Epoch 2, Batch Loss: 0.13474294543266296\n",
            "Epoch 2, Batch Loss: 0.11255649477243423\n",
            "Epoch 2, Batch Loss: 0.14907769858837128\n",
            "Epoch 2, Batch Loss: 0.1451248824596405\n",
            "Epoch 2, Batch Loss: 0.1678873896598816\n",
            "Epoch 2, Batch Loss: 0.18379808962345123\n",
            "Epoch 2, Batch Loss: 0.18124690651893616\n",
            "Epoch 2, Batch Loss: 0.1446058601140976\n",
            "Epoch 2, Batch Loss: 0.20231202244758606\n",
            "Epoch 2, Batch Loss: 0.13883811235427856\n",
            "Epoch 2, Batch Loss: 0.15451115369796753\n",
            "Epoch 2, Batch Loss: 0.18236997723579407\n",
            "Epoch 2, Batch Loss: 0.1893749237060547\n",
            "Epoch 2, Batch Loss: 0.17285087704658508\n",
            "Epoch 2, Batch Loss: 0.14049559831619263\n",
            "Epoch 2, Batch Loss: 0.16879461705684662\n",
            "Epoch 2, Batch Loss: 0.14716582000255585\n",
            "Epoch 2, Batch Loss: 0.09473208338022232\n",
            "Epoch 2, Batch Loss: 0.15942808985710144\n",
            "Epoch 2, Batch Loss: 0.15936222672462463\n",
            "Epoch 2, Batch Loss: 0.07550974190235138\n",
            "Epoch 2, Batch Loss: 0.15020626783370972\n",
            "Epoch 2, Batch Loss: 0.20598050951957703\n",
            "Epoch 2, Batch Loss: 0.14055341482162476\n",
            "Epoch 2, Batch Loss: 0.10617685317993164\n",
            "Epoch 2, Batch Loss: 0.20192945003509521\n",
            "Epoch 2, Batch Loss: 0.18616120517253876\n",
            "Epoch 2, Batch Loss: 0.15653881430625916\n",
            "Epoch 2, Batch Loss: 0.20676448941230774\n",
            "Epoch 2, Batch Loss: 0.16797514259815216\n",
            "Epoch 2, Batch Loss: 0.1878887414932251\n",
            "Epoch 2, Batch Loss: 0.16172732412815094\n",
            "Epoch 2, Batch Loss: 0.1798543930053711\n",
            "Epoch 2, Batch Loss: 0.17806710302829742\n",
            "Epoch 2, Batch Loss: 0.15369126200675964\n",
            "Epoch 2, Batch Loss: 0.1899704933166504\n",
            "Epoch 2, Batch Loss: 0.14800912141799927\n",
            "Epoch 2, Batch Loss: 0.17226696014404297\n",
            "Epoch 2, Batch Loss: 0.2030213326215744\n",
            "Epoch 2, Batch Loss: 0.10637218505144119\n",
            "Epoch 2, Batch Loss: 0.07577361166477203\n",
            "Epoch 2, Batch Loss: 0.11326596140861511\n",
            "Epoch 2, Batch Loss: 0.1699879765510559\n",
            "Epoch 2, Batch Loss: 0.18680748343467712\n",
            "Epoch 2, Batch Loss: 0.18713760375976562\n",
            "Epoch 2, Batch Loss: 0.16635960340499878\n",
            "Epoch 2, Batch Loss: 0.18004098534584045\n",
            "Epoch 2, Batch Loss: 0.1052250862121582\n",
            "Epoch 2, Batch Loss: 0.14215146005153656\n",
            "Epoch 2, Batch Loss: 0.14861345291137695\n",
            "Epoch 2, Batch Loss: 0.14284451305866241\n",
            "Epoch 2, Batch Loss: 0.15508811175823212\n",
            "Epoch 2, Batch Loss: 0.13940227031707764\n",
            "Epoch 2, Batch Loss: 0.15604087710380554\n",
            "Epoch 2, Batch Loss: 0.12961798906326294\n",
            "Epoch 2, Batch Loss: 0.14927588403224945\n",
            "Epoch 2, Batch Loss: 0.20514020323753357\n",
            "Epoch 2, Batch Loss: 0.1361432671546936\n",
            "Epoch 2, Batch Loss: 0.11566765606403351\n",
            "Epoch 2, Batch Loss: 0.19657547771930695\n",
            "Epoch 2, Batch Loss: 0.12528426945209503\n",
            "Epoch 2, Batch Loss: 0.17038339376449585\n",
            "Epoch 2, Batch Loss: 0.08873604238033295\n",
            "Epoch 2, Batch Loss: 0.19879066944122314\n",
            "Epoch 2, Batch Loss: 0.18397164344787598\n",
            "Epoch 2, Batch Loss: 0.21182407438755035\n",
            "Epoch 2, Batch Loss: 0.18493889272212982\n",
            "Epoch 2, Batch Loss: 0.16011697053909302\n",
            "Epoch 2, Batch Loss: 0.1745581328868866\n",
            "Epoch 2, Batch Loss: 0.1332613229751587\n",
            "Epoch 2, Batch Loss: 0.1735917031764984\n",
            "Epoch 2, Batch Loss: 0.13244928419589996\n",
            "Epoch 2, Batch Loss: 0.20617763698101044\n",
            "Epoch 2, Batch Loss: 0.1669624000787735\n",
            "Epoch 2, Batch Loss: 0.19319353997707367\n",
            "Epoch 2, Batch Loss: 0.19683223962783813\n",
            "Epoch 2, Batch Loss: 0.16987968981266022\n",
            "Epoch 2, Batch Loss: 0.17920273542404175\n",
            "Epoch 2, Batch Loss: 0.17952939867973328\n",
            "Epoch 2, Batch Loss: 0.16356346011161804\n",
            "Epoch 2, Batch Loss: 0.08828552812337875\n",
            "Epoch 2, Batch Loss: 0.11793683469295502\n",
            "Epoch 2, Batch Loss: 0.1324610412120819\n",
            "Epoch 2, Batch Loss: 0.11475619673728943\n",
            "Epoch 2, Batch Loss: 0.10459563136100769\n",
            "Epoch 2, Batch Loss: 0.15789993107318878\n",
            "Epoch 2, Batch Loss: 0.20268268883228302\n",
            "Epoch 2, Batch Loss: 0.13887007534503937\n",
            "Epoch 2, Batch Loss: 0.1195143312215805\n",
            "Epoch 2, Batch Loss: 0.12578529119491577\n",
            "Epoch 2, Batch Loss: 0.1608712077140808\n",
            "Epoch 2, Batch Loss: 0.21805670857429504\n",
            "Epoch 2, Batch Loss: 0.12683098018169403\n",
            "Epoch 2, Batch Loss: 0.18098381161689758\n",
            "Epoch 2, Batch Loss: 0.18838787078857422\n",
            "Epoch 2, Batch Loss: 0.24999600648880005\n",
            "Epoch 2, Batch Loss: 0.16006535291671753\n",
            "Epoch 2, Batch Loss: 0.15304893255233765\n",
            "Epoch 2, Batch Loss: 0.17073282599449158\n",
            "Epoch 2, Batch Loss: 0.10648283362388611\n",
            "Epoch 2, Batch Loss: 0.15837056934833527\n",
            "Epoch 2, Batch Loss: 0.1419445425271988\n",
            "Epoch 2, Batch Loss: 0.1455063670873642\n",
            "Epoch 2, Batch Loss: 0.17373794317245483\n",
            "Epoch 2, Batch Loss: 0.10380686819553375\n",
            "Epoch 2, Batch Loss: 0.13021616637706757\n",
            "Epoch 2, Batch Loss: 0.14538875222206116\n",
            "Epoch 2, Batch Loss: 0.13374149799346924\n",
            "Epoch 2, Batch Loss: 0.17044392228126526\n",
            "Epoch 2, Batch Loss: 0.25503161549568176\n",
            "Epoch 2, Batch Loss: 0.1507602035999298\n",
            "Epoch 2, Batch Loss: 0.14031082391738892\n",
            "Epoch 2, Batch Loss: 0.14020311832427979\n",
            "Epoch 2, Batch Loss: 0.15125097334384918\n",
            "Epoch 2, Batch Loss: 0.09700331091880798\n",
            "Epoch 2, Batch Loss: 0.17325541377067566\n",
            "Epoch 2, Batch Loss: 0.11415833234786987\n",
            "Epoch 2, Batch Loss: 0.09961795061826706\n",
            "Epoch 2, Batch Loss: 0.13739454746246338\n",
            "Epoch 2, Batch Loss: 0.12445014715194702\n",
            "Epoch 2, Batch Loss: 0.1879262775182724\n",
            "Epoch 2, Batch Loss: 0.08788598328828812\n",
            "Epoch 2, Batch Loss: 0.20341189205646515\n",
            "Epoch 2, Batch Loss: 0.10571722686290741\n",
            "Epoch 2, Batch Loss: 0.17128993570804596\n",
            "Epoch 2, Batch Loss: 0.1242850199341774\n",
            "Epoch 2, Batch Loss: 0.11787249147891998\n",
            "Epoch 2, Batch Loss: 0.21449127793312073\n",
            "Epoch 2, Batch Loss: 0.1297910362482071\n",
            "Epoch 2, Batch Loss: 0.14009316265583038\n",
            "Epoch 2, Batch Loss: 0.14792710542678833\n",
            "Epoch 2, Batch Loss: 0.12921550869941711\n",
            "Epoch 2, Batch Loss: 0.125991553068161\n",
            "Epoch 2, Batch Loss: 0.15431833267211914\n",
            "Epoch 2, Batch Loss: 0.11251264810562134\n",
            "Epoch 2, Batch Loss: 0.11689209192991257\n",
            "Epoch 2, Batch Loss: 0.16477400064468384\n",
            "Epoch 2, Batch Loss: 0.18863843381404877\n",
            "Epoch 2, Batch Loss: 0.16333141922950745\n",
            "Epoch 2, Batch Loss: 0.1625921130180359\n",
            "Epoch 2, Batch Loss: 0.1688418835401535\n",
            "Epoch 2, Batch Loss: 0.18437619507312775\n",
            "Epoch 2, Batch Loss: 0.2005825936794281\n",
            "Epoch 2, Batch Loss: 0.16375301778316498\n",
            "Epoch 2, Batch Loss: 0.19539105892181396\n",
            "Epoch 2, Batch Loss: 0.1329580843448639\n",
            "Epoch 2, Batch Loss: 0.1727726310491562\n",
            "Epoch 2, Batch Loss: 0.139337956905365\n",
            "Epoch 2, Batch Loss: 0.2104930877685547\n",
            "Epoch 2, Batch Loss: 0.11950106173753738\n",
            "Epoch 2, Batch Loss: 0.17200231552124023\n",
            "Epoch 2, Batch Loss: 0.16672736406326294\n",
            "Epoch 2, Batch Loss: 0.16995707154273987\n",
            "Epoch 2, Batch Loss: 0.14168104529380798\n",
            "Epoch 2, Batch Loss: 0.13529670238494873\n",
            "Epoch 2, Batch Loss: 0.09724514931440353\n",
            "Epoch 2, Batch Loss: 0.11131709069013596\n",
            "Epoch 2, Batch Loss: 0.11163423210382462\n",
            "Epoch 2, Batch Loss: 0.14228558540344238\n",
            "Epoch 2, Batch Loss: 0.17338642477989197\n",
            "Epoch 2, Batch Loss: 0.15936915576457977\n",
            "Epoch 2, Batch Loss: 0.20907019078731537\n",
            "Epoch 2, Batch Loss: 0.1816100925207138\n",
            "Epoch 2, Batch Loss: 0.20395761728286743\n",
            "Epoch 2, Batch Loss: 0.15644262731075287\n",
            "Epoch 2, Batch Loss: 0.1421487182378769\n",
            "Epoch 2, Batch Loss: 0.12926386296749115\n",
            "Epoch 2, Batch Loss: 0.21494576334953308\n",
            "Epoch 2, Batch Loss: 0.13441091775894165\n",
            "Epoch 2, Batch Loss: 0.18381839990615845\n",
            "Epoch 2, Batch Loss: 0.21281327307224274\n",
            "Epoch 2, Batch Loss: 0.10697253048419952\n",
            "Epoch 2, Batch Loss: 0.13879090547561646\n",
            "Epoch 2, Batch Loss: 0.1559503674507141\n",
            "Epoch 2, Batch Loss: 0.15102888643741608\n",
            "Epoch 2, Batch Loss: 0.1576598435640335\n",
            "Epoch 2, Batch Loss: 0.11850524693727493\n",
            "Epoch 2, Batch Loss: 0.20305795967578888\n",
            "Epoch 2, Batch Loss: 0.1937067210674286\n",
            "Epoch 2, Batch Loss: 0.1866171956062317\n",
            "Epoch 2, Batch Loss: 0.11662429571151733\n",
            "Epoch 2, Batch Loss: 0.13236349821090698\n",
            "Epoch 2, Batch Loss: 0.2080973982810974\n",
            "Epoch 2, Batch Loss: 0.126177579164505\n",
            "Epoch 2, Batch Loss: 0.15893931686878204\n",
            "Epoch 2, Batch Loss: 0.13897952437400818\n",
            "Epoch 2, Batch Loss: 0.13987243175506592\n",
            "Epoch 2, Batch Loss: 0.1368589699268341\n",
            "Epoch 2, Batch Loss: 0.11290474236011505\n",
            "Epoch 2, Batch Loss: 0.11019014567136765\n",
            "Epoch 2, Batch Loss: 0.16532418131828308\n",
            "Epoch 2, Batch Loss: 0.15070632100105286\n",
            "Epoch 2, Batch Loss: 0.1925884187221527\n",
            "Epoch 2, Batch Loss: 0.09710408002138138\n",
            "Epoch 2, Batch Loss: 0.13363738358020782\n",
            "Epoch 2, Batch Loss: 0.13211479783058167\n",
            "Epoch 2, Batch Loss: 0.12304342538118362\n",
            "Epoch 2, Batch Loss: 0.14705868065357208\n",
            "Epoch 2, Batch Loss: 0.16240423917770386\n",
            "Epoch 2, Batch Loss: 0.14734970033168793\n",
            "Epoch 2, Batch Loss: 0.16562218964099884\n",
            "Epoch 2, Batch Loss: 0.10074332356452942\n",
            "Epoch 2, Batch Loss: 0.1924564242362976\n",
            "Epoch 2, Batch Loss: 0.2287299633026123\n",
            "Epoch 2, Batch Loss: 0.1640017330646515\n",
            "Epoch 2, Batch Loss: 0.10019427537918091\n",
            "Epoch 2, Batch Loss: 0.1614309549331665\n",
            "Epoch 2, Batch Loss: 0.1689651608467102\n",
            "Epoch 2, Batch Loss: 0.161123126745224\n",
            "Epoch 2, Batch Loss: 0.14930464327335358\n",
            "Epoch 2, Batch Loss: 0.1590469479560852\n",
            "Epoch 2, Batch Loss: 0.1721920669078827\n",
            "Epoch 2, Batch Loss: 0.21284443140029907\n",
            "Epoch 2, Batch Loss: 0.11097373813390732\n",
            "Epoch 2, Batch Loss: 0.23531030118465424\n",
            "Epoch 2, Batch Loss: 0.234897643327713\n",
            "Epoch 2, Batch Loss: 0.1673460602760315\n",
            "Epoch 2, Batch Loss: 0.1839326024055481\n",
            "Epoch 2, Batch Loss: 0.1438838094472885\n",
            "Epoch 2, Batch Loss: 0.11475512385368347\n",
            "Epoch 2, Batch Loss: 0.1430768370628357\n",
            "Epoch 2, Batch Loss: 0.18413548171520233\n",
            "Epoch 2, Batch Loss: 0.13338838517665863\n",
            "Epoch 2, Batch Loss: 0.09564577043056488\n",
            "Epoch 2, Batch Loss: 0.1061134859919548\n",
            "Epoch 2, Batch Loss: 0.15742915868759155\n",
            "Epoch 2, Batch Loss: 0.10570184886455536\n",
            "Epoch 2, Batch Loss: 0.08590716123580933\n",
            "Epoch 2, Batch Loss: 0.18467292189598083\n",
            "Epoch 2, Batch Loss: 0.16795788705348969\n",
            "Epoch 2, Batch Loss: 0.16915421187877655\n",
            "Epoch 2, Batch Loss: 0.13486605882644653\n",
            "Epoch 2, Batch Loss: 0.09662636369466782\n",
            "Epoch 2, Batch Loss: 0.1861114352941513\n",
            "Epoch 2, Batch Loss: 0.22027477622032166\n",
            "Epoch 2, Batch Loss: 0.13285773992538452\n",
            "Epoch 2, Batch Loss: 0.13243205845355988\n",
            "Epoch 2, Batch Loss: 0.16281050443649292\n",
            "Epoch 2, Batch Loss: 0.15479828417301178\n",
            "Epoch 2, Batch Loss: 0.12306007742881775\n",
            "Epoch 2, Batch Loss: 0.0966092124581337\n",
            "Epoch 2, Batch Loss: 0.16340163350105286\n",
            "Epoch 2, Batch Loss: 0.1503400355577469\n",
            "Epoch 2, Batch Loss: 0.12760339677333832\n",
            "Epoch 2, Batch Loss: 0.12030532956123352\n",
            "Epoch 2, Batch Loss: 0.11119437217712402\n",
            "Epoch 2, Batch Loss: 0.15768271684646606\n",
            "Epoch 2, Batch Loss: 0.17757554352283478\n",
            "Epoch 2, Batch Loss: 0.1638014316558838\n",
            "Epoch 2, Batch Loss: 0.14076805114746094\n",
            "Epoch 2, Batch Loss: 0.16786496341228485\n",
            "Epoch 2, Batch Loss: 0.12548166513442993\n",
            "Epoch 2, Batch Loss: 0.10264669358730316\n",
            "Epoch 2, Batch Loss: 0.1874285638332367\n",
            "Epoch 2, Batch Loss: 0.21730008721351624\n",
            "Epoch 2, Batch Loss: 0.11785411834716797\n",
            "Epoch 2, Batch Loss: 0.12108726799488068\n",
            "Epoch 2, Batch Loss: 0.14804430305957794\n",
            "Epoch 2, Batch Loss: 0.1907343864440918\n",
            "Epoch 2, Batch Loss: 0.09054594486951828\n",
            "Epoch 2, Batch Loss: 0.13370047509670258\n",
            "Epoch 2, Batch Loss: 0.12444651126861572\n",
            "Epoch 2, Batch Loss: 0.14804205298423767\n",
            "Epoch 2, Batch Loss: 0.09910592436790466\n",
            "Epoch 2, Batch Loss: 0.20751529932022095\n",
            "Epoch 2, Batch Loss: 0.1583256721496582\n",
            "Epoch 2, Batch Loss: 0.12115534394979477\n",
            "Epoch 2, Batch Loss: 0.1080639436841011\n",
            "Epoch 2, Batch Loss: 0.23370230197906494\n",
            "Epoch 2, Batch Loss: 0.08413466066122055\n",
            "Epoch 2, Batch Loss: 0.14651349186897278\n",
            "Epoch 2, Batch Loss: 0.18591460585594177\n",
            "Epoch 2, Batch Loss: 0.2038649320602417\n",
            "Epoch 2, Batch Loss: 0.15313208103179932\n",
            "Epoch 2, Batch Loss: 0.1035599634051323\n",
            "Epoch 2, Batch Loss: 0.11126797646284103\n",
            "Epoch 2, Batch Loss: 0.09874007105827332\n",
            "Epoch 2, Batch Loss: 0.1032608151435852\n",
            "Epoch 2, Batch Loss: 0.07989263534545898\n",
            "Epoch 2, Batch Loss: 0.21472571790218353\n",
            "Epoch 2, Batch Loss: 0.186073437333107\n",
            "Epoch 2, Batch Loss: 0.07895617187023163\n",
            "Epoch 2, Batch Loss: 0.14046227931976318\n",
            "Epoch 2, Batch Loss: 0.14749181270599365\n",
            "Epoch 2, Batch Loss: 0.14806438982486725\n",
            "Epoch 2, Batch Loss: 0.18245643377304077\n",
            "Epoch 2, Batch Loss: 0.21623694896697998\n",
            "Epoch 2, Batch Loss: 0.13015545904636383\n",
            "Epoch 2, Batch Loss: 0.155783548951149\n",
            "Epoch 2, Batch Loss: 0.12826871871948242\n",
            "Epoch 2, Batch Loss: 0.2072698026895523\n",
            "Epoch 2, Batch Loss: 0.16015556454658508\n",
            "Epoch 2, Batch Loss: 0.2085663229227066\n",
            "Epoch 2, Batch Loss: 0.10633815824985504\n",
            "Epoch 2, Batch Loss: 0.22549724578857422\n",
            "Epoch 2, Batch Loss: 0.12607328593730927\n",
            "Epoch 2, Batch Loss: 0.1521969884634018\n",
            "Epoch 2, Batch Loss: 0.10187307745218277\n",
            "Epoch 2, Batch Loss: 0.13653618097305298\n",
            "Epoch 2, Batch Loss: 0.1558224856853485\n",
            "Epoch 2, Batch Loss: 0.11091113090515137\n",
            "Epoch 2, Batch Loss: 0.16238515079021454\n",
            "Epoch 2, Batch Loss: 0.15361769497394562\n",
            "Epoch 2, Batch Loss: 0.1562241166830063\n",
            "Epoch 2, Batch Loss: 0.18576660752296448\n",
            "Epoch 2, Batch Loss: 0.21005168557167053\n",
            "Epoch 2, Batch Loss: 0.1437082439661026\n",
            "Epoch 2, Batch Loss: 0.14412760734558105\n",
            "Epoch 2, Batch Loss: 0.15875747799873352\n",
            "Epoch 2, Batch Loss: 0.1846667230129242\n",
            "Epoch 2, Batch Loss: 0.1466948539018631\n",
            "Epoch 2, Batch Loss: 0.16321027278900146\n",
            "Epoch 2, Batch Loss: 0.1552337408065796\n",
            "Epoch 2, Batch Loss: 0.12025605887174606\n",
            "Epoch 2, Batch Loss: 0.18703529238700867\n",
            "Epoch 2, Batch Loss: 0.09714385122060776\n",
            "Epoch 2, Batch Loss: 0.20207595825195312\n",
            "Epoch 2, Batch Loss: 0.1510002464056015\n",
            "Epoch 2, Batch Loss: 0.21351148188114166\n",
            "Epoch 2, Batch Loss: 0.1519612967967987\n",
            "Epoch 2, Batch Loss: 0.19051989912986755\n",
            "Epoch 2, Batch Loss: 0.11311429738998413\n",
            "Epoch 2, Batch Loss: 0.15762566030025482\n",
            "Epoch 2, Batch Loss: 0.15368638932704926\n",
            "Epoch 2, Batch Loss: 0.19220617413520813\n",
            "Epoch 2, Batch Loss: 0.11417484283447266\n",
            "Epoch 2, Batch Loss: 0.08799029886722565\n",
            "Epoch 2, Batch Loss: 0.1462060809135437\n",
            "Epoch 2, Batch Loss: 0.15873074531555176\n",
            "Epoch 2, Batch Loss: 0.11511647701263428\n",
            "Epoch 2, Batch Loss: 0.08736925572156906\n",
            "Epoch 2, Batch Loss: 0.12082313001155853\n",
            "Epoch 2, Batch Loss: 0.1350623369216919\n",
            "Epoch 2, Batch Loss: 0.1804700493812561\n",
            "Epoch 2, Batch Loss: 0.1149744763970375\n",
            "Epoch 2, Batch Loss: 0.14996594190597534\n",
            "Epoch 2, Batch Loss: 0.17431393265724182\n",
            "Epoch 2, Batch Loss: 0.11089127510786057\n",
            "Epoch 2, Batch Loss: 0.16917598247528076\n",
            "Epoch 2, Batch Loss: 0.10419221967458725\n",
            "Epoch 2, Batch Loss: 0.09913590550422668\n",
            "Epoch 2, Batch Loss: 0.22080150246620178\n",
            "Epoch 2, Batch Loss: 0.10458812862634659\n",
            "Epoch 2, Batch Loss: 0.12494978308677673\n",
            "Epoch 2, Batch Loss: 0.15118670463562012\n",
            "Epoch 2, Batch Loss: 0.11451360583305359\n",
            "Epoch 2, Batch Loss: 0.15718376636505127\n",
            "Epoch 2, Batch Loss: 0.12035396695137024\n",
            "Epoch 2, Batch Loss: 0.1489446461200714\n",
            "Epoch 2, Batch Loss: 0.12919452786445618\n",
            "Epoch 2, Batch Loss: 0.20113760232925415\n",
            "Epoch 2, Batch Loss: 0.13734027743339539\n",
            "Epoch 2, Batch Loss: 0.20814931392669678\n",
            "Epoch 2, Batch Loss: 0.13596762716770172\n",
            "Epoch 2, Batch Loss: 0.15146926045417786\n",
            "Epoch 2, Batch Loss: 0.1452324539422989\n",
            "Epoch 2, Batch Loss: 0.11678105592727661\n",
            "Epoch 2, Batch Loss: 0.17217497527599335\n",
            "Epoch 2, Batch Loss: 0.13753028213977814\n",
            "Epoch 2, Batch Loss: 0.11583578586578369\n",
            "Epoch 2, Batch Loss: 0.11936910450458527\n",
            "Epoch 2, Batch Loss: 0.16750246286392212\n",
            "Epoch 2, Batch Loss: 0.15739886462688446\n",
            "Epoch 2, Batch Loss: 0.20979855954647064\n",
            "Epoch 2, Batch Loss: 0.1444731503725052\n",
            "Epoch 2, Batch Loss: 0.18478676676750183\n",
            "Epoch 2, Batch Loss: 0.16679376363754272\n",
            "Epoch 2, Batch Loss: 0.14231832325458527\n",
            "Epoch 2, Batch Loss: 0.11990979313850403\n",
            "Epoch 2, Batch Loss: 0.10217080265283585\n",
            "Epoch 2, Batch Loss: 0.22414818406105042\n",
            "Epoch 2, Batch Loss: 0.1480800062417984\n",
            "Epoch 2, Batch Loss: 0.1340024173259735\n",
            "Epoch 2, Batch Loss: 0.1746484935283661\n",
            "Epoch 2, Batch Loss: 0.11507981270551682\n",
            "Epoch 2, Batch Loss: 0.17138127982616425\n",
            "Epoch 2, Batch Loss: 0.14302915334701538\n",
            "Epoch 2, Batch Loss: 0.18806900084018707\n",
            "Epoch 2, Batch Loss: 0.11720389127731323\n",
            "Epoch 2, Batch Loss: 0.1617804765701294\n",
            "Epoch 2, Batch Loss: 0.20775248110294342\n",
            "Epoch 2, Batch Loss: 0.16763731837272644\n",
            "Epoch 2, Batch Loss: 0.12855343520641327\n",
            "Epoch 2, Batch Loss: 0.1309654265642166\n",
            "Epoch 2, Batch Loss: 0.1681186705827713\n",
            "Epoch 2, Batch Loss: 0.1536814570426941\n",
            "Epoch 2, Batch Loss: 0.15746310353279114\n",
            "Epoch 2, Batch Loss: 0.1885710060596466\n",
            "Epoch 2, Batch Loss: 0.1281040608882904\n",
            "Epoch 2, Batch Loss: 0.14322882890701294\n",
            "Epoch 2, Batch Loss: 0.1366404891014099\n",
            "Epoch 2, Batch Loss: 0.11280505359172821\n",
            "Epoch 2, Batch Loss: 0.08422628045082092\n",
            "Epoch 2, Batch Loss: 0.20194971561431885\n",
            "Epoch 2, Batch Loss: 0.1818433403968811\n",
            "Epoch 2, Batch Loss: 0.16652807593345642\n",
            "Epoch 2, Batch Loss: 0.11056961119174957\n",
            "Epoch 2, Batch Loss: 0.1188393384218216\n",
            "Epoch 2, Batch Loss: 0.1346476972103119\n",
            "Epoch 2, Batch Loss: 0.15968063473701477\n",
            "Epoch 2, Batch Loss: 0.18848472833633423\n",
            "Epoch 2, Batch Loss: 0.20097534358501434\n",
            "Epoch 2, Batch Loss: 0.11636600643396378\n",
            "Epoch 2, Batch Loss: 0.12286292016506195\n",
            "Epoch 2, Batch Loss: 0.15974950790405273\n",
            "Epoch 2, Batch Loss: 0.11121649295091629\n",
            "Epoch 2, Batch Loss: 0.09349790215492249\n",
            "Epoch 2, Batch Loss: 0.1383177936077118\n",
            "Epoch 2, Batch Loss: 0.15319329500198364\n",
            "Epoch 2, Batch Loss: 0.1633669137954712\n",
            "Epoch 2, Batch Loss: 0.1670500636100769\n",
            "Epoch 2, Batch Loss: 0.11349648982286453\n",
            "Epoch 2, Batch Loss: 0.12962427735328674\n",
            "Epoch 2, Batch Loss: 0.2022792249917984\n",
            "Epoch 2, Batch Loss: 0.17959149181842804\n",
            "Epoch 2, Epoch Loss: 0.17959149181842804\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename='training.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(2):\n",
        "    for batch in dataloader:\n",
        "        uid_meta, uid_interaction, pos, neg = batch\n",
        "        optimizer.zero_grad()\n",
        "        anchor = u2v(uid_meta, uid_interaction)\n",
        "        positive = i2v(pos)\n",
        "        negative = i2v(neg)\n",
        "        loss = triplet_loss(anchor, positive, negative)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Log the loss for each batch\n",
        "        print(f\"Epoch {epoch + 1}, Batch Loss: {loss.item()}\")\n",
        "\n",
        "    # Log the epoch loss\n",
        "    print(f\"Epoch {epoch + 1}, Epoch Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VRXi0BO7Yo8i"
      },
      "outputs": [],
      "source": [
        "# Inference:\n",
        "# Get user and item features\n",
        "rand_uid = np.random.choice(list(users_ohe_df.index))\n",
        "user_meta_feats = users_ohe_df.drop([\"user_id\"], axis=1).iloc[rand_uid].values\n",
        "user_interaction_vec = interactions_vec[rand_uid]\n",
        "rand_iid = np.random.choice(list(items_ohe_df.index))\n",
        "item_feats = items_ohe_df.drop([\"item_id\"], axis=1).iloc[rand_iid].values\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "user_meta_feats = torch.tensor(user_meta_feats, dtype=torch.float32)\n",
        "user_interaction_vec = torch.tensor(user_interaction_vec, dtype=torch.float32)\n",
        "item_feats = torch.tensor(item_feats, dtype=torch.float32)\n",
        "\n",
        "# Get user and item embeddings\n",
        "user_vec = u2v(user_meta_feats.unsqueeze(0), user_interaction_vec.unsqueeze(0))\n",
        "item_vec = i2v(item_feats.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3T13ZDWZepQ",
        "outputId": "305f865e-f7b6-479d-8fe3-20ec36715712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between user 1868 and item 5721: 15.041807174682617\n"
          ]
        }
      ],
      "source": [
        "# Inference:\n",
        "# Get user and item features\n",
        "rand_uid = np.random.choice(list(users_ohe_df.index))\n",
        "user_meta_feats = users_ohe_df.drop([\"user_id\"], axis=1).iloc[rand_uid].values\n",
        "user_interaction_vec = interactions_vec[rand_uid]\n",
        "rand_iid = np.random.choice(list(items_ohe_df.index))\n",
        "item_feats = items_ohe_df.drop([\"item_id\"], axis=1).iloc[rand_iid].values\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "user_meta_feats = torch.tensor(user_meta_feats, dtype=torch.float32)\n",
        "user_interaction_vec = torch.tensor(user_interaction_vec, dtype=torch.float32)\n",
        "item_feats = torch.tensor(item_feats, dtype=torch.float32)\n",
        "\n",
        "# Get user and item embeddings\n",
        "user_vec = u2v(user_meta_feats.unsqueeze(0), user_interaction_vec.unsqueeze(0))\n",
        "item_vec = i2v(item_feats.unsqueeze(0))\n",
        "\n",
        "# Calculate distance\n",
        "distance = torch.dist(user_vec, item_vec)\n",
        "\n",
        "# Print distance\n",
        "print(f\"Distance between user {rand_uid} and item {rand_iid}: {distance.item()}\")\n",
        "\n",
        "# Get top 10 recommendations for all users\n",
        "users_meta_feats = torch.tensor(users_ohe_df.drop([\"user_id\"], axis=1).values, dtype=torch.float32)\n",
        "users_interaction_vec = torch.tensor(interactions_vec, dtype=torch.float32)\n",
        "items_feats = torch.tensor(items_ohe_df.drop([\"item_id\"], axis=1).values, dtype=torch.float32)\n",
        "\n",
        "users_vec = u2v(users_meta_feats, users_interaction_vec)\n",
        "items_vecs = i2v(items_feats)\n",
        "\n",
        "dists = torch.cdist(users_vec, items_vecs)\n",
        "\n",
        "top10_iids = torch.argsort(dists, dim=1)[:, :10]\n",
        "\n",
        "top10_iids_item = [iid_to_item_id[iid.item()] for iid in top10_iids.reshape(-1)]\n",
        "top10_iids_item = np.array(top10_iids_item).reshape(top10_iids.shape)\n",
        "\n",
        "df_dssm = pd.DataFrame({'user_id': [uid_to_user_id[uid] for uid in np.arange(top10_iids_item.shape[0])]})\n",
        "df_dssm['item_id'] = list(top10_iids_item)\n",
        "df_dssm = df_dssm.explode('item_id')\n",
        "df_dssm['rank'] = df_dssm.groupby('user_id').cumcount() + 1\n",
        "df_dssm = df_dssm.groupby('user_id').agg({'item_id': list}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uUyiyMpmZef3",
        "outputId": "ee521660-5d62-492b-dd33-788821fe4b3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[6809, 11237, 12173, 16166, 9342, 10761, 9728,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>[6809, 11237, 10761, 12173, 9342, 849, 5693, 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>53</td>\n",
              "      <td>[6809, 10761, 11237, 9728, 9342, 16166, 12173,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>[6809, 11237, 10761, 12173, 9728, 9342, 5693, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>81</td>\n",
              "      <td>[6809, 9728, 11237, 4621, 849, 10761, 1844, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65969</th>\n",
              "      <td>1097486</td>\n",
              "      <td>[6809, 11237, 9728, 9342, 12173, 849, 1844, 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65970</th>\n",
              "      <td>1097489</td>\n",
              "      <td>[6809, 11237, 10761, 12173, 9342, 5693, 849, 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65971</th>\n",
              "      <td>1097508</td>\n",
              "      <td>[6809, 11237, 10761, 12173, 9342, 16166, 9728,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65972</th>\n",
              "      <td>1097513</td>\n",
              "      <td>[6809, 11237, 12173, 10761, 849, 9342, 9728, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65973</th>\n",
              "      <td>1097516</td>\n",
              "      <td>[9728, 1844, 10761, 4621, 6809, 3509, 849, 721...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65974 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_id                                            item_id\n",
              "0            2  [6809, 11237, 12173, 16166, 9342, 10761, 9728,...\n",
              "1           21  [6809, 11237, 10761, 12173, 9342, 849, 5693, 9...\n",
              "2           53  [6809, 10761, 11237, 9728, 9342, 16166, 12173,...\n",
              "3           60  [6809, 11237, 10761, 12173, 9728, 9342, 5693, ...\n",
              "4           81  [6809, 9728, 11237, 4621, 849, 10761, 1844, 16...\n",
              "...        ...                                                ...\n",
              "65969  1097486  [6809, 11237, 9728, 9342, 12173, 849, 1844, 10...\n",
              "65970  1097489  [6809, 11237, 10761, 12173, 9342, 5693, 849, 9...\n",
              "65971  1097508  [6809, 11237, 10761, 12173, 9342, 16166, 9728,...\n",
              "65972  1097513  [6809, 11237, 12173, 10761, 849, 9342, 9728, 5...\n",
              "65973  1097516  [9728, 1844, 10761, 4621, 6809, 3509, 849, 721...\n",
              "\n",
              "[65974 rows x 2 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dssm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проделаны следующие изменения/эксперименты:\n",
        "- замена MLM слоев на энкодер блоки трансформера для улучшение моделирования зависимостей\n",
        "- замена триплет loss на триплет loss с расчетом косинусной близости для более робастного сравнения векторов \n",
        "- добавил Dropout и Layer Norm слои для уменьшения переобучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # сохранение векторов для сервиса\n",
        "# import pickle\n",
        "# import hnswlib\n",
        "\n",
        "# def save_dssm_for_service(item_model, user_model, output_dir, \n",
        "#                          items_df, users_df, interactions_vec):\n",
        "#     \"\"\"\n",
        "#     Сохраняет эмбеддинги и маппинги DSSM модели для использования в сервисе\n",
        "    \n",
        "#     Args:\n",
        "#         item_model: Обученная модель ItemModel\n",
        "#         user_model: Обученная модель UserModel\n",
        "#         output_dir: Директория для сохранения файлов\n",
        "#         items_df: DataFrame с данными предметов\n",
        "#         users_df: DataFrame с данными пользователей\n",
        "#         interactions_vec: Матрица взаимодействий пользователь-предмет\n",
        "#     \"\"\"\n",
        "#     import os\n",
        "    \n",
        "#     # Создаем директорию, если она не существует\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "#     print(f\"Сохранение модели DSSM в директорию {output_dir}...\")\n",
        "    \n",
        "#     # 1. Вычисляем эмбеддинги предметов\n",
        "#     item_model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         items_feats = torch.tensor(items_df.drop([\"item_id\"], axis=1).values, dtype=torch.float32)\n",
        "#         item_embeddings = item_model(items_feats).cpu().numpy()\n",
        "    \n",
        "#     # 2. Вычисляем эмбеддинги пользователей\n",
        "#     user_model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         users_meta = torch.tensor(users_df.drop([\"user_id\"], axis=1).values, dtype=torch.float32)\n",
        "#         users_interactions = torch.tensor(interactions_vec, dtype=torch.float32)\n",
        "#         user_embeddings = user_model(users_meta, users_interactions).cpu().numpy()\n",
        "    \n",
        "#     # 3. Создаем маппинги ID -> индексы и наоборот\n",
        "#     user_id_to_idx = {user_id: idx for idx, user_id in enumerate(users_df.user_id.values)}\n",
        "#     idx_to_user_id = {idx: user_id for user_id, idx in user_id_to_idx.items()}\n",
        "    \n",
        "#     item_id_to_idx = {item_id: idx for idx, item_id in enumerate(items_df.item_id.values)}\n",
        "#     idx_to_item_id = {idx: item_id for item_id, idx in item_id_to_idx.items()}\n",
        "    \n",
        "#     mappings = {\n",
        "#         \"user_id_to_idx\": user_id_to_idx,\n",
        "#         \"idx_to_user_id\": idx_to_user_id,\n",
        "#         \"item_id_to_idx\": item_id_to_idx,\n",
        "#         \"idx_to_item_id\": idx_to_item_id\n",
        "#     }\n",
        "    \n",
        "#     # 4. Сохраняем эмбеддинги\n",
        "#     np.save(os.path.join(output_dir, \"user_embeddings.npy\"), user_embeddings)\n",
        "#     np.save(os.path.join(output_dir, \"item_embeddings.npy\"), item_embeddings)\n",
        "    \n",
        "#     # 5. Сохраняем маппинги\n",
        "#     with open(os.path.join(output_dir, \"id_mappings.pkl\"), 'wb') as f:\n",
        "#         pickle.dump(mappings, f)\n",
        "    \n",
        "#     # 6. Создаем и сохраняем HNSW индекс\n",
        "#     dim = item_embeddings.shape[1]\n",
        "#     num_elements = item_embeddings.shape[0]\n",
        "    \n",
        "#     # Инициализируем индекс с косинусным расстоянием\n",
        "#     index = hnswlib.Index(space='cosine', dim=dim)\n",
        "#     index.init_index(max_elements=num_elements, ef_construction=200, M=50)\n",
        "    \n",
        "#     # Добавляем эмбеддинги предметов в индекс\n",
        "#     index.add_items(item_embeddings)\n",
        "    \n",
        "#     # Устанавливаем параметр ef для поиска\n",
        "#     index.set_ef(30)\n",
        "    \n",
        "#     # Сохраняем индекс\n",
        "#     index.save_index(os.path.join(output_dir, \"hnsw_index.bin\"))\n",
        "    \n",
        "#     # Сохраняем конфигурацию индекса\n",
        "#     config_params = {\n",
        "#             \"hnsw_params\": {\n",
        "#                 \"space\": \"cosine\",\n",
        "#                 \"dim\": dim,\n",
        "#                 \"efC\": 200,\n",
        "#                 \"efS\": 30,\n",
        "#                 \"M\": 50\n",
        "#             },\n",
        "#         }\n",
        "    \n",
        "#     with open(os.path.join(output_dir, \"config.pkl\"), 'wb') as f:\n",
        "#         pickle.dump(config_params, f)\n",
        "    \n",
        "#     print(\"Сохранение завершено. Сохранены следующие файлы:\")\n",
        "#     print(f\"- {os.path.join(output_dir, 'user_embeddings.npy')}\")\n",
        "#     print(f\"- {os.path.join(output_dir, 'item_embeddings.npy')}\")\n",
        "#     print(f\"- {os.path.join(output_dir, 'id_mappings.pkl')}\")\n",
        "#     print(f\"- {os.path.join(output_dir, 'hnsw_index.bin')}\")\n",
        "#     print(f\"- {os.path.join(output_dir, 'config.pkl')}\")\n",
        "    \n",
        "#     return {\n",
        "#         \"user_embeddings_path\": os.path.join(output_dir, \"user_embeddings.npy\"),\n",
        "#         \"item_embeddings_path\": os.path.join(output_dir, \"item_embeddings.npy\"),\n",
        "#         \"id_mappings_path\": os.path.join(output_dir, \"id_mappings.pkl\"),\n",
        "#         \"hnsw_index_path\": os.path.join(output_dir, \"hnsw_index.bin\"),\n",
        "#         \"hnsw_mappings_path\": os.path.join(output_dir, \"config.pkl\")\n",
        "#     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Сохранение модели DSSM в директорию /Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm...\n",
            "Сохранение завершено. Сохранены следующие файлы:\n",
            "- /Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/user_embeddings.npy\n",
            "- /Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/item_embeddings.npy\n",
            "- /Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/id_mappings.pkl\n",
            "- /Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/hnsw_index.bin\n",
            "- /Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/config.pkl\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'user_embeddings_path': '/Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/user_embeddings.npy',\n",
              " 'item_embeddings_path': '/Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/item_embeddings.npy',\n",
              " 'id_mappings_path': '/Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/id_mappings.pkl',\n",
              " 'hnsw_index_path': '/Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/hnsw_index.bin',\n",
              " 'hnsw_mappings_path': '/Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm/config.pkl'}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# output_dir = \"/Users/kulyaskin_mikhail/ITMO/RecSys/data/dssm\"\n",
        "# save_dssm_for_service(i2v, u2v, output_dir, \n",
        "#                       items_ohe_df.reset_index(drop=True), \n",
        "#                       users_ohe_df.reset_index(drop=True), \n",
        "#                       interactions_vec)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "044dd95f0ac64bc58af81f99e222d166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7ce9010ffd54638b94797325827e4e0",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28e13beeb37845238cef064c8d7bd387",
            "value": 75
          }
        },
        "1f6caa6903b646e9978230aab8e755ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1cd152a8dfc4bac8b02af0109065cbd",
              "IPY_MODEL_044dd95f0ac64bc58af81f99e222d166",
              "IPY_MODEL_cb0860e031754e8a83fc0b56b2e31402"
            ],
            "layout": "IPY_MODEL_9162e98d7091446ab6711eda100ced59"
          }
        },
        "28e13beeb37845238cef064c8d7bd387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5609cbd6c5564965bfdf64580278b887": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8157c87a4a4e4a4f8b05aa3f2ebadf31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9162e98d7091446ab6711eda100ced59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba94d8beede438a821ccd09c36a0c21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37863cce5d74db9985fc1694df2a644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7ce9010ffd54638b94797325827e4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1cd152a8dfc4bac8b02af0109065cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8157c87a4a4e4a4f8b05aa3f2ebadf31",
            "placeholder": "​",
            "style": "IPY_MODEL_5609cbd6c5564965bfdf64580278b887",
            "value": "Downloading kion_train.zip: "
          }
        },
        "cb0860e031754e8a83fc0b56b2e31402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba94d8beede438a821ccd09c36a0c21",
            "placeholder": "​",
            "style": "IPY_MODEL_a37863cce5d74db9985fc1694df2a644",
            "value": " 76/? [00:00&lt;00:00, 308.38MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
